{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkJoQBkUIHC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaTwK7ojXr2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9d716e0-e532-44f1-d707-261b2abb30ef"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUkhkMfU4wq"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYP9cQTWbzuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb19722d-f86d-40b5-e1b5-401257067a8a"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38vKGE6Nb2RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2079a26b-6c1e-4b05-88f6-2ade1e2cedb0"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "aLv7t1AhSSfh",
        "outputId": "a24ac416-b67b-4d6e-eef5-4726bc73a271"
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>15574012</td>\n",
              "      <td>Chu</td>\n",
              "      <td>645</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>8</td>\n",
              "      <td>113755.78</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>149756.71</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>15592531</td>\n",
              "      <td>Bartlett</td>\n",
              "      <td>822</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>50</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10062.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>15656148</td>\n",
              "      <td>Obinna</td>\n",
              "      <td>376</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Female</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>115046.74</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>119346.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>15792365</td>\n",
              "      <td>He</td>\n",
              "      <td>501</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>142051.07</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74940.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>15592389</td>\n",
              "      <td>H?</td>\n",
              "      <td>684</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>134603.88</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>71725.73</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "5          6    15574012       Chu  ...               0       149756.71      1\n",
              "6          7    15592531  Bartlett  ...               1        10062.80      0\n",
              "7          8    15656148    Obinna  ...               0       119346.88      1\n",
              "8          9    15792365        He  ...               1        74940.50      0\n",
              "9         10    15592389        H?  ...               1        71725.73      0\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVKWXxLbczC"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M1KboxFb6OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724c6782-ee29-4dc8-e259-57e67b7f0c4c"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMXC8-KMVirw"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcxwEon-b8nV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03998cbc-736c-4b75-e54f-01dcc2527d30"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSzSa4DLaKC2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQMGcJEvTGkP",
        "outputId": "593a1615-5b8d-4806-9236-3c1392755fc4"
      },
      "source": [
        "print(X[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0 0.0 0.0 619 0 42 2 0.0 1 1 1 101348.88]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHQWWD89TGs7",
        "outputId": "892aec34-9356-4dfc-9e91-25b8c8c45def"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-TDt0Y_XEfc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCrE00rV8Sk"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad7ZM3_jT3BU",
        "outputId": "b48d48cd-027e-454c-aaab-592946fc55ac"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.01460667 -0.5698444   1.74309049  0.16958176 -1.09168714 -0.46460796\n",
            "  0.00666099 -1.21571749  0.8095029   0.64259497 -1.03227043  1.10643166]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dtrScHxXQox"
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bppGycBXYCQr"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JneR0u0sYRTd"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3x41RBYfvY"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG3RrwDXZEaS"
      },
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHZ-LKv_ZRb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0225c11-3081-4a1f-bfea-629653891457"
      },
      "source": [
        "#train on 100,500,1000 epochs\n",
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 500)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8648\n",
            "Epoch 2/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8631\n",
            "Epoch 3/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8634\n",
            "Epoch 4/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8644\n",
            "Epoch 5/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8660\n",
            "Epoch 6/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8631\n",
            "Epoch 7/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8634\n",
            "Epoch 8/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8643\n",
            "Epoch 9/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8645\n",
            "Epoch 10/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8636\n",
            "Epoch 11/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8633\n",
            "Epoch 12/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8641\n",
            "Epoch 13/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8643\n",
            "Epoch 14/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8630\n",
            "Epoch 15/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8645\n",
            "Epoch 16/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8637\n",
            "Epoch 17/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8645\n",
            "Epoch 18/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8645\n",
            "Epoch 19/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8646\n",
            "Epoch 20/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8633\n",
            "Epoch 21/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8639\n",
            "Epoch 22/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8664\n",
            "Epoch 23/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8645\n",
            "Epoch 24/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8645\n",
            "Epoch 25/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8649\n",
            "Epoch 26/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8645\n",
            "Epoch 27/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8652\n",
            "Epoch 28/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8654\n",
            "Epoch 29/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8644\n",
            "Epoch 30/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8648\n",
            "Epoch 31/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8644\n",
            "Epoch 32/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8640\n",
            "Epoch 33/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8648\n",
            "Epoch 34/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8655\n",
            "Epoch 35/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8637\n",
            "Epoch 36/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8645\n",
            "Epoch 37/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8652\n",
            "Epoch 38/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8648\n",
            "Epoch 39/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8640\n",
            "Epoch 40/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8633\n",
            "Epoch 41/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8649\n",
            "Epoch 42/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8641\n",
            "Epoch 43/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8676\n",
            "Epoch 44/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8640\n",
            "Epoch 45/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8659\n",
            "Epoch 46/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8646\n",
            "Epoch 47/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8639\n",
            "Epoch 48/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8648\n",
            "Epoch 49/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8662\n",
            "Epoch 50/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8649\n",
            "Epoch 51/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8640\n",
            "Epoch 52/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8634\n",
            "Epoch 53/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8645\n",
            "Epoch 54/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8644\n",
            "Epoch 55/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8662\n",
            "Epoch 56/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8645\n",
            "Epoch 57/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8649\n",
            "Epoch 58/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8643\n",
            "Epoch 59/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8646\n",
            "Epoch 60/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8641\n",
            "Epoch 61/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8637\n",
            "Epoch 62/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8640\n",
            "Epoch 63/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8661\n",
            "Epoch 64/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8659\n",
            "Epoch 65/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8659\n",
            "Epoch 66/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8641\n",
            "Epoch 67/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8658\n",
            "Epoch 68/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8640\n",
            "Epoch 69/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8641\n",
            "Epoch 70/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8658\n",
            "Epoch 71/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8652\n",
            "Epoch 72/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8654\n",
            "Epoch 73/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8656\n",
            "Epoch 74/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8658\n",
            "Epoch 75/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8654\n",
            "Epoch 76/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8664\n",
            "Epoch 77/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8656\n",
            "Epoch 78/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8660\n",
            "Epoch 79/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8637\n",
            "Epoch 80/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8662\n",
            "Epoch 81/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8655\n",
            "Epoch 82/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8664\n",
            "Epoch 83/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8640\n",
            "Epoch 84/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8659\n",
            "Epoch 85/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8651\n",
            "Epoch 86/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8633\n",
            "Epoch 87/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8654\n",
            "Epoch 88/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8662\n",
            "Epoch 89/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8645\n",
            "Epoch 90/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8670\n",
            "Epoch 91/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8662\n",
            "Epoch 92/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8684\n",
            "Epoch 93/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8659\n",
            "Epoch 94/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8655\n",
            "Epoch 95/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8655\n",
            "Epoch 96/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8661\n",
            "Epoch 97/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8652\n",
            "Epoch 98/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8660\n",
            "Epoch 99/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8668\n",
            "Epoch 100/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8651\n",
            "Epoch 101/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8652\n",
            "Epoch 102/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8666\n",
            "Epoch 103/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8648\n",
            "Epoch 104/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8650\n",
            "Epoch 105/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8665\n",
            "Epoch 106/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8652\n",
            "Epoch 107/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8656\n",
            "Epoch 108/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8659\n",
            "Epoch 109/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8666\n",
            "Epoch 110/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8661\n",
            "Epoch 111/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8651\n",
            "Epoch 112/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8661\n",
            "Epoch 113/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8646\n",
            "Epoch 114/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8652\n",
            "Epoch 115/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8668\n",
            "Epoch 116/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8652\n",
            "Epoch 117/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8655\n",
            "Epoch 118/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8649\n",
            "Epoch 119/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8662\n",
            "Epoch 120/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8631\n",
            "Epoch 121/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8651\n",
            "Epoch 122/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8655\n",
            "Epoch 123/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8651\n",
            "Epoch 124/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8652\n",
            "Epoch 125/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8649\n",
            "Epoch 126/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8656\n",
            "Epoch 127/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8665\n",
            "Epoch 128/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8648\n",
            "Epoch 129/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8656\n",
            "Epoch 130/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8654\n",
            "Epoch 131/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8645\n",
            "Epoch 132/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8656\n",
            "Epoch 133/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8660\n",
            "Epoch 134/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8661\n",
            "Epoch 135/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8648\n",
            "Epoch 136/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8655\n",
            "Epoch 137/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8669\n",
            "Epoch 138/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8662\n",
            "Epoch 139/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8659\n",
            "Epoch 140/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8637\n",
            "Epoch 141/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8650\n",
            "Epoch 142/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8650\n",
            "Epoch 143/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8650\n",
            "Epoch 144/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8648\n",
            "Epoch 145/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8665\n",
            "Epoch 146/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8641\n",
            "Epoch 147/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8635\n",
            "Epoch 148/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8664\n",
            "Epoch 149/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8645\n",
            "Epoch 150/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8646\n",
            "Epoch 151/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8649\n",
            "Epoch 152/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8655\n",
            "Epoch 153/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8654\n",
            "Epoch 154/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8650\n",
            "Epoch 155/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8665\n",
            "Epoch 156/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8652\n",
            "Epoch 157/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8645\n",
            "Epoch 158/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8634\n",
            "Epoch 159/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8659\n",
            "Epoch 160/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8644\n",
            "Epoch 161/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8649\n",
            "Epoch 162/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8649\n",
            "Epoch 163/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8645\n",
            "Epoch 164/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8665\n",
            "Epoch 165/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8654\n",
            "Epoch 166/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8661\n",
            "Epoch 167/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8656\n",
            "Epoch 168/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8652\n",
            "Epoch 169/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8645\n",
            "Epoch 170/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8652\n",
            "Epoch 171/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8660\n",
            "Epoch 172/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8652\n",
            "Epoch 173/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8673\n",
            "Epoch 174/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8651\n",
            "Epoch 175/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8651\n",
            "Epoch 176/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8660\n",
            "Epoch 177/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8656\n",
            "Epoch 178/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8646\n",
            "Epoch 179/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8652\n",
            "Epoch 180/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8639\n",
            "Epoch 181/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8649\n",
            "Epoch 182/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8668\n",
            "Epoch 183/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8658\n",
            "Epoch 184/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8654\n",
            "Epoch 185/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8655\n",
            "Epoch 186/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8648\n",
            "Epoch 187/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8648\n",
            "Epoch 188/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8637\n",
            "Epoch 189/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8643\n",
            "Epoch 190/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8660\n",
            "Epoch 191/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8662\n",
            "Epoch 192/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8668\n",
            "Epoch 193/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8673\n",
            "Epoch 194/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8636\n",
            "Epoch 195/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8650\n",
            "Epoch 196/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8662\n",
            "Epoch 197/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8641\n",
            "Epoch 198/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8640\n",
            "Epoch 199/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8652\n",
            "Epoch 200/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8652\n",
            "Epoch 201/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8656\n",
            "Epoch 202/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8639\n",
            "Epoch 203/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8655\n",
            "Epoch 204/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8648\n",
            "Epoch 205/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8639\n",
            "Epoch 206/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8664\n",
            "Epoch 207/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8651\n",
            "Epoch 208/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8650\n",
            "Epoch 209/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8648\n",
            "Epoch 210/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8655\n",
            "Epoch 211/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8645\n",
            "Epoch 212/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8652\n",
            "Epoch 213/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8675\n",
            "Epoch 214/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8655\n",
            "Epoch 215/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8659\n",
            "Epoch 216/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8651\n",
            "Epoch 217/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8655\n",
            "Epoch 218/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8637\n",
            "Epoch 219/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8649\n",
            "Epoch 220/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8644\n",
            "Epoch 221/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8655\n",
            "Epoch 222/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8646\n",
            "Epoch 223/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8661\n",
            "Epoch 224/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8652\n",
            "Epoch 225/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8655\n",
            "Epoch 226/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8656\n",
            "Epoch 227/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8661\n",
            "Epoch 228/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8658\n",
            "Epoch 229/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8654\n",
            "Epoch 230/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8651\n",
            "Epoch 231/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8654\n",
            "Epoch 232/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8649\n",
            "Epoch 233/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8668\n",
            "Epoch 234/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8650\n",
            "Epoch 235/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8660\n",
            "Epoch 236/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8661\n",
            "Epoch 237/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8648\n",
            "Epoch 238/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8655\n",
            "Epoch 239/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8648\n",
            "Epoch 240/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8649\n",
            "Epoch 241/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8651\n",
            "Epoch 242/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8662\n",
            "Epoch 243/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8655\n",
            "Epoch 244/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8648\n",
            "Epoch 245/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8643\n",
            "Epoch 246/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8648\n",
            "Epoch 247/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8644\n",
            "Epoch 248/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8658\n",
            "Epoch 249/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8659\n",
            "Epoch 250/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8636\n",
            "Epoch 251/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8652\n",
            "Epoch 252/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8648\n",
            "Epoch 253/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8671\n",
            "Epoch 254/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8661\n",
            "Epoch 255/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8671\n",
            "Epoch 256/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8669\n",
            "Epoch 257/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8661\n",
            "Epoch 258/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8659\n",
            "Epoch 259/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8652\n",
            "Epoch 260/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8644\n",
            "Epoch 261/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8645\n",
            "Epoch 262/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8668\n",
            "Epoch 263/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8652\n",
            "Epoch 264/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8646\n",
            "Epoch 265/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8660\n",
            "Epoch 266/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 267/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8651\n",
            "Epoch 268/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8666\n",
            "Epoch 269/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8666\n",
            "Epoch 270/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8654\n",
            "Epoch 271/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8651\n",
            "Epoch 272/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8674\n",
            "Epoch 273/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8649\n",
            "Epoch 274/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8646\n",
            "Epoch 275/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8656\n",
            "Epoch 276/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8658\n",
            "Epoch 277/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8654\n",
            "Epoch 278/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8652\n",
            "Epoch 279/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8664\n",
            "Epoch 280/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8652\n",
            "Epoch 281/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8658\n",
            "Epoch 282/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8633\n",
            "Epoch 283/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8655\n",
            "Epoch 284/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8651\n",
            "Epoch 285/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8654\n",
            "Epoch 286/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8650\n",
            "Epoch 287/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8648\n",
            "Epoch 288/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8651\n",
            "Epoch 289/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8649\n",
            "Epoch 290/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8654\n",
            "Epoch 291/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8654\n",
            "Epoch 292/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8651\n",
            "Epoch 293/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8656\n",
            "Epoch 294/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8651\n",
            "Epoch 295/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8659\n",
            "Epoch 296/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8659\n",
            "Epoch 297/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8651\n",
            "Epoch 298/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8650\n",
            "Epoch 299/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8648\n",
            "Epoch 300/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8655\n",
            "Epoch 301/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8654\n",
            "Epoch 302/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8655\n",
            "Epoch 303/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8649\n",
            "Epoch 304/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8650\n",
            "Epoch 305/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8661\n",
            "Epoch 306/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8655\n",
            "Epoch 307/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8649\n",
            "Epoch 308/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8652\n",
            "Epoch 309/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8652\n",
            "Epoch 310/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8650\n",
            "Epoch 311/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8645\n",
            "Epoch 312/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8651\n",
            "Epoch 313/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8648\n",
            "Epoch 314/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8666\n",
            "Epoch 315/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8651\n",
            "Epoch 316/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8662\n",
            "Epoch 317/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8660\n",
            "Epoch 318/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8661\n",
            "Epoch 319/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8660\n",
            "Epoch 320/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8651\n",
            "Epoch 321/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8658\n",
            "Epoch 322/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8651\n",
            "Epoch 323/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8649\n",
            "Epoch 324/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8661\n",
            "Epoch 325/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8655\n",
            "Epoch 326/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8659\n",
            "Epoch 327/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8655\n",
            "Epoch 328/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8654\n",
            "Epoch 329/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8655\n",
            "Epoch 330/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8659\n",
            "Epoch 331/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8650\n",
            "Epoch 332/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8636\n",
            "Epoch 333/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8662\n",
            "Epoch 334/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8661\n",
            "Epoch 335/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 336/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 337/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8635\n",
            "Epoch 338/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8669\n",
            "Epoch 339/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8658\n",
            "Epoch 340/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8658\n",
            "Epoch 341/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8650\n",
            "Epoch 342/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8648\n",
            "Epoch 343/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8655\n",
            "Epoch 344/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8643\n",
            "Epoch 345/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8650\n",
            "Epoch 346/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8661\n",
            "Epoch 347/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8659\n",
            "Epoch 348/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8644\n",
            "Epoch 349/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8665\n",
            "Epoch 350/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8660\n",
            "Epoch 351/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8648\n",
            "Epoch 352/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8666\n",
            "Epoch 353/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8646\n",
            "Epoch 354/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8659\n",
            "Epoch 355/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8661\n",
            "Epoch 356/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8646\n",
            "Epoch 357/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8660\n",
            "Epoch 358/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8639\n",
            "Epoch 359/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8648\n",
            "Epoch 360/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8656\n",
            "Epoch 361/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8640\n",
            "Epoch 362/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8661\n",
            "Epoch 363/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8662\n",
            "Epoch 364/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8650\n",
            "Epoch 365/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8664\n",
            "Epoch 366/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8656\n",
            "Epoch 367/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 368/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8652\n",
            "Epoch 369/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8662\n",
            "Epoch 370/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8660\n",
            "Epoch 371/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8659\n",
            "Epoch 372/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8655\n",
            "Epoch 373/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8659\n",
            "Epoch 374/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8665\n",
            "Epoch 375/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8643\n",
            "Epoch 376/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8648\n",
            "Epoch 377/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8659\n",
            "Epoch 378/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8659\n",
            "Epoch 379/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8636\n",
            "Epoch 380/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8649\n",
            "Epoch 381/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8656\n",
            "Epoch 382/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8637\n",
            "Epoch 383/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8675\n",
            "Epoch 384/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8640\n",
            "Epoch 385/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8661\n",
            "Epoch 386/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8649\n",
            "Epoch 387/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8662\n",
            "Epoch 388/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8656\n",
            "Epoch 389/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8652\n",
            "Epoch 390/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8649\n",
            "Epoch 391/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8666\n",
            "Epoch 392/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8668\n",
            "Epoch 393/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8664\n",
            "Epoch 394/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8649\n",
            "Epoch 395/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8652\n",
            "Epoch 396/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8655\n",
            "Epoch 397/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8654\n",
            "Epoch 398/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8646\n",
            "Epoch 399/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8679\n",
            "Epoch 400/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8661\n",
            "Epoch 401/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8659\n",
            "Epoch 402/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8655\n",
            "Epoch 403/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8650\n",
            "Epoch 404/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8639\n",
            "Epoch 405/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8655\n",
            "Epoch 406/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8666\n",
            "Epoch 407/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8651\n",
            "Epoch 408/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8656\n",
            "Epoch 409/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8670\n",
            "Epoch 410/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8659\n",
            "Epoch 411/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8652\n",
            "Epoch 412/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8649\n",
            "Epoch 413/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8658\n",
            "Epoch 414/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8652\n",
            "Epoch 415/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8649\n",
            "Epoch 416/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8664\n",
            "Epoch 417/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8656\n",
            "Epoch 418/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8648\n",
            "Epoch 419/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8669\n",
            "Epoch 420/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8650\n",
            "Epoch 421/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8665\n",
            "Epoch 422/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8668\n",
            "Epoch 423/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8650\n",
            "Epoch 424/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8656\n",
            "Epoch 425/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8670\n",
            "Epoch 426/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 427/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 428/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8656\n",
            "Epoch 429/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8651\n",
            "Epoch 430/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8665\n",
            "Epoch 431/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8645\n",
            "Epoch 432/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8662\n",
            "Epoch 433/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8660\n",
            "Epoch 434/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8639\n",
            "Epoch 435/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8652\n",
            "Epoch 436/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8652\n",
            "Epoch 437/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8656\n",
            "Epoch 438/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8649\n",
            "Epoch 439/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8656\n",
            "Epoch 440/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8660\n",
            "Epoch 441/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8675\n",
            "Epoch 442/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8668\n",
            "Epoch 443/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8658\n",
            "Epoch 444/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8661\n",
            "Epoch 445/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8649\n",
            "Epoch 446/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8655\n",
            "Epoch 447/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8654\n",
            "Epoch 448/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8654\n",
            "Epoch 449/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8671\n",
            "Epoch 450/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8650\n",
            "Epoch 451/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8661\n",
            "Epoch 452/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8651\n",
            "Epoch 453/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8662\n",
            "Epoch 454/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8652\n",
            "Epoch 455/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8665\n",
            "Epoch 456/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8659\n",
            "Epoch 457/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8659\n",
            "Epoch 458/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8662\n",
            "Epoch 459/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8652\n",
            "Epoch 460/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8658\n",
            "Epoch 461/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8666\n",
            "Epoch 462/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8668\n",
            "Epoch 463/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8656\n",
            "Epoch 464/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8664\n",
            "Epoch 465/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8639\n",
            "Epoch 466/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8661\n",
            "Epoch 467/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8656\n",
            "Epoch 468/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8661\n",
            "Epoch 469/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8649\n",
            "Epoch 470/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8658\n",
            "Epoch 471/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8661\n",
            "Epoch 472/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8656\n",
            "Epoch 473/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8656\n",
            "Epoch 474/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8654\n",
            "Epoch 475/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8655\n",
            "Epoch 476/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8656\n",
            "Epoch 477/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8651\n",
            "Epoch 478/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8671\n",
            "Epoch 479/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8654\n",
            "Epoch 480/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8662\n",
            "Epoch 481/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8655\n",
            "Epoch 482/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8659\n",
            "Epoch 483/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8668\n",
            "Epoch 484/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8662\n",
            "Epoch 485/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8649\n",
            "Epoch 486/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8656\n",
            "Epoch 487/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8662\n",
            "Epoch 488/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8652\n",
            "Epoch 489/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8668\n",
            "Epoch 490/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8644\n",
            "Epoch 491/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8646\n",
            "Epoch 492/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8670\n",
            "Epoch 493/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8656\n",
            "Epoch 494/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8656\n",
            "Epoch 495/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8646\n",
            "Epoch 496/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8659\n",
            "Epoch 497/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 498/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8655\n",
            "Epoch 499/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8649\n",
            "Epoch 500/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa2ca46d8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of 3 observation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns.For Male you should encode as '1' and for Female '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "**Assignment**\n",
        "\n",
        "Use our ANN model to predict if the customers with the following informations will leave the bank: \n",
        "\n",
        "Geography: France,Germany,Spain\n",
        "\n",
        "Credit Score: 600,800,700\n",
        "\n",
        "Gender: Male,Female,Male\n",
        "\n",
        "Age: 40,50,35,years old\n",
        "\n",
        "Tenure: 3,5,4 years\n",
        "\n",
        "Balance: \\$ 60000,70000,0\n",
        "\n",
        "Number of Products: 2,1,0\n",
        "\n",
        "Does this customer have a credit card ? Yes,No,No\n",
        "\n",
        "Is this customer an Active Member: Yes,No,No\n",
        "\n",
        "Estimated Salary: \\$ 50000,10000,0\n",
        "\n",
        "So, should we say goodbye to that customer ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "Sample \n",
        "If value is greater than 0.5 - True  \n",
        "Else -False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-15JL842dxWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d093114c-2296-4c93-ae4e-7e549c755875"
      },
      "source": [
        "print(ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]])) > 0.5)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBHeG0Pwafvt",
        "outputId": "82ce307b-997a-4e76-8399-82d946044380"
      },
      "source": [
        "ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0261786]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opk6uV7JjjW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43028df-e3ed-4f53-bf82-94eb23ebcbd4"
      },
      "source": [
        "print(ann.predict(sc.transform([[0,1,0,800,0,50,5,70000,1,0,0,10000]])) > 0.5)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGAYIx4Zjjgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d88957d-98db-4b06-8dc1-d66a1800a59a"
      },
      "source": [
        "print(ann.predict(sc.transform([[0,0,1,700,1,35,4,0,0,0,0,0]])) > 0.5)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCw4m5bCjkKt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyEeQdRZwgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed0f3e4-5e71-4ebb-fb63-b19a4124b71b"
      },
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjvfa5SBe-eP",
        "outputId": "9a9d1e75-4ca2-44c6-e0ba-388ec7ba34fa"
      },
      "source": [
        "y_pred[0:10]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KcgCBWbX89C",
        "outputId": "4eda1089-3679-4a03-dd76-af6093dab8a3"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6K_r6LaF6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d827540-a88c-421d-8893-056ad5fc5307"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1519   76]\n",
            " [ 207  198]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ut3uyxlOqs",
        "outputId": "4ced9d5b-ffb3-4411-f0c3-fda7eb0b66dc"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8585"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "qSRSEMXDjmI2",
        "outputId": "7c9a2bfb-2039-493f-b288-65eb78465e1f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "LABELS = ['Not Left Bank', 'Left Bank'] \n",
        "plt.figure(figsize =(8, 8)) \n",
        "sns.heatmap(cm, xticklabels = LABELS,  \n",
        "            yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
        "plt.title(\"Confusion matrix\") \n",
        "plt.ylabel('True class') \n",
        "plt.xlabel('Predicted class') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ijy_fUxk-Ga"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}