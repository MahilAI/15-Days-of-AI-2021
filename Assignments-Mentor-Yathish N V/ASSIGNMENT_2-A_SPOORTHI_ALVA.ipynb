{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxosQ5cQtRK4"
      },
      "source": [
        "**Artificial Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Az6luWtUDc"
      },
      "source": [
        "**Importing the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44qFD-evtaQI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "tINv2-dntehz",
        "outputId": "be464cbc-7327-46bf-e0d7-fbcde9a3f769"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e688f8ef-c07f-4806-9690-d689e7ab117f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e688f8ef-c07f-4806-9690-d689e7ab117f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Churn_Modelling.csv to Churn_Modelling.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA3maDIOtvhD"
      },
      "source": [
        "**Part 1 - Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-y9SLnDzgtB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7du2VNe4tyLe"
      },
      "source": [
        "\n",
        "\n",
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuVPJS3Vt4lm",
        "outputId": "9b678b98-445c-4f52-b356-4a0aed857432"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZnPnwLlt8em",
        "outputId": "e375bcea-0f20-4185-e1f7-addf4c043369"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "B0E0DE7rt_kG",
        "outputId": "feb6c1b1-ec38-483d-d85c-ca83864774e3"
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>15574012</td>\n",
              "      <td>Chu</td>\n",
              "      <td>645</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>8</td>\n",
              "      <td>113755.78</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>149756.71</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>15592531</td>\n",
              "      <td>Bartlett</td>\n",
              "      <td>822</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>50</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10062.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>15656148</td>\n",
              "      <td>Obinna</td>\n",
              "      <td>376</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Female</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>115046.74</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>119346.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>15792365</td>\n",
              "      <td>He</td>\n",
              "      <td>501</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>142051.07</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74940.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>15592389</td>\n",
              "      <td>H?</td>\n",
              "      <td>684</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>134603.88</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>71725.73</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "5          6    15574012       Chu  ...               0       149756.71      1\n",
              "6          7    15592531  Bartlett  ...               1        10062.80      0\n",
              "7          8    15656148    Obinna  ...               0       119346.88      1\n",
              "8          9    15792365        He  ...               1        74940.50      0\n",
              "9         10    15592389        H?  ...               1        71725.73      0\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Um8zSgRuJKp"
      },
      "source": [
        "**Encoding categorical data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uremlpVBuR-_"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDupJGFyuOV-"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbflMqyMuCoo",
        "outputId": "1101709d-fa46-4c20-f834-93406fcea769"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EywEkNKOuZiV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_uuh4g6uezi"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Sig5ufugWS"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6Et2x1tu6kw",
        "outputId": "95f7b605-f21f-41e5-9d6f-09f5031fc0e9"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2zaOvKWu-6w",
        "outputId": "fe65ad53-06d6-478a-9ee1-d90382d3a766"
      },
      "source": [
        "print(X[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0 0.0 0.0 619 0 42 2 0.0 1 1 1 101348.88]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTsDg4mqvBkr",
        "outputId": "3060673d-9ae8-4208-a7c1-b638628a124e"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK10Lrz1vEgU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw8ECOwsvHFi"
      },
      "source": [
        "Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV7ZN7fpvIKL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4drQscAvNdu"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LXL6PeQvRg4",
        "outputId": "c12ee1ae-025b-4ee0-83ce-ac09d7114d1e"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.01460667 -0.5698444   1.74309049  0.16958176 -1.09168714 -0.46460796\n",
            "  0.00666099 -1.21571749  0.8095029   0.64259497 -1.03227043  1.10643166]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u-iKgG9vbyh"
      },
      "source": [
        "\n",
        "**Part 2 - Building the ANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrzlDfzvvj-l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmf1XZQKvn6P"
      },
      "source": [
        "Initializing the ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hr761nCv0sv"
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrfrvG8vvpeO"
      },
      "source": [
        "Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imnwKA75v52A"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyqpIYGSvtj2"
      },
      "source": [
        "Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oCCUapvv9o1"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLXW-A-ovws2"
      },
      "source": [
        "Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Hk_Zzuv-_Z"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SygUP_pSwHzc"
      },
      "source": [
        "**Part 3 - Training the ANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWGKd-3jwKeS"
      },
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQmrlU1wORv"
      },
      "source": [
        "Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tIJRgYCwV1C",
        "outputId": "03e6a368-1e2e-490a-f757-f3f7b0d96446"
      },
      "source": [
        "#train on 100,500,1000 epochs\n",
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 910us/step - loss: 0.5539 - accuracy: 0.7653\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 889us/step - loss: 0.4687 - accuracy: 0.7974\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 855us/step - loss: 0.4417 - accuracy: 0.8009\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 853us/step - loss: 0.4262 - accuracy: 0.8111\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 889us/step - loss: 0.4161 - accuracy: 0.8164\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 851us/step - loss: 0.4080 - accuracy: 0.8179\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3994 - accuracy: 0.8236\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 870us/step - loss: 0.3905 - accuracy: 0.8321\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3823 - accuracy: 0.8364\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 865us/step - loss: 0.3760 - accuracy: 0.8395\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 866us/step - loss: 0.3714 - accuracy: 0.8435\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 857us/step - loss: 0.3672 - accuracy: 0.8465\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 871us/step - loss: 0.3649 - accuracy: 0.8476\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3624 - accuracy: 0.8476\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3609 - accuracy: 0.8472\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3598 - accuracy: 0.8495\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3582 - accuracy: 0.8509\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 858us/step - loss: 0.3567 - accuracy: 0.8516\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8544\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 984us/step - loss: 0.3546 - accuracy: 0.8520\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 858us/step - loss: 0.3531 - accuracy: 0.8546\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3520 - accuracy: 0.8545\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 864us/step - loss: 0.3510 - accuracy: 0.8547\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 803us/step - loss: 0.3501 - accuracy: 0.8566\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 803us/step - loss: 0.3492 - accuracy: 0.8568\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 804us/step - loss: 0.3482 - accuracy: 0.8581\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 853us/step - loss: 0.3475 - accuracy: 0.8565\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 862us/step - loss: 0.3466 - accuracy: 0.8597\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 882us/step - loss: 0.3460 - accuracy: 0.8587\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3457 - accuracy: 0.8593\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 845us/step - loss: 0.3451 - accuracy: 0.8600\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 858us/step - loss: 0.3444 - accuracy: 0.8612\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 858us/step - loss: 0.3442 - accuracy: 0.8596\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 858us/step - loss: 0.3435 - accuracy: 0.8614\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 890us/step - loss: 0.3432 - accuracy: 0.8608\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3426 - accuracy: 0.8615\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 870us/step - loss: 0.3424 - accuracy: 0.8611\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 834us/step - loss: 0.3424 - accuracy: 0.8605\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 884us/step - loss: 0.3420 - accuracy: 0.8609\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 884us/step - loss: 0.3418 - accuracy: 0.8601\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 836us/step - loss: 0.3415 - accuracy: 0.8618\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 891us/step - loss: 0.3413 - accuracy: 0.8621\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3411 - accuracy: 0.8612\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3406 - accuracy: 0.8611\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 856us/step - loss: 0.3404 - accuracy: 0.8610\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 848us/step - loss: 0.3403 - accuracy: 0.8611\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 890us/step - loss: 0.3400 - accuracy: 0.8611\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 867us/step - loss: 0.3399 - accuracy: 0.8616\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 888us/step - loss: 0.3395 - accuracy: 0.8616\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 880us/step - loss: 0.3392 - accuracy: 0.8614\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 910us/step - loss: 0.3393 - accuracy: 0.8619\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 866us/step - loss: 0.3389 - accuracy: 0.8634\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 883us/step - loss: 0.3389 - accuracy: 0.8610\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 847us/step - loss: 0.3382 - accuracy: 0.8618\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 891us/step - loss: 0.3382 - accuracy: 0.8619\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 799us/step - loss: 0.3378 - accuracy: 0.8624\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3381 - accuracy: 0.8625\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 878us/step - loss: 0.3375 - accuracy: 0.8641\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3375 - accuracy: 0.8629\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 856us/step - loss: 0.3371 - accuracy: 0.8621\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3372 - accuracy: 0.8630\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 874us/step - loss: 0.3372 - accuracy: 0.8618\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 898us/step - loss: 0.3370 - accuracy: 0.8620\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 881us/step - loss: 0.3369 - accuracy: 0.8625\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 891us/step - loss: 0.3368 - accuracy: 0.8641\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 914us/step - loss: 0.3367 - accuracy: 0.8633\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 896us/step - loss: 0.3367 - accuracy: 0.8627\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 870us/step - loss: 0.3365 - accuracy: 0.8633\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 894us/step - loss: 0.3360 - accuracy: 0.8627\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 869us/step - loss: 0.3365 - accuracy: 0.8627\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 891us/step - loss: 0.3364 - accuracy: 0.8641\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3360 - accuracy: 0.8630\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 891us/step - loss: 0.3359 - accuracy: 0.8625\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3362 - accuracy: 0.8640\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3358 - accuracy: 0.8641\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3355 - accuracy: 0.8629\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3358 - accuracy: 0.8620\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 802us/step - loss: 0.3356 - accuracy: 0.8631\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3356 - accuracy: 0.8627\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3357 - accuracy: 0.8635\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 849us/step - loss: 0.3353 - accuracy: 0.8637\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 894us/step - loss: 0.3352 - accuracy: 0.8645\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 900us/step - loss: 0.3353 - accuracy: 0.8648\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 904us/step - loss: 0.3351 - accuracy: 0.8645\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 800us/step - loss: 0.3346 - accuracy: 0.8641\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 942us/step - loss: 0.3350 - accuracy: 0.8627\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3349 - accuracy: 0.8644\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 855us/step - loss: 0.3350 - accuracy: 0.8640\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 874us/step - loss: 0.3347 - accuracy: 0.8644\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 857us/step - loss: 0.3345 - accuracy: 0.8645\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3346 - accuracy: 0.8634\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 889us/step - loss: 0.3346 - accuracy: 0.8640\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 874us/step - loss: 0.3347 - accuracy: 0.8644\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 849us/step - loss: 0.3342 - accuracy: 0.8650\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3339 - accuracy: 0.8635\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 894us/step - loss: 0.3343 - accuracy: 0.8654\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 888us/step - loss: 0.3342 - accuracy: 0.8639\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 890us/step - loss: 0.3339 - accuracy: 0.8641\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3339 - accuracy: 0.8645\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 889us/step - loss: 0.3339 - accuracy: 0.8626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f703473df90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bT_O-sjzu89",
        "outputId": "76984cf0-b47f-4ee6-e840-d6a8cd2f263e"
      },
      "source": [
        "#train on 100,500,1000 epochs\n",
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 1000)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "250/250 [==============================] - 0s 942us/step - loss: 0.3340 - accuracy: 0.8652\n",
            "Epoch 2/1000\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.3333 - accuracy: 0.8648\n",
            "Epoch 3/1000\n",
            "250/250 [==============================] - 0s 904us/step - loss: 0.3343 - accuracy: 0.8640\n",
            "Epoch 4/1000\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3335 - accuracy: 0.8646\n",
            "Epoch 5/1000\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3338 - accuracy: 0.8636\n",
            "Epoch 6/1000\n",
            "250/250 [==============================] - 0s 890us/step - loss: 0.3339 - accuracy: 0.8635\n",
            "Epoch 7/1000\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.3336 - accuracy: 0.8650\n",
            "Epoch 8/1000\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3336 - accuracy: 0.8635\n",
            "Epoch 9/1000\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3336 - accuracy: 0.8636\n",
            "Epoch 10/1000\n",
            "250/250 [==============================] - 0s 903us/step - loss: 0.3334 - accuracy: 0.8648\n",
            "Epoch 11/1000\n",
            "250/250 [==============================] - 0s 903us/step - loss: 0.3333 - accuracy: 0.8637\n",
            "Epoch 12/1000\n",
            "250/250 [==============================] - 0s 975us/step - loss: 0.3331 - accuracy: 0.8649\n",
            "Epoch 13/1000\n",
            "250/250 [==============================] - 0s 893us/step - loss: 0.3330 - accuracy: 0.8654\n",
            "Epoch 14/1000\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3334 - accuracy: 0.8659\n",
            "Epoch 15/1000\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3332 - accuracy: 0.8640\n",
            "Epoch 16/1000\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3331 - accuracy: 0.8635\n",
            "Epoch 17/1000\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3330 - accuracy: 0.8635\n",
            "Epoch 18/1000\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3331 - accuracy: 0.8643\n",
            "Epoch 19/1000\n",
            "250/250 [==============================] - 0s 897us/step - loss: 0.3329 - accuracy: 0.8643\n",
            "Epoch 20/1000\n",
            "250/250 [==============================] - 0s 842us/step - loss: 0.3330 - accuracy: 0.8625\n",
            "Epoch 21/1000\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3330 - accuracy: 0.8643\n",
            "Epoch 22/1000\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3328 - accuracy: 0.8649\n",
            "Epoch 23/1000\n",
            "250/250 [==============================] - 0s 890us/step - loss: 0.3328 - accuracy: 0.8644\n",
            "Epoch 24/1000\n",
            "250/250 [==============================] - 0s 873us/step - loss: 0.3328 - accuracy: 0.8645\n",
            "Epoch 25/1000\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3327 - accuracy: 0.8643\n",
            "Epoch 26/1000\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3329 - accuracy: 0.8649\n",
            "Epoch 27/1000\n",
            "250/250 [==============================] - 0s 874us/step - loss: 0.3323 - accuracy: 0.8644\n",
            "Epoch 28/1000\n",
            "250/250 [==============================] - 0s 902us/step - loss: 0.3329 - accuracy: 0.8644\n",
            "Epoch 29/1000\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3325 - accuracy: 0.8640\n",
            "Epoch 30/1000\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3324 - accuracy: 0.8650\n",
            "Epoch 31/1000\n",
            "250/250 [==============================] - 0s 914us/step - loss: 0.3325 - accuracy: 0.8631\n",
            "Epoch 32/1000\n",
            "250/250 [==============================] - 0s 840us/step - loss: 0.3320 - accuracy: 0.8644\n",
            "Epoch 33/1000\n",
            "250/250 [==============================] - 0s 883us/step - loss: 0.3325 - accuracy: 0.8644\n",
            "Epoch 34/1000\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3323 - accuracy: 0.8648\n",
            "Epoch 35/1000\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3318 - accuracy: 0.8630\n",
            "Epoch 36/1000\n",
            "250/250 [==============================] - 0s 887us/step - loss: 0.3321 - accuracy: 0.8644\n",
            "Epoch 37/1000\n",
            "250/250 [==============================] - 0s 817us/step - loss: 0.3318 - accuracy: 0.8651\n",
            "Epoch 38/1000\n",
            "250/250 [==============================] - 0s 903us/step - loss: 0.3323 - accuracy: 0.8656\n",
            "Epoch 39/1000\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3317 - accuracy: 0.8651\n",
            "Epoch 40/1000\n",
            "250/250 [==============================] - 0s 900us/step - loss: 0.3322 - accuracy: 0.8645\n",
            "Epoch 41/1000\n",
            "250/250 [==============================] - 0s 839us/step - loss: 0.3318 - accuracy: 0.8643\n",
            "Epoch 42/1000\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3316 - accuracy: 0.8637\n",
            "Epoch 43/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8651\n",
            "Epoch 44/1000\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3315 - accuracy: 0.8651\n",
            "Epoch 45/1000\n",
            "250/250 [==============================] - 0s 904us/step - loss: 0.3314 - accuracy: 0.8639\n",
            "Epoch 46/1000\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3319 - accuracy: 0.8650\n",
            "Epoch 47/1000\n",
            "250/250 [==============================] - 0s 878us/step - loss: 0.3317 - accuracy: 0.8655\n",
            "Epoch 48/1000\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3315 - accuracy: 0.8664\n",
            "Epoch 49/1000\n",
            "250/250 [==============================] - 0s 853us/step - loss: 0.3315 - accuracy: 0.8633\n",
            "Epoch 50/1000\n",
            "250/250 [==============================] - 0s 848us/step - loss: 0.3315 - accuracy: 0.8656\n",
            "Epoch 51/1000\n",
            "250/250 [==============================] - 0s 897us/step - loss: 0.3312 - accuracy: 0.8636\n",
            "Epoch 52/1000\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3310 - accuracy: 0.8652\n",
            "Epoch 53/1000\n",
            "250/250 [==============================] - 0s 887us/step - loss: 0.3312 - accuracy: 0.8631\n",
            "Epoch 54/1000\n",
            "250/250 [==============================] - 0s 848us/step - loss: 0.3312 - accuracy: 0.8658\n",
            "Epoch 55/1000\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3310 - accuracy: 0.8646\n",
            "Epoch 56/1000\n",
            "250/250 [==============================] - 0s 903us/step - loss: 0.3312 - accuracy: 0.8661\n",
            "Epoch 57/1000\n",
            "250/250 [==============================] - 0s 879us/step - loss: 0.3313 - accuracy: 0.8654\n",
            "Epoch 58/1000\n",
            "250/250 [==============================] - 0s 864us/step - loss: 0.3311 - accuracy: 0.8648\n",
            "Epoch 59/1000\n",
            "250/250 [==============================] - 0s 897us/step - loss: 0.3312 - accuracy: 0.8641\n",
            "Epoch 60/1000\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3313 - accuracy: 0.8658\n",
            "Epoch 61/1000\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3309 - accuracy: 0.8645\n",
            "Epoch 62/1000\n",
            "250/250 [==============================] - 0s 895us/step - loss: 0.3313 - accuracy: 0.8651\n",
            "Epoch 63/1000\n",
            "250/250 [==============================] - 0s 859us/step - loss: 0.3310 - accuracy: 0.8643\n",
            "Epoch 64/1000\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.3309 - accuracy: 0.8643\n",
            "Epoch 65/1000\n",
            "250/250 [==============================] - 0s 979us/step - loss: 0.3311 - accuracy: 0.8656\n",
            "Epoch 66/1000\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3310 - accuracy: 0.8646\n",
            "Epoch 67/1000\n",
            "250/250 [==============================] - 0s 882us/step - loss: 0.3306 - accuracy: 0.8652\n",
            "Epoch 68/1000\n",
            "250/250 [==============================] - 0s 853us/step - loss: 0.3308 - accuracy: 0.8652\n",
            "Epoch 69/1000\n",
            "250/250 [==============================] - 0s 900us/step - loss: 0.3310 - accuracy: 0.8646\n",
            "Epoch 70/1000\n",
            "250/250 [==============================] - 0s 895us/step - loss: 0.3310 - accuracy: 0.8649\n",
            "Epoch 71/1000\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3307 - accuracy: 0.8646\n",
            "Epoch 72/1000\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3309 - accuracy: 0.8637\n",
            "Epoch 73/1000\n",
            "250/250 [==============================] - 0s 902us/step - loss: 0.3306 - accuracy: 0.8639\n",
            "Epoch 74/1000\n",
            "250/250 [==============================] - 0s 868us/step - loss: 0.3308 - accuracy: 0.8652\n",
            "Epoch 75/1000\n",
            "250/250 [==============================] - 0s 900us/step - loss: 0.3304 - accuracy: 0.8644\n",
            "Epoch 76/1000\n",
            "250/250 [==============================] - 0s 889us/step - loss: 0.3307 - accuracy: 0.8646\n",
            "Epoch 77/1000\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3307 - accuracy: 0.8640\n",
            "Epoch 78/1000\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3306 - accuracy: 0.8650\n",
            "Epoch 79/1000\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3305 - accuracy: 0.8646\n",
            "Epoch 80/1000\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3304 - accuracy: 0.8641\n",
            "Epoch 81/1000\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3307 - accuracy: 0.8655\n",
            "Epoch 82/1000\n",
            "250/250 [==============================] - 0s 885us/step - loss: 0.3304 - accuracy: 0.8656\n",
            "Epoch 83/1000\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3307 - accuracy: 0.8645\n",
            "Epoch 84/1000\n",
            "250/250 [==============================] - 0s 877us/step - loss: 0.3308 - accuracy: 0.8649\n",
            "Epoch 85/1000\n",
            "250/250 [==============================] - 0s 861us/step - loss: 0.3303 - accuracy: 0.8643\n",
            "Epoch 86/1000\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.3307 - accuracy: 0.8646\n",
            "Epoch 87/1000\n",
            "250/250 [==============================] - 0s 928us/step - loss: 0.3303 - accuracy: 0.8644\n",
            "Epoch 88/1000\n",
            "250/250 [==============================] - 0s 897us/step - loss: 0.3300 - accuracy: 0.8660\n",
            "Epoch 89/1000\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3308 - accuracy: 0.8646\n",
            "Epoch 90/1000\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3304 - accuracy: 0.8652\n",
            "Epoch 91/1000\n",
            "250/250 [==============================] - 0s 964us/step - loss: 0.3304 - accuracy: 0.8654\n",
            "Epoch 92/1000\n",
            "250/250 [==============================] - 0s 903us/step - loss: 0.3303 - accuracy: 0.8655\n",
            "Epoch 93/1000\n",
            "250/250 [==============================] - 0s 867us/step - loss: 0.3302 - accuracy: 0.8652\n",
            "Epoch 94/1000\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3301 - accuracy: 0.8641\n",
            "Epoch 95/1000\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3301 - accuracy: 0.8666\n",
            "Epoch 96/1000\n",
            "250/250 [==============================] - 0s 850us/step - loss: 0.3305 - accuracy: 0.8652\n",
            "Epoch 97/1000\n",
            "250/250 [==============================] - 0s 892us/step - loss: 0.3301 - accuracy: 0.8644\n",
            "Epoch 98/1000\n",
            "250/250 [==============================] - 0s 889us/step - loss: 0.3302 - accuracy: 0.8650\n",
            "Epoch 99/1000\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3299 - accuracy: 0.8651\n",
            "Epoch 100/1000\n",
            "250/250 [==============================] - 0s 897us/step - loss: 0.3304 - accuracy: 0.8645\n",
            "Epoch 101/1000\n",
            "250/250 [==============================] - 0s 1000us/step - loss: 0.3301 - accuracy: 0.8656\n",
            "Epoch 102/1000\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3300 - accuracy: 0.8654\n",
            "Epoch 103/1000\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3300 - accuracy: 0.8650\n",
            "Epoch 104/1000\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3303 - accuracy: 0.8641\n",
            "Epoch 105/1000\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3304 - accuracy: 0.8649\n",
            "Epoch 106/1000\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3299 - accuracy: 0.8656\n",
            "Epoch 107/1000\n",
            "250/250 [==============================] - 0s 901us/step - loss: 0.3302 - accuracy: 0.8651\n",
            "Epoch 108/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8655\n",
            "Epoch 109/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8660\n",
            "Epoch 110/1000\n",
            "250/250 [==============================] - 0s 992us/step - loss: 0.3300 - accuracy: 0.8661\n",
            "Epoch 111/1000\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3299 - accuracy: 0.8660\n",
            "Epoch 112/1000\n",
            "250/250 [==============================] - 0s 887us/step - loss: 0.3300 - accuracy: 0.8649\n",
            "Epoch 113/1000\n",
            "250/250 [==============================] - 0s 874us/step - loss: 0.3303 - accuracy: 0.8654\n",
            "Epoch 114/1000\n",
            "250/250 [==============================] - 0s 858us/step - loss: 0.3298 - accuracy: 0.8666\n",
            "Epoch 115/1000\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3299 - accuracy: 0.8652\n",
            "Epoch 116/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8658\n",
            "Epoch 117/1000\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3299 - accuracy: 0.8655\n",
            "Epoch 118/1000\n",
            "250/250 [==============================] - 0s 953us/step - loss: 0.3299 - accuracy: 0.8646\n",
            "Epoch 119/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8661\n",
            "Epoch 120/1000\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3296 - accuracy: 0.8649\n",
            "Epoch 121/1000\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3298 - accuracy: 0.8652\n",
            "Epoch 122/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8651\n",
            "Epoch 123/1000\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3299 - accuracy: 0.8648\n",
            "Epoch 124/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8655\n",
            "Epoch 125/1000\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3300 - accuracy: 0.8654\n",
            "Epoch 126/1000\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3295 - accuracy: 0.8649\n",
            "Epoch 127/1000\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3296 - accuracy: 0.8669\n",
            "Epoch 128/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8646\n",
            "Epoch 129/1000\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3296 - accuracy: 0.8660\n",
            "Epoch 130/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8666\n",
            "Epoch 131/1000\n",
            "250/250 [==============================] - 0s 953us/step - loss: 0.3298 - accuracy: 0.8646\n",
            "Epoch 132/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8652\n",
            "Epoch 133/1000\n",
            "250/250 [==============================] - 0s 976us/step - loss: 0.3295 - accuracy: 0.8660\n",
            "Epoch 134/1000\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3298 - accuracy: 0.8651\n",
            "Epoch 135/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8658\n",
            "Epoch 136/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8651\n",
            "Epoch 137/1000\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3296 - accuracy: 0.8649\n",
            "Epoch 138/1000\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3296 - accuracy: 0.8633\n",
            "Epoch 139/1000\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.3296 - accuracy: 0.8649\n",
            "Epoch 140/1000\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3297 - accuracy: 0.8645\n",
            "Epoch 141/1000\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3293 - accuracy: 0.8660\n",
            "Epoch 142/1000\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3298 - accuracy: 0.8654\n",
            "Epoch 143/1000\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3295 - accuracy: 0.8646\n",
            "Epoch 144/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8661\n",
            "Epoch 145/1000\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3297 - accuracy: 0.8651\n",
            "Epoch 146/1000\n",
            "250/250 [==============================] - 0s 997us/step - loss: 0.3298 - accuracy: 0.8651\n",
            "Epoch 147/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8650\n",
            "Epoch 148/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8660\n",
            "Epoch 149/1000\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3297 - accuracy: 0.8652\n",
            "Epoch 150/1000\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3297 - accuracy: 0.8655\n",
            "Epoch 151/1000\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3292 - accuracy: 0.8652\n",
            "Epoch 152/1000\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3302 - accuracy: 0.8658\n",
            "Epoch 153/1000\n",
            "250/250 [==============================] - 0s 879us/step - loss: 0.3295 - accuracy: 0.8644\n",
            "Epoch 154/1000\n",
            "250/250 [==============================] - 0s 976us/step - loss: 0.3296 - accuracy: 0.8636\n",
            "Epoch 155/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8651\n",
            "Epoch 156/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8646\n",
            "Epoch 157/1000\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3294 - accuracy: 0.8650\n",
            "Epoch 158/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8645\n",
            "Epoch 159/1000\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3295 - accuracy: 0.8656\n",
            "Epoch 160/1000\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3296 - accuracy: 0.8662\n",
            "Epoch 161/1000\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3295 - accuracy: 0.8652\n",
            "Epoch 162/1000\n",
            "250/250 [==============================] - 0s 842us/step - loss: 0.3296 - accuracy: 0.8641\n",
            "Epoch 163/1000\n",
            "250/250 [==============================] - 0s 868us/step - loss: 0.3296 - accuracy: 0.8641\n",
            "Epoch 164/1000\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3295 - accuracy: 0.8650\n",
            "Epoch 165/1000\n",
            "250/250 [==============================] - 0s 877us/step - loss: 0.3293 - accuracy: 0.8649\n",
            "Epoch 166/1000\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3298 - accuracy: 0.8651\n",
            "Epoch 167/1000\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3296 - accuracy: 0.8664\n",
            "Epoch 168/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8660\n",
            "Epoch 169/1000\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3299 - accuracy: 0.8671\n",
            "Epoch 170/1000\n",
            "250/250 [==============================] - 0s 910us/step - loss: 0.3294 - accuracy: 0.8654\n",
            "Epoch 171/1000\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3296 - accuracy: 0.8658\n",
            "Epoch 172/1000\n",
            "250/250 [==============================] - 0s 876us/step - loss: 0.3294 - accuracy: 0.8643\n",
            "Epoch 173/1000\n",
            "250/250 [==============================] - 0s 884us/step - loss: 0.3293 - accuracy: 0.8650\n",
            "Epoch 174/1000\n",
            "250/250 [==============================] - 0s 897us/step - loss: 0.3295 - accuracy: 0.8639\n",
            "Epoch 175/1000\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3295 - accuracy: 0.8654\n",
            "Epoch 176/1000\n",
            "250/250 [==============================] - 0s 893us/step - loss: 0.3294 - accuracy: 0.8643\n",
            "Epoch 177/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8655\n",
            "Epoch 178/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8648\n",
            "Epoch 179/1000\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3295 - accuracy: 0.8652\n",
            "Epoch 180/1000\n",
            "250/250 [==============================] - 0s 964us/step - loss: 0.3298 - accuracy: 0.8655\n",
            "Epoch 181/1000\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3294 - accuracy: 0.8659\n",
            "Epoch 182/1000\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3295 - accuracy: 0.8650\n",
            "Epoch 183/1000\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3298 - accuracy: 0.8646\n",
            "Epoch 184/1000\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3295 - accuracy: 0.8635\n",
            "Epoch 185/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8654\n",
            "Epoch 186/1000\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3293 - accuracy: 0.8651\n",
            "Epoch 187/1000\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3294 - accuracy: 0.8651\n",
            "Epoch 188/1000\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3298 - accuracy: 0.8661\n",
            "Epoch 189/1000\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3297 - accuracy: 0.8658\n",
            "Epoch 190/1000\n",
            "250/250 [==============================] - 0s 887us/step - loss: 0.3297 - accuracy: 0.8648\n",
            "Epoch 191/1000\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3295 - accuracy: 0.8652\n",
            "Epoch 192/1000\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3298 - accuracy: 0.8661\n",
            "Epoch 193/1000\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3291 - accuracy: 0.8639\n",
            "Epoch 194/1000\n",
            "250/250 [==============================] - 0s 891us/step - loss: 0.3297 - accuracy: 0.8656\n",
            "Epoch 195/1000\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3294 - accuracy: 0.8643\n",
            "Epoch 196/1000\n",
            "250/250 [==============================] - 0s 844us/step - loss: 0.3294 - accuracy: 0.8659\n",
            "Epoch 197/1000\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3296 - accuracy: 0.8652\n",
            "Epoch 198/1000\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3295 - accuracy: 0.8648\n",
            "Epoch 199/1000\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3294 - accuracy: 0.8656\n",
            "Epoch 200/1000\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3295 - accuracy: 0.8659\n",
            "Epoch 201/1000\n",
            "250/250 [==============================] - 0s 903us/step - loss: 0.3298 - accuracy: 0.8655\n",
            "Epoch 202/1000\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3297 - accuracy: 0.8639\n",
            "Epoch 203/1000\n",
            "250/250 [==============================] - 0s 881us/step - loss: 0.3294 - accuracy: 0.8648\n",
            "Epoch 204/1000\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3296 - accuracy: 0.8649\n",
            "Epoch 205/1000\n",
            "250/250 [==============================] - 0s 885us/step - loss: 0.3297 - accuracy: 0.8655\n",
            "Epoch 206/1000\n",
            "250/250 [==============================] - 0s 914us/step - loss: 0.3295 - accuracy: 0.8644\n",
            "Epoch 207/1000\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3294 - accuracy: 0.8652\n",
            "Epoch 208/1000\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3294 - accuracy: 0.8658\n",
            "Epoch 209/1000\n",
            "250/250 [==============================] - 0s 858us/step - loss: 0.3294 - accuracy: 0.8656\n",
            "Epoch 210/1000\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3294 - accuracy: 0.8646\n",
            "Epoch 211/1000\n",
            "250/250 [==============================] - 0s 866us/step - loss: 0.3293 - accuracy: 0.8650\n",
            "Epoch 212/1000\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3299 - accuracy: 0.8651\n",
            "Epoch 213/1000\n",
            "250/250 [==============================] - 0s 879us/step - loss: 0.3294 - accuracy: 0.8643\n",
            "Epoch 214/1000\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.3294 - accuracy: 0.8655\n",
            "Epoch 215/1000\n",
            "250/250 [==============================] - 0s 898us/step - loss: 0.3285 - accuracy: 0.8650\n",
            "Epoch 216/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8648\n",
            "Epoch 217/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8648\n",
            "Epoch 218/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8661\n",
            "Epoch 219/1000\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3292 - accuracy: 0.8665\n",
            "Epoch 220/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8660\n",
            "Epoch 221/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8655\n",
            "Epoch 222/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8654\n",
            "Epoch 223/1000\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3293 - accuracy: 0.8651\n",
            "Epoch 224/1000\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3295 - accuracy: 0.8655\n",
            "Epoch 225/1000\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3293 - accuracy: 0.8651\n",
            "Epoch 226/1000\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3295 - accuracy: 0.8644\n",
            "Epoch 227/1000\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3294 - accuracy: 0.8654\n",
            "Epoch 228/1000\n",
            "250/250 [==============================] - 0s 897us/step - loss: 0.3297 - accuracy: 0.8651\n",
            "Epoch 229/1000\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3292 - accuracy: 0.8654\n",
            "Epoch 230/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8643\n",
            "Epoch 231/1000\n",
            "250/250 [==============================] - 0s 988us/step - loss: 0.3289 - accuracy: 0.8661\n",
            "Epoch 232/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8645\n",
            "Epoch 233/1000\n",
            "250/250 [==============================] - 0s 893us/step - loss: 0.3293 - accuracy: 0.8641\n",
            "Epoch 234/1000\n",
            "250/250 [==============================] - 0s 877us/step - loss: 0.3290 - accuracy: 0.8645\n",
            "Epoch 235/1000\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3293 - accuracy: 0.8648\n",
            "Epoch 236/1000\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3289 - accuracy: 0.8656\n",
            "Epoch 237/1000\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3295 - accuracy: 0.8646\n",
            "Epoch 238/1000\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3292 - accuracy: 0.8650\n",
            "Epoch 239/1000\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 240/1000\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3290 - accuracy: 0.8664\n",
            "Epoch 241/1000\n",
            "250/250 [==============================] - 0s 1000us/step - loss: 0.3296 - accuracy: 0.8636\n",
            "Epoch 242/1000\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3296 - accuracy: 0.8649\n",
            "Epoch 243/1000\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3292 - accuracy: 0.8655\n",
            "Epoch 244/1000\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3294 - accuracy: 0.8651\n",
            "Epoch 245/1000\n",
            "250/250 [==============================] - 0s 902us/step - loss: 0.3289 - accuracy: 0.8643\n",
            "Epoch 246/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8635\n",
            "Epoch 247/1000\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3293 - accuracy: 0.8640\n",
            "Epoch 248/1000\n",
            "250/250 [==============================] - 0s 893us/step - loss: 0.3295 - accuracy: 0.8651\n",
            "Epoch 249/1000\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3292 - accuracy: 0.8641\n",
            "Epoch 250/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8644\n",
            "Epoch 251/1000\n",
            "250/250 [==============================] - 0s 981us/step - loss: 0.3290 - accuracy: 0.8645\n",
            "Epoch 252/1000\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3288 - accuracy: 0.8641\n",
            "Epoch 253/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8649\n",
            "Epoch 254/1000\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.3293 - accuracy: 0.8641\n",
            "Epoch 255/1000\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3291 - accuracy: 0.8648\n",
            "Epoch 256/1000\n",
            "250/250 [==============================] - 0s 963us/step - loss: 0.3291 - accuracy: 0.8636\n",
            "Epoch 257/1000\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3294 - accuracy: 0.8641\n",
            "Epoch 258/1000\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3292 - accuracy: 0.8635\n",
            "Epoch 259/1000\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3290 - accuracy: 0.8655\n",
            "Epoch 260/1000\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3290 - accuracy: 0.8645\n",
            "Epoch 261/1000\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3290 - accuracy: 0.8652\n",
            "Epoch 262/1000\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3294 - accuracy: 0.8643\n",
            "Epoch 263/1000\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3293 - accuracy: 0.8644\n",
            "Epoch 264/1000\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3297 - accuracy: 0.8649\n",
            "Epoch 265/1000\n",
            "250/250 [==============================] - 0s 974us/step - loss: 0.3293 - accuracy: 0.8659\n",
            "Epoch 266/1000\n",
            "250/250 [==============================] - 0s 991us/step - loss: 0.3291 - accuracy: 0.8659\n",
            "Epoch 267/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8652\n",
            "Epoch 268/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8652\n",
            "Epoch 269/1000\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3291 - accuracy: 0.8634\n",
            "Epoch 270/1000\n",
            "250/250 [==============================] - 0s 997us/step - loss: 0.3292 - accuracy: 0.8648\n",
            "Epoch 271/1000\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 272/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8664\n",
            "Epoch 273/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8644\n",
            "Epoch 274/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8641\n",
            "Epoch 275/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8643\n",
            "Epoch 276/1000\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3292 - accuracy: 0.8652\n",
            "Epoch 277/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8644\n",
            "Epoch 278/1000\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3292 - accuracy: 0.8655\n",
            "Epoch 279/1000\n",
            "250/250 [==============================] - 0s 995us/step - loss: 0.3294 - accuracy: 0.8643\n",
            "Epoch 280/1000\n",
            "250/250 [==============================] - 0s 964us/step - loss: 0.3289 - accuracy: 0.8637\n",
            "Epoch 281/1000\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3290 - accuracy: 0.8648\n",
            "Epoch 282/1000\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3293 - accuracy: 0.8644\n",
            "Epoch 283/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8661\n",
            "Epoch 284/1000\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3295 - accuracy: 0.8639\n",
            "Epoch 285/1000\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3295 - accuracy: 0.8648\n",
            "Epoch 286/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8635\n",
            "Epoch 287/1000\n",
            "250/250 [==============================] - 0s 981us/step - loss: 0.3292 - accuracy: 0.8645\n",
            "Epoch 288/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8648\n",
            "Epoch 289/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8639\n",
            "Epoch 290/1000\n",
            "250/250 [==============================] - 0s 967us/step - loss: 0.3293 - accuracy: 0.8661\n",
            "Epoch 291/1000\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3292 - accuracy: 0.8644\n",
            "Epoch 292/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8640\n",
            "Epoch 293/1000\n",
            "250/250 [==============================] - 0s 988us/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 294/1000\n",
            "250/250 [==============================] - 0s 1000us/step - loss: 0.3294 - accuracy: 0.8652\n",
            "Epoch 295/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8629\n",
            "Epoch 296/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8652\n",
            "Epoch 297/1000\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3298 - accuracy: 0.8636\n",
            "Epoch 298/1000\n",
            "250/250 [==============================] - 0s 999us/step - loss: 0.3289 - accuracy: 0.8643\n",
            "Epoch 299/1000\n",
            "250/250 [==============================] - 0s 896us/step - loss: 0.3293 - accuracy: 0.8639\n",
            "Epoch 300/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8645\n",
            "Epoch 301/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8651\n",
            "Epoch 302/1000\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.3291 - accuracy: 0.8651\n",
            "Epoch 303/1000\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3290 - accuracy: 0.8649\n",
            "Epoch 304/1000\n",
            "250/250 [==============================] - 0s 921us/step - loss: 0.3292 - accuracy: 0.8643\n",
            "Epoch 305/1000\n",
            "250/250 [==============================] - 0s 892us/step - loss: 0.3295 - accuracy: 0.8651\n",
            "Epoch 306/1000\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3292 - accuracy: 0.8639\n",
            "Epoch 307/1000\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3292 - accuracy: 0.8635\n",
            "Epoch 308/1000\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3288 - accuracy: 0.8656\n",
            "Epoch 309/1000\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3293 - accuracy: 0.8650\n",
            "Epoch 310/1000\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3296 - accuracy: 0.8637\n",
            "Epoch 311/1000\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3290 - accuracy: 0.8633\n",
            "Epoch 312/1000\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3291 - accuracy: 0.8650\n",
            "Epoch 313/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8646\n",
            "Epoch 314/1000\n",
            "250/250 [==============================] - 0s 902us/step - loss: 0.3291 - accuracy: 0.8649\n",
            "Epoch 315/1000\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3292 - accuracy: 0.8652\n",
            "Epoch 316/1000\n",
            "250/250 [==============================] - 0s 901us/step - loss: 0.3287 - accuracy: 0.8635\n",
            "Epoch 317/1000\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3293 - accuracy: 0.8641\n",
            "Epoch 318/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8643\n",
            "Epoch 319/1000\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3294 - accuracy: 0.8650\n",
            "Epoch 320/1000\n",
            "250/250 [==============================] - 0s 896us/step - loss: 0.3292 - accuracy: 0.8651\n",
            "Epoch 321/1000\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3291 - accuracy: 0.8643\n",
            "Epoch 322/1000\n",
            "250/250 [==============================] - 0s 866us/step - loss: 0.3292 - accuracy: 0.8641\n",
            "Epoch 323/1000\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3287 - accuracy: 0.8636\n",
            "Epoch 324/1000\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3290 - accuracy: 0.8649\n",
            "Epoch 325/1000\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3294 - accuracy: 0.8634\n",
            "Epoch 326/1000\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3291 - accuracy: 0.8646\n",
            "Epoch 327/1000\n",
            "250/250 [==============================] - 0s 893us/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 328/1000\n",
            "250/250 [==============================] - 0s 872us/step - loss: 0.3293 - accuracy: 0.8650\n",
            "Epoch 329/1000\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3295 - accuracy: 0.8655\n",
            "Epoch 330/1000\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3292 - accuracy: 0.8648\n",
            "Epoch 331/1000\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3293 - accuracy: 0.8646\n",
            "Epoch 332/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8631\n",
            "Epoch 333/1000\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3293 - accuracy: 0.8649\n",
            "Epoch 334/1000\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3290 - accuracy: 0.8651\n",
            "Epoch 335/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8646\n",
            "Epoch 336/1000\n",
            "250/250 [==============================] - 0s 979us/step - loss: 0.3294 - accuracy: 0.8637\n",
            "Epoch 337/1000\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3291 - accuracy: 0.8630\n",
            "Epoch 338/1000\n",
            "250/250 [==============================] - 0s 963us/step - loss: 0.3294 - accuracy: 0.8639\n",
            "Epoch 339/1000\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3290 - accuracy: 0.8643\n",
            "Epoch 340/1000\n",
            "250/250 [==============================] - 0s 984us/step - loss: 0.3297 - accuracy: 0.8646\n",
            "Epoch 341/1000\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3289 - accuracy: 0.8648\n",
            "Epoch 342/1000\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.3290 - accuracy: 0.8650\n",
            "Epoch 343/1000\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3293 - accuracy: 0.8648\n",
            "Epoch 344/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 345/1000\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.3293 - accuracy: 0.8639\n",
            "Epoch 346/1000\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 347/1000\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3290 - accuracy: 0.8637\n",
            "Epoch 348/1000\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3289 - accuracy: 0.8661\n",
            "Epoch 349/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8646\n",
            "Epoch 350/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8655\n",
            "Epoch 351/1000\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 352/1000\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3290 - accuracy: 0.8636\n",
            "Epoch 353/1000\n",
            "250/250 [==============================] - 0s 904us/step - loss: 0.3294 - accuracy: 0.8636\n",
            "Epoch 354/1000\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3290 - accuracy: 0.8644\n",
            "Epoch 355/1000\n",
            "250/250 [==============================] - 0s 974us/step - loss: 0.3292 - accuracy: 0.8651\n",
            "Epoch 356/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8650\n",
            "Epoch 357/1000\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 358/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8651\n",
            "Epoch 359/1000\n",
            "250/250 [==============================] - 0s 983us/step - loss: 0.3291 - accuracy: 0.8646\n",
            "Epoch 360/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8633\n",
            "Epoch 361/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 362/1000\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 363/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8655\n",
            "Epoch 364/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8650\n",
            "Epoch 365/1000\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 366/1000\n",
            "250/250 [==============================] - 0s 905us/step - loss: 0.3289 - accuracy: 0.8651\n",
            "Epoch 367/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8641\n",
            "Epoch 368/1000\n",
            "250/250 [==============================] - 0s 978us/step - loss: 0.3294 - accuracy: 0.8645\n",
            "Epoch 369/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8644\n",
            "Epoch 370/1000\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3290 - accuracy: 0.8648\n",
            "Epoch 371/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8646\n",
            "Epoch 372/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8658\n",
            "Epoch 373/1000\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3293 - accuracy: 0.8641\n",
            "Epoch 374/1000\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3293 - accuracy: 0.8645\n",
            "Epoch 375/1000\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3291 - accuracy: 0.8639\n",
            "Epoch 376/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8644\n",
            "Epoch 377/1000\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3291 - accuracy: 0.8654\n",
            "Epoch 378/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8645\n",
            "Epoch 379/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8656\n",
            "Epoch 380/1000\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3292 - accuracy: 0.8630\n",
            "Epoch 381/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8655\n",
            "Epoch 382/1000\n",
            "250/250 [==============================] - 0s 921us/step - loss: 0.3290 - accuracy: 0.8634\n",
            "Epoch 383/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8661\n",
            "Epoch 384/1000\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3293 - accuracy: 0.8648\n",
            "Epoch 385/1000\n",
            "250/250 [==============================] - 0s 992us/step - loss: 0.3292 - accuracy: 0.8646\n",
            "Epoch 386/1000\n",
            "250/250 [==============================] - 0s 999us/step - loss: 0.3290 - accuracy: 0.8648\n",
            "Epoch 387/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8648\n",
            "Epoch 388/1000\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3294 - accuracy: 0.8629\n",
            "Epoch 389/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8651\n",
            "Epoch 390/1000\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3290 - accuracy: 0.8652\n",
            "Epoch 391/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8648\n",
            "Epoch 392/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8643\n",
            "Epoch 393/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8652\n",
            "Epoch 394/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8640\n",
            "Epoch 395/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8634\n",
            "Epoch 396/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8643\n",
            "Epoch 397/1000\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 398/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8633\n",
            "Epoch 399/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8652\n",
            "Epoch 400/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8643\n",
            "Epoch 401/1000\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3291 - accuracy: 0.8643\n",
            "Epoch 402/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8650\n",
            "Epoch 403/1000\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3297 - accuracy: 0.8659\n",
            "Epoch 404/1000\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3295 - accuracy: 0.8641\n",
            "Epoch 405/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8635\n",
            "Epoch 406/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8645\n",
            "Epoch 407/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8646\n",
            "Epoch 408/1000\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.3293 - accuracy: 0.8640\n",
            "Epoch 409/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 410/1000\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3290 - accuracy: 0.8644\n",
            "Epoch 411/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8626\n",
            "Epoch 412/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8635\n",
            "Epoch 413/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8637\n",
            "Epoch 414/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8658\n",
            "Epoch 415/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8654\n",
            "Epoch 416/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8637\n",
            "Epoch 417/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8645\n",
            "Epoch 418/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8635\n",
            "Epoch 419/1000\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3290 - accuracy: 0.8624\n",
            "Epoch 420/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8633\n",
            "Epoch 421/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8646\n",
            "Epoch 422/1000\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3294 - accuracy: 0.8636\n",
            "Epoch 423/1000\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3291 - accuracy: 0.8648\n",
            "Epoch 424/1000\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3295 - accuracy: 0.8644\n",
            "Epoch 425/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8645\n",
            "Epoch 426/1000\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.3289 - accuracy: 0.8643\n",
            "Epoch 427/1000\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3292 - accuracy: 0.8635\n",
            "Epoch 428/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8654\n",
            "Epoch 429/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8644\n",
            "Epoch 430/1000\n",
            "250/250 [==============================] - 0s 975us/step - loss: 0.3288 - accuracy: 0.8640\n",
            "Epoch 431/1000\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3291 - accuracy: 0.8650\n",
            "Epoch 432/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8635\n",
            "Epoch 433/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8651\n",
            "Epoch 434/1000\n",
            "250/250 [==============================] - 0s 967us/step - loss: 0.3286 - accuracy: 0.8646\n",
            "Epoch 435/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8636\n",
            "Epoch 436/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8630\n",
            "Epoch 437/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8641\n",
            "Epoch 438/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8634\n",
            "Epoch 439/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8640\n",
            "Epoch 440/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 441/1000\n",
            "250/250 [==============================] - 0s 978us/step - loss: 0.3290 - accuracy: 0.8631\n",
            "Epoch 442/1000\n",
            "250/250 [==============================] - 0s 978us/step - loss: 0.3291 - accuracy: 0.8651\n",
            "Epoch 443/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8659\n",
            "Epoch 444/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8652\n",
            "Epoch 445/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8640\n",
            "Epoch 446/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8646\n",
            "Epoch 447/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8634\n",
            "Epoch 448/1000\n",
            "250/250 [==============================] - 0s 979us/step - loss: 0.3291 - accuracy: 0.8634\n",
            "Epoch 449/1000\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3290 - accuracy: 0.8629\n",
            "Epoch 450/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8646\n",
            "Epoch 451/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 452/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8643\n",
            "Epoch 453/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8650\n",
            "Epoch 454/1000\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3291 - accuracy: 0.8645\n",
            "Epoch 455/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8639\n",
            "Epoch 456/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8636\n",
            "Epoch 457/1000\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 458/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8654\n",
            "Epoch 459/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8646\n",
            "Epoch 460/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 461/1000\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3286 - accuracy: 0.8626\n",
            "Epoch 462/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 463/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8646\n",
            "Epoch 464/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8636\n",
            "Epoch 465/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8650\n",
            "Epoch 466/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8645\n",
            "Epoch 467/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8654\n",
            "Epoch 468/1000\n",
            "250/250 [==============================] - 0s 975us/step - loss: 0.3290 - accuracy: 0.8639\n",
            "Epoch 469/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8640\n",
            "Epoch 470/1000\n",
            "250/250 [==============================] - 0s 974us/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 471/1000\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3291 - accuracy: 0.8652\n",
            "Epoch 472/1000\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3289 - accuracy: 0.8637\n",
            "Epoch 473/1000\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3290 - accuracy: 0.8648\n",
            "Epoch 474/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8634\n",
            "Epoch 475/1000\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3292 - accuracy: 0.8646\n",
            "Epoch 476/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8633\n",
            "Epoch 477/1000\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3284 - accuracy: 0.8646\n",
            "Epoch 478/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8651\n",
            "Epoch 479/1000\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3286 - accuracy: 0.8646\n",
            "Epoch 480/1000\n",
            "250/250 [==============================] - 0s 967us/step - loss: 0.3285 - accuracy: 0.8643\n",
            "Epoch 481/1000\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3289 - accuracy: 0.8650\n",
            "Epoch 482/1000\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3296 - accuracy: 0.8641\n",
            "Epoch 483/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8643\n",
            "Epoch 484/1000\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3290 - accuracy: 0.8640\n",
            "Epoch 485/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8639\n",
            "Epoch 486/1000\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3287 - accuracy: 0.8652\n",
            "Epoch 487/1000\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 488/1000\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.3291 - accuracy: 0.8645\n",
            "Epoch 489/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8636\n",
            "Epoch 490/1000\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3293 - accuracy: 0.8635\n",
            "Epoch 491/1000\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 492/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8655\n",
            "Epoch 493/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8645\n",
            "Epoch 494/1000\n",
            "250/250 [==============================] - 0s 994us/step - loss: 0.3288 - accuracy: 0.8635\n",
            "Epoch 495/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8636\n",
            "Epoch 496/1000\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3291 - accuracy: 0.8637\n",
            "Epoch 497/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8643\n",
            "Epoch 498/1000\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3289 - accuracy: 0.8648\n",
            "Epoch 499/1000\n",
            "250/250 [==============================] - 0s 995us/step - loss: 0.3292 - accuracy: 0.8629\n",
            "Epoch 500/1000\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.3289 - accuracy: 0.8654\n",
            "Epoch 501/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8646\n",
            "Epoch 502/1000\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3291 - accuracy: 0.8633\n",
            "Epoch 503/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8648\n",
            "Epoch 504/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8634\n",
            "Epoch 505/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8655\n",
            "Epoch 506/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8622\n",
            "Epoch 507/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8649\n",
            "Epoch 508/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8640\n",
            "Epoch 509/1000\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3290 - accuracy: 0.8639\n",
            "Epoch 510/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8643\n",
            "Epoch 511/1000\n",
            "250/250 [==============================] - 0s 994us/step - loss: 0.3287 - accuracy: 0.8649\n",
            "Epoch 512/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8626\n",
            "Epoch 513/1000\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3289 - accuracy: 0.8636\n",
            "Epoch 514/1000\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3289 - accuracy: 0.8649\n",
            "Epoch 515/1000\n",
            "250/250 [==============================] - 0s 984us/step - loss: 0.3286 - accuracy: 0.8635\n",
            "Epoch 516/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8652\n",
            "Epoch 517/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8636\n",
            "Epoch 518/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8633\n",
            "Epoch 519/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 520/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8644\n",
            "Epoch 521/1000\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 522/1000\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3289 - accuracy: 0.8645\n",
            "Epoch 523/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8635\n",
            "Epoch 524/1000\n",
            "250/250 [==============================] - 0s 999us/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 525/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8640\n",
            "Epoch 526/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8641\n",
            "Epoch 527/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8637\n",
            "Epoch 528/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8640\n",
            "Epoch 529/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8645\n",
            "Epoch 530/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 531/1000\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3287 - accuracy: 0.8641\n",
            "Epoch 532/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8640\n",
            "Epoch 533/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8622\n",
            "Epoch 534/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8640\n",
            "Epoch 535/1000\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3292 - accuracy: 0.8636\n",
            "Epoch 536/1000\n",
            "250/250 [==============================] - 0s 974us/step - loss: 0.3288 - accuracy: 0.8645\n",
            "Epoch 537/1000\n",
            "250/250 [==============================] - 0s 999us/step - loss: 0.3289 - accuracy: 0.8644\n",
            "Epoch 538/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8648\n",
            "Epoch 539/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8627\n",
            "Epoch 540/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8643\n",
            "Epoch 541/1000\n",
            "250/250 [==============================] - 0s 975us/step - loss: 0.3289 - accuracy: 0.8643\n",
            "Epoch 542/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8639\n",
            "Epoch 543/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8656\n",
            "Epoch 544/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8644\n",
            "Epoch 545/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8648\n",
            "Epoch 546/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8640\n",
            "Epoch 547/1000\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3288 - accuracy: 0.8637\n",
            "Epoch 548/1000\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3290 - accuracy: 0.8640\n",
            "Epoch 549/1000\n",
            "250/250 [==============================] - 0s 1000us/step - loss: 0.3289 - accuracy: 0.8630\n",
            "Epoch 550/1000\n",
            "250/250 [==============================] - 0s 964us/step - loss: 0.3289 - accuracy: 0.8644\n",
            "Epoch 551/1000\n",
            "250/250 [==============================] - 0s 978us/step - loss: 0.3288 - accuracy: 0.8640\n",
            "Epoch 552/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8648\n",
            "Epoch 553/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8656\n",
            "Epoch 554/1000\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3290 - accuracy: 0.8640\n",
            "Epoch 555/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8640\n",
            "Epoch 556/1000\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3289 - accuracy: 0.8630\n",
            "Epoch 557/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8654\n",
            "Epoch 558/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8634\n",
            "Epoch 559/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8643\n",
            "Epoch 560/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 561/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8643\n",
            "Epoch 562/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8636\n",
            "Epoch 563/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8637\n",
            "Epoch 564/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 565/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8605\n",
            "Epoch 566/1000\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 567/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8640\n",
            "Epoch 568/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 569/1000\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3290 - accuracy: 0.8637\n",
            "Epoch 570/1000\n",
            "250/250 [==============================] - 0s 992us/step - loss: 0.3287 - accuracy: 0.8639\n",
            "Epoch 571/1000\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3289 - accuracy: 0.8635\n",
            "Epoch 572/1000\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3288 - accuracy: 0.8640\n",
            "Epoch 573/1000\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 574/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8651\n",
            "Epoch 575/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8634\n",
            "Epoch 576/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8637\n",
            "Epoch 577/1000\n",
            "250/250 [==============================] - 0s 991us/step - loss: 0.3291 - accuracy: 0.8639\n",
            "Epoch 578/1000\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3286 - accuracy: 0.8640\n",
            "Epoch 579/1000\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3289 - accuracy: 0.8651\n",
            "Epoch 580/1000\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3283 - accuracy: 0.8627\n",
            "Epoch 581/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8626\n",
            "Epoch 582/1000\n",
            "250/250 [==============================] - 0s 988us/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 583/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8635\n",
            "Epoch 584/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8640\n",
            "Epoch 585/1000\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3290 - accuracy: 0.8643\n",
            "Epoch 586/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 587/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8631\n",
            "Epoch 588/1000\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3290 - accuracy: 0.8631\n",
            "Epoch 589/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8649\n",
            "Epoch 590/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
            "Epoch 591/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8639\n",
            "Epoch 592/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8633\n",
            "Epoch 593/1000\n",
            "250/250 [==============================] - 0s 974us/step - loss: 0.3289 - accuracy: 0.8649\n",
            "Epoch 594/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8626\n",
            "Epoch 595/1000\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3289 - accuracy: 0.8644\n",
            "Epoch 596/1000\n",
            "250/250 [==============================] - 0s 988us/step - loss: 0.3288 - accuracy: 0.8641\n",
            "Epoch 597/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8639\n",
            "Epoch 598/1000\n",
            "250/250 [==============================] - 0s 963us/step - loss: 0.3288 - accuracy: 0.8624\n",
            "Epoch 599/1000\n",
            "250/250 [==============================] - 0s 983us/step - loss: 0.3290 - accuracy: 0.8639\n",
            "Epoch 600/1000\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 601/1000\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3288 - accuracy: 0.8652\n",
            "Epoch 602/1000\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3289 - accuracy: 0.8640\n",
            "Epoch 603/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8649\n",
            "Epoch 604/1000\n",
            "250/250 [==============================] - 0s 975us/step - loss: 0.3289 - accuracy: 0.8627\n",
            "Epoch 605/1000\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3286 - accuracy: 0.8639\n",
            "Epoch 606/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8650\n",
            "Epoch 607/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8651\n",
            "Epoch 608/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8636\n",
            "Epoch 609/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8639\n",
            "Epoch 610/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8637\n",
            "Epoch 611/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
            "Epoch 612/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8639\n",
            "Epoch 613/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8633\n",
            "Epoch 614/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8630\n",
            "Epoch 615/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8650\n",
            "Epoch 616/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8618\n",
            "Epoch 617/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8648\n",
            "Epoch 618/1000\n",
            "250/250 [==============================] - 0s 991us/step - loss: 0.3286 - accuracy: 0.8635\n",
            "Epoch 619/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 620/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8656\n",
            "Epoch 621/1000\n",
            "250/250 [==============================] - 0s 994us/step - loss: 0.3287 - accuracy: 0.8634\n",
            "Epoch 622/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8640\n",
            "Epoch 623/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8630\n",
            "Epoch 624/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8655\n",
            "Epoch 625/1000\n",
            "250/250 [==============================] - 0s 995us/step - loss: 0.3287 - accuracy: 0.8633\n",
            "Epoch 626/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8639\n",
            "Epoch 627/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8639\n",
            "Epoch 628/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8648\n",
            "Epoch 629/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8637\n",
            "Epoch 630/1000\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3287 - accuracy: 0.8640\n",
            "Epoch 631/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 632/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 633/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8646\n",
            "Epoch 634/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8649\n",
            "Epoch 635/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8669\n",
            "Epoch 636/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8645\n",
            "Epoch 637/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8644\n",
            "Epoch 638/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8635\n",
            "Epoch 639/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8645\n",
            "Epoch 640/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 641/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8639\n",
            "Epoch 642/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
            "Epoch 643/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8651\n",
            "Epoch 644/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8648\n",
            "Epoch 645/1000\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3291 - accuracy: 0.8639\n",
            "Epoch 646/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8640\n",
            "Epoch 647/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8645\n",
            "Epoch 648/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8644\n",
            "Epoch 649/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8654\n",
            "Epoch 650/1000\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3288 - accuracy: 0.8630\n",
            "Epoch 651/1000\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3288 - accuracy: 0.8637\n",
            "Epoch 652/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8630\n",
            "Epoch 653/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8650\n",
            "Epoch 654/1000\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3285 - accuracy: 0.8656\n",
            "Epoch 655/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 656/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8637\n",
            "Epoch 657/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 658/1000\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3288 - accuracy: 0.8650\n",
            "Epoch 659/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8634\n",
            "Epoch 660/1000\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3288 - accuracy: 0.8633\n",
            "Epoch 661/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
            "Epoch 662/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8634\n",
            "Epoch 663/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8639\n",
            "Epoch 664/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8644\n",
            "Epoch 665/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8643\n",
            "Epoch 666/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8650\n",
            "Epoch 667/1000\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3288 - accuracy: 0.8625\n",
            "Epoch 668/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8641\n",
            "Epoch 669/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8637\n",
            "Epoch 670/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8646\n",
            "Epoch 671/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8635\n",
            "Epoch 672/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8651\n",
            "Epoch 673/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8633\n",
            "Epoch 674/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8652\n",
            "Epoch 675/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 676/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8651\n",
            "Epoch 677/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8637\n",
            "Epoch 678/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 679/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8645\n",
            "Epoch 680/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8636\n",
            "Epoch 681/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8650\n",
            "Epoch 682/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8633\n",
            "Epoch 683/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8634\n",
            "Epoch 684/1000\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3284 - accuracy: 0.8641\n",
            "Epoch 685/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8648\n",
            "Epoch 686/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8648\n",
            "Epoch 687/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8641\n",
            "Epoch 688/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8650\n",
            "Epoch 689/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8635\n",
            "Epoch 690/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8624\n",
            "Epoch 691/1000\n",
            "250/250 [==============================] - 0s 976us/step - loss: 0.3286 - accuracy: 0.8634\n",
            "Epoch 692/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8631\n",
            "Epoch 693/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8643\n",
            "Epoch 694/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8645\n",
            "Epoch 695/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8640\n",
            "Epoch 696/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8640\n",
            "Epoch 697/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8648\n",
            "Epoch 698/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 699/1000\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3288 - accuracy: 0.8636\n",
            "Epoch 700/1000\n",
            "250/250 [==============================] - 0s 976us/step - loss: 0.3285 - accuracy: 0.8641\n",
            "Epoch 701/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8651\n",
            "Epoch 702/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8629\n",
            "Epoch 703/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8649\n",
            "Epoch 704/1000\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3284 - accuracy: 0.8637\n",
            "Epoch 705/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 706/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8646\n",
            "Epoch 707/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8651\n",
            "Epoch 708/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8649\n",
            "Epoch 709/1000\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3289 - accuracy: 0.8649\n",
            "Epoch 710/1000\n",
            "250/250 [==============================] - 0s 964us/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 711/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8633\n",
            "Epoch 712/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8649\n",
            "Epoch 713/1000\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3287 - accuracy: 0.8627\n",
            "Epoch 714/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8627\n",
            "Epoch 715/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8639\n",
            "Epoch 716/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8631\n",
            "Epoch 717/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8655\n",
            "Epoch 718/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8622\n",
            "Epoch 719/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8639\n",
            "Epoch 720/1000\n",
            "250/250 [==============================] - 0s 963us/step - loss: 0.3281 - accuracy: 0.8651\n",
            "Epoch 721/1000\n",
            "250/250 [==============================] - 0s 995us/step - loss: 0.3287 - accuracy: 0.8629\n",
            "Epoch 722/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8636\n",
            "Epoch 723/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8644\n",
            "Epoch 724/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8645\n",
            "Epoch 725/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8651\n",
            "Epoch 726/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8649\n",
            "Epoch 727/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 728/1000\n",
            "250/250 [==============================] - 0s 974us/step - loss: 0.3284 - accuracy: 0.8637\n",
            "Epoch 729/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8639\n",
            "Epoch 730/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8651\n",
            "Epoch 731/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8649\n",
            "Epoch 732/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8648\n",
            "Epoch 733/1000\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.3281 - accuracy: 0.8634\n",
            "Epoch 734/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8652\n",
            "Epoch 735/1000\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3282 - accuracy: 0.8648\n",
            "Epoch 736/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8655\n",
            "Epoch 737/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8644\n",
            "Epoch 738/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8640\n",
            "Epoch 739/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8640\n",
            "Epoch 740/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8655\n",
            "Epoch 741/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8651\n",
            "Epoch 742/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8633\n",
            "Epoch 743/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8640\n",
            "Epoch 744/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8648\n",
            "Epoch 745/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8650\n",
            "Epoch 746/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8646\n",
            "Epoch 747/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8641\n",
            "Epoch 748/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8649\n",
            "Epoch 749/1000\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3283 - accuracy: 0.8646\n",
            "Epoch 750/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8639\n",
            "Epoch 751/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8639\n",
            "Epoch 752/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8643\n",
            "Epoch 753/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8629\n",
            "Epoch 754/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8655\n",
            "Epoch 755/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8641\n",
            "Epoch 756/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8639\n",
            "Epoch 757/1000\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3283 - accuracy: 0.8645\n",
            "Epoch 758/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8643\n",
            "Epoch 759/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8652\n",
            "Epoch 760/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8645\n",
            "Epoch 761/1000\n",
            "250/250 [==============================] - 0s 995us/step - loss: 0.3285 - accuracy: 0.8637\n",
            "Epoch 762/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8643\n",
            "Epoch 763/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8634\n",
            "Epoch 764/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8635\n",
            "Epoch 765/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8639\n",
            "Epoch 766/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8640\n",
            "Epoch 767/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
            "Epoch 768/1000\n",
            "250/250 [==============================] - 0s 992us/step - loss: 0.3283 - accuracy: 0.8649\n",
            "Epoch 769/1000\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3285 - accuracy: 0.8641\n",
            "Epoch 770/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8643\n",
            "Epoch 771/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8636\n",
            "Epoch 772/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8635\n",
            "Epoch 773/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8655\n",
            "Epoch 774/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 775/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8651\n",
            "Epoch 776/1000\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3285 - accuracy: 0.8648\n",
            "Epoch 777/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8636\n",
            "Epoch 778/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8621\n",
            "Epoch 779/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8641\n",
            "Epoch 780/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8640\n",
            "Epoch 781/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8651\n",
            "Epoch 782/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8640\n",
            "Epoch 783/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8639\n",
            "Epoch 784/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 785/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8639\n",
            "Epoch 786/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8651\n",
            "Epoch 787/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8643\n",
            "Epoch 788/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8651\n",
            "Epoch 789/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8637\n",
            "Epoch 790/1000\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3285 - accuracy: 0.8646\n",
            "Epoch 791/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8627\n",
            "Epoch 792/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8637\n",
            "Epoch 793/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8640\n",
            "Epoch 794/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8621\n",
            "Epoch 795/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 796/1000\n",
            "250/250 [==============================] - 0s 994us/step - loss: 0.3279 - accuracy: 0.8643\n",
            "Epoch 797/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 798/1000\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3285 - accuracy: 0.8645\n",
            "Epoch 799/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8636\n",
            "Epoch 800/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8644\n",
            "Epoch 801/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8644\n",
            "Epoch 802/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8644\n",
            "Epoch 803/1000\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3285 - accuracy: 0.8646\n",
            "Epoch 804/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8651\n",
            "Epoch 805/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8641\n",
            "Epoch 806/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8635\n",
            "Epoch 807/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8649\n",
            "Epoch 808/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8651\n",
            "Epoch 809/1000\n",
            "250/250 [==============================] - 0s 994us/step - loss: 0.3284 - accuracy: 0.8636\n",
            "Epoch 810/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8649\n",
            "Epoch 811/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8655\n",
            "Epoch 812/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8652\n",
            "Epoch 813/1000\n",
            "250/250 [==============================] - 0s 999us/step - loss: 0.3286 - accuracy: 0.8640\n",
            "Epoch 814/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8649\n",
            "Epoch 815/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8644\n",
            "Epoch 816/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8646\n",
            "Epoch 817/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8643\n",
            "Epoch 818/1000\n",
            "250/250 [==============================] - 0s 997us/step - loss: 0.3286 - accuracy: 0.8644\n",
            "Epoch 819/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8635\n",
            "Epoch 820/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8639\n",
            "Epoch 821/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8655\n",
            "Epoch 822/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8643\n",
            "Epoch 823/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 824/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8644\n",
            "Epoch 825/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8641\n",
            "Epoch 826/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8652\n",
            "Epoch 827/1000\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3282 - accuracy: 0.8630\n",
            "Epoch 828/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8641\n",
            "Epoch 829/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8637\n",
            "Epoch 830/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8648\n",
            "Epoch 831/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8644\n",
            "Epoch 832/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8640\n",
            "Epoch 833/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8641\n",
            "Epoch 834/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8639\n",
            "Epoch 835/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8641\n",
            "Epoch 836/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 837/1000\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3284 - accuracy: 0.8648\n",
            "Epoch 838/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
            "Epoch 839/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8634\n",
            "Epoch 840/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8643\n",
            "Epoch 841/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8639\n",
            "Epoch 842/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8643\n",
            "Epoch 843/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8637\n",
            "Epoch 844/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8654\n",
            "Epoch 845/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8640\n",
            "Epoch 846/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8639\n",
            "Epoch 847/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8654\n",
            "Epoch 848/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 849/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8648\n",
            "Epoch 850/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8631\n",
            "Epoch 851/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8644\n",
            "Epoch 852/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8631\n",
            "Epoch 853/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8640\n",
            "Epoch 854/1000\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 855/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8645\n",
            "Epoch 856/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8637\n",
            "Epoch 857/1000\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3282 - accuracy: 0.8640\n",
            "Epoch 858/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8636\n",
            "Epoch 859/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8645\n",
            "Epoch 860/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8637\n",
            "Epoch 861/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8641\n",
            "Epoch 862/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8643\n",
            "Epoch 863/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8649\n",
            "Epoch 864/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8636\n",
            "Epoch 865/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8637\n",
            "Epoch 866/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8639\n",
            "Epoch 867/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8635\n",
            "Epoch 868/1000\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3285 - accuracy: 0.8639\n",
            "Epoch 869/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8651\n",
            "Epoch 870/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8631\n",
            "Epoch 871/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8646\n",
            "Epoch 872/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8651\n",
            "Epoch 873/1000\n",
            "250/250 [==============================] - 0s 1000us/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 874/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8652\n",
            "Epoch 875/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8645\n",
            "Epoch 876/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8645\n",
            "Epoch 877/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8639\n",
            "Epoch 878/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8654\n",
            "Epoch 879/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8648\n",
            "Epoch 880/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8645\n",
            "Epoch 881/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8656\n",
            "Epoch 882/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8661\n",
            "Epoch 883/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8644\n",
            "Epoch 884/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8640\n",
            "Epoch 885/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8648\n",
            "Epoch 886/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8651\n",
            "Epoch 887/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8639\n",
            "Epoch 888/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8639\n",
            "Epoch 889/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8644\n",
            "Epoch 890/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8634\n",
            "Epoch 891/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8640\n",
            "Epoch 892/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8649\n",
            "Epoch 893/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8640\n",
            "Epoch 894/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8650\n",
            "Epoch 895/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8633\n",
            "Epoch 896/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8631\n",
            "Epoch 897/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 898/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8648\n",
            "Epoch 899/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8640\n",
            "Epoch 900/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8645\n",
            "Epoch 901/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8659\n",
            "Epoch 902/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8644\n",
            "Epoch 903/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8641\n",
            "Epoch 904/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8636\n",
            "Epoch 905/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8649\n",
            "Epoch 906/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8650\n",
            "Epoch 907/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8624\n",
            "Epoch 908/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8646\n",
            "Epoch 909/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8639\n",
            "Epoch 910/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8643\n",
            "Epoch 911/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8645\n",
            "Epoch 912/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8648\n",
            "Epoch 913/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8629\n",
            "Epoch 914/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8648\n",
            "Epoch 915/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8641\n",
            "Epoch 916/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8640\n",
            "Epoch 917/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8634\n",
            "Epoch 918/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8645\n",
            "Epoch 919/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8641\n",
            "Epoch 920/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8636\n",
            "Epoch 921/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8640\n",
            "Epoch 922/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8641\n",
            "Epoch 923/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8649\n",
            "Epoch 924/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8644\n",
            "Epoch 925/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8635\n",
            "Epoch 926/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8660\n",
            "Epoch 927/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8646\n",
            "Epoch 928/1000\n",
            "250/250 [==============================] - 0s 995us/step - loss: 0.3278 - accuracy: 0.8650\n",
            "Epoch 929/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8660\n",
            "Epoch 930/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8652\n",
            "Epoch 931/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8656\n",
            "Epoch 932/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8627\n",
            "Epoch 933/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8643\n",
            "Epoch 934/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8649\n",
            "Epoch 935/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8649\n",
            "Epoch 936/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 937/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8645\n",
            "Epoch 938/1000\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3279 - accuracy: 0.8635\n",
            "Epoch 939/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8635\n",
            "Epoch 940/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8645\n",
            "Epoch 941/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8643\n",
            "Epoch 942/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8636\n",
            "Epoch 943/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8636\n",
            "Epoch 944/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8646\n",
            "Epoch 945/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8658\n",
            "Epoch 946/1000\n",
            "250/250 [==============================] - 0s 981us/step - loss: 0.3283 - accuracy: 0.8645\n",
            "Epoch 947/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8640\n",
            "Epoch 948/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8646\n",
            "Epoch 949/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8649\n",
            "Epoch 950/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8644\n",
            "Epoch 951/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8644\n",
            "Epoch 952/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8643\n",
            "Epoch 953/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8625\n",
            "Epoch 954/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8646\n",
            "Epoch 955/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8640\n",
            "Epoch 956/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8640\n",
            "Epoch 957/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8644\n",
            "Epoch 958/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8654\n",
            "Epoch 959/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 960/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8637\n",
            "Epoch 961/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8640\n",
            "Epoch 962/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8640\n",
            "Epoch 963/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8655\n",
            "Epoch 964/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8652\n",
            "Epoch 965/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8641\n",
            "Epoch 966/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8640\n",
            "Epoch 967/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8641\n",
            "Epoch 968/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8634\n",
            "Epoch 969/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8646\n",
            "Epoch 970/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8645\n",
            "Epoch 971/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8639\n",
            "Epoch 972/1000\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3284 - accuracy: 0.8639\n",
            "Epoch 973/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8645\n",
            "Epoch 974/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8645\n",
            "Epoch 975/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8659\n",
            "Epoch 976/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8650\n",
            "Epoch 977/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8654\n",
            "Epoch 978/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 979/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8655\n",
            "Epoch 980/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8639\n",
            "Epoch 981/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8646\n",
            "Epoch 982/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8631\n",
            "Epoch 983/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8643\n",
            "Epoch 984/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8631\n",
            "Epoch 985/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8648\n",
            "Epoch 986/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8655\n",
            "Epoch 987/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8646\n",
            "Epoch 988/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8641\n",
            "Epoch 989/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8644\n",
            "Epoch 990/1000\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3278 - accuracy: 0.8640\n",
            "Epoch 991/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8645\n",
            "Epoch 992/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8644\n",
            "Epoch 993/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8640\n",
            "Epoch 994/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8654\n",
            "Epoch 995/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8656\n",
            "Epoch 996/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8636\n",
            "Epoch 997/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8639\n",
            "Epoch 998/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8640\n",
            "Epoch 999/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8650\n",
            "Epoch 1000/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f703096ba50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFAGrBM0z066",
        "outputId": "bb0d89a6-5386-4f9b-e895-83d96460024b"
      },
      "source": [
        "#train on 100,500,1000 epochs\n",
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 500)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "250/250 [==============================] - 0s 837us/step - loss: 0.3285 - accuracy: 0.8656\n",
            "Epoch 2/500\n",
            "250/250 [==============================] - 0s 775us/step - loss: 0.3281 - accuracy: 0.8644\n",
            "Epoch 3/500\n",
            "250/250 [==============================] - 0s 838us/step - loss: 0.3280 - accuracy: 0.8650\n",
            "Epoch 4/500\n",
            "250/250 [==============================] - 0s 818us/step - loss: 0.3280 - accuracy: 0.8652\n",
            "Epoch 5/500\n",
            "250/250 [==============================] - 0s 856us/step - loss: 0.3283 - accuracy: 0.8644\n",
            "Epoch 6/500\n",
            "250/250 [==============================] - 0s 904us/step - loss: 0.3282 - accuracy: 0.8646\n",
            "Epoch 7/500\n",
            "250/250 [==============================] - 0s 846us/step - loss: 0.3282 - accuracy: 0.8651\n",
            "Epoch 8/500\n",
            "250/250 [==============================] - 0s 848us/step - loss: 0.3282 - accuracy: 0.8656\n",
            "Epoch 9/500\n",
            "250/250 [==============================] - 0s 799us/step - loss: 0.3279 - accuracy: 0.8650\n",
            "Epoch 10/500\n",
            "250/250 [==============================] - 0s 879us/step - loss: 0.3280 - accuracy: 0.8649\n",
            "Epoch 11/500\n",
            "250/250 [==============================] - 0s 864us/step - loss: 0.3279 - accuracy: 0.8650\n",
            "Epoch 12/500\n",
            "250/250 [==============================] - 0s 862us/step - loss: 0.3283 - accuracy: 0.8649\n",
            "Epoch 13/500\n",
            "250/250 [==============================] - 0s 881us/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 14/500\n",
            "250/250 [==============================] - 0s 850us/step - loss: 0.3276 - accuracy: 0.8654\n",
            "Epoch 15/500\n",
            "250/250 [==============================] - 0s 873us/step - loss: 0.3283 - accuracy: 0.8648\n",
            "Epoch 16/500\n",
            "250/250 [==============================] - 0s 797us/step - loss: 0.3275 - accuracy: 0.8656\n",
            "Epoch 17/500\n",
            "250/250 [==============================] - 0s 881us/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 18/500\n",
            "250/250 [==============================] - 0s 942us/step - loss: 0.3281 - accuracy: 0.8658\n",
            "Epoch 19/500\n",
            "250/250 [==============================] - 0s 928us/step - loss: 0.3280 - accuracy: 0.8658\n",
            "Epoch 20/500\n",
            "250/250 [==============================] - 0s 861us/step - loss: 0.3282 - accuracy: 0.8651\n",
            "Epoch 21/500\n",
            "250/250 [==============================] - 0s 880us/step - loss: 0.3280 - accuracy: 0.8643\n",
            "Epoch 22/500\n",
            "250/250 [==============================] - 0s 891us/step - loss: 0.3280 - accuracy: 0.8640\n",
            "Epoch 23/500\n",
            "250/250 [==============================] - 0s 791us/step - loss: 0.3280 - accuracy: 0.8648\n",
            "Epoch 24/500\n",
            "250/250 [==============================] - 0s 868us/step - loss: 0.3282 - accuracy: 0.8656\n",
            "Epoch 25/500\n",
            "250/250 [==============================] - 0s 837us/step - loss: 0.3282 - accuracy: 0.8633\n",
            "Epoch 26/500\n",
            "250/250 [==============================] - 0s 894us/step - loss: 0.3281 - accuracy: 0.8655\n",
            "Epoch 27/500\n",
            "250/250 [==============================] - 0s 876us/step - loss: 0.3279 - accuracy: 0.8656\n",
            "Epoch 28/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3282 - accuracy: 0.8644\n",
            "Epoch 29/500\n",
            "250/250 [==============================] - 0s 837us/step - loss: 0.3280 - accuracy: 0.8656\n",
            "Epoch 30/500\n",
            "250/250 [==============================] - 0s 875us/step - loss: 0.3281 - accuracy: 0.8650\n",
            "Epoch 31/500\n",
            "250/250 [==============================] - 0s 852us/step - loss: 0.3281 - accuracy: 0.8639\n",
            "Epoch 32/500\n",
            "250/250 [==============================] - 0s 845us/step - loss: 0.3281 - accuracy: 0.8639\n",
            "Epoch 33/500\n",
            "250/250 [==============================] - 0s 888us/step - loss: 0.3279 - accuracy: 0.8639\n",
            "Epoch 34/500\n",
            "250/250 [==============================] - 0s 866us/step - loss: 0.3283 - accuracy: 0.8641\n",
            "Epoch 35/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3279 - accuracy: 0.8654\n",
            "Epoch 36/500\n",
            "250/250 [==============================] - 0s 901us/step - loss: 0.3282 - accuracy: 0.8650\n",
            "Epoch 37/500\n",
            "250/250 [==============================] - 0s 848us/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 38/500\n",
            "250/250 [==============================] - 0s 866us/step - loss: 0.3277 - accuracy: 0.8645\n",
            "Epoch 39/500\n",
            "250/250 [==============================] - 0s 880us/step - loss: 0.3279 - accuracy: 0.8646\n",
            "Epoch 40/500\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3279 - accuracy: 0.8654\n",
            "Epoch 41/500\n",
            "250/250 [==============================] - 0s 841us/step - loss: 0.3278 - accuracy: 0.8645\n",
            "Epoch 42/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 43/500\n",
            "250/250 [==============================] - 0s 992us/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 44/500\n",
            "250/250 [==============================] - 0s 849us/step - loss: 0.3278 - accuracy: 0.8656\n",
            "Epoch 45/500\n",
            "250/250 [==============================] - 0s 857us/step - loss: 0.3282 - accuracy: 0.8650\n",
            "Epoch 46/500\n",
            "250/250 [==============================] - 0s 882us/step - loss: 0.3282 - accuracy: 0.8658\n",
            "Epoch 47/500\n",
            "250/250 [==============================] - 0s 885us/step - loss: 0.3281 - accuracy: 0.8649\n",
            "Epoch 48/500\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3282 - accuracy: 0.8660\n",
            "Epoch 49/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3279 - accuracy: 0.8654\n",
            "Epoch 50/500\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.3284 - accuracy: 0.8654\n",
            "Epoch 51/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3280 - accuracy: 0.8645\n",
            "Epoch 52/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3282 - accuracy: 0.8655\n",
            "Epoch 53/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3276 - accuracy: 0.8648\n",
            "Epoch 54/500\n",
            "250/250 [==============================] - 0s 876us/step - loss: 0.3281 - accuracy: 0.8652\n",
            "Epoch 55/500\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3278 - accuracy: 0.8654\n",
            "Epoch 56/500\n",
            "250/250 [==============================] - 0s 860us/step - loss: 0.3280 - accuracy: 0.8641\n",
            "Epoch 57/500\n",
            "250/250 [==============================] - 0s 877us/step - loss: 0.3278 - accuracy: 0.8656\n",
            "Epoch 58/500\n",
            "250/250 [==============================] - 0s 868us/step - loss: 0.3283 - accuracy: 0.8635\n",
            "Epoch 59/500\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3280 - accuracy: 0.8654\n",
            "Epoch 60/500\n",
            "250/250 [==============================] - 0s 902us/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 61/500\n",
            "250/250 [==============================] - 0s 874us/step - loss: 0.3280 - accuracy: 0.8643\n",
            "Epoch 62/500\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3281 - accuracy: 0.8648\n",
            "Epoch 63/500\n",
            "250/250 [==============================] - 0s 895us/step - loss: 0.3278 - accuracy: 0.8646\n",
            "Epoch 64/500\n",
            "250/250 [==============================] - 0s 876us/step - loss: 0.3281 - accuracy: 0.8648\n",
            "Epoch 65/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3277 - accuracy: 0.8636\n",
            "Epoch 66/500\n",
            "250/250 [==============================] - 0s 861us/step - loss: 0.3279 - accuracy: 0.8655\n",
            "Epoch 67/500\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3278 - accuracy: 0.8652\n",
            "Epoch 68/500\n",
            "250/250 [==============================] - 0s 900us/step - loss: 0.3277 - accuracy: 0.8658\n",
            "Epoch 69/500\n",
            "250/250 [==============================] - 0s 866us/step - loss: 0.3280 - accuracy: 0.8631\n",
            "Epoch 70/500\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.3279 - accuracy: 0.8648\n",
            "Epoch 71/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3281 - accuracy: 0.8637\n",
            "Epoch 72/500\n",
            "250/250 [==============================] - 0s 815us/step - loss: 0.3282 - accuracy: 0.8649\n",
            "Epoch 73/500\n",
            "250/250 [==============================] - 0s 902us/step - loss: 0.3280 - accuracy: 0.8633\n",
            "Epoch 74/500\n",
            "250/250 [==============================] - 0s 862us/step - loss: 0.3281 - accuracy: 0.8652\n",
            "Epoch 75/500\n",
            "250/250 [==============================] - 0s 882us/step - loss: 0.3282 - accuracy: 0.8639\n",
            "Epoch 76/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3284 - accuracy: 0.8651\n",
            "Epoch 77/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3283 - accuracy: 0.8646\n",
            "Epoch 78/500\n",
            "250/250 [==============================] - 0s 914us/step - loss: 0.3280 - accuracy: 0.8656\n",
            "Epoch 79/500\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.3280 - accuracy: 0.8658\n",
            "Epoch 80/500\n",
            "250/250 [==============================] - 0s 882us/step - loss: 0.3282 - accuracy: 0.8664\n",
            "Epoch 81/500\n",
            "250/250 [==============================] - 0s 883us/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 82/500\n",
            "250/250 [==============================] - 0s 898us/step - loss: 0.3281 - accuracy: 0.8646\n",
            "Epoch 83/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3279 - accuracy: 0.8655\n",
            "Epoch 84/500\n",
            "250/250 [==============================] - 0s 991us/step - loss: 0.3277 - accuracy: 0.8660\n",
            "Epoch 85/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3279 - accuracy: 0.8635\n",
            "Epoch 86/500\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3284 - accuracy: 0.8643\n",
            "Epoch 87/500\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3279 - accuracy: 0.8646\n",
            "Epoch 88/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3279 - accuracy: 0.8659\n",
            "Epoch 89/500\n",
            "250/250 [==============================] - 0s 896us/step - loss: 0.3278 - accuracy: 0.8649\n",
            "Epoch 90/500\n",
            "250/250 [==============================] - 0s 870us/step - loss: 0.3282 - accuracy: 0.8637\n",
            "Epoch 91/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3277 - accuracy: 0.8644\n",
            "Epoch 92/500\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3283 - accuracy: 0.8661\n",
            "Epoch 93/500\n",
            "250/250 [==============================] - 0s 878us/step - loss: 0.3281 - accuracy: 0.8651\n",
            "Epoch 94/500\n",
            "250/250 [==============================] - 0s 871us/step - loss: 0.3279 - accuracy: 0.8643\n",
            "Epoch 95/500\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3284 - accuracy: 0.8631\n",
            "Epoch 96/500\n",
            "250/250 [==============================] - 0s 877us/step - loss: 0.3281 - accuracy: 0.8641\n",
            "Epoch 97/500\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3278 - accuracy: 0.8648\n",
            "Epoch 98/500\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3281 - accuracy: 0.8652\n",
            "Epoch 99/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 100/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3278 - accuracy: 0.8641\n",
            "Epoch 101/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3277 - accuracy: 0.8635\n",
            "Epoch 102/500\n",
            "250/250 [==============================] - 0s 879us/step - loss: 0.3280 - accuracy: 0.8656\n",
            "Epoch 103/500\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3282 - accuracy: 0.8643\n",
            "Epoch 104/500\n",
            "250/250 [==============================] - 0s 887us/step - loss: 0.3278 - accuracy: 0.8664\n",
            "Epoch 105/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3282 - accuracy: 0.8646\n",
            "Epoch 106/500\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3279 - accuracy: 0.8650\n",
            "Epoch 107/500\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3281 - accuracy: 0.8643\n",
            "Epoch 108/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 109/500\n",
            "250/250 [==============================] - 0s 878us/step - loss: 0.3282 - accuracy: 0.8652\n",
            "Epoch 110/500\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.3276 - accuracy: 0.8648\n",
            "Epoch 111/500\n",
            "250/250 [==============================] - 0s 910us/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 112/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3282 - accuracy: 0.8640\n",
            "Epoch 113/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3276 - accuracy: 0.8650\n",
            "Epoch 114/500\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.3276 - accuracy: 0.8650\n",
            "Epoch 115/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3280 - accuracy: 0.8644\n",
            "Epoch 116/500\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.3280 - accuracy: 0.8639\n",
            "Epoch 117/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3278 - accuracy: 0.8668\n",
            "Epoch 118/500\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3281 - accuracy: 0.8656\n",
            "Epoch 119/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8639\n",
            "Epoch 120/500\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.3281 - accuracy: 0.8658\n",
            "Epoch 121/500\n",
            "250/250 [==============================] - 0s 895us/step - loss: 0.3278 - accuracy: 0.8644\n",
            "Epoch 122/500\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3281 - accuracy: 0.8644\n",
            "Epoch 123/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3279 - accuracy: 0.8645\n",
            "Epoch 124/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8650\n",
            "Epoch 125/500\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.3276 - accuracy: 0.8622\n",
            "Epoch 126/500\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3280 - accuracy: 0.8655\n",
            "Epoch 127/500\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3277 - accuracy: 0.8662\n",
            "Epoch 128/500\n",
            "250/250 [==============================] - 0s 904us/step - loss: 0.3279 - accuracy: 0.8649\n",
            "Epoch 129/500\n",
            "250/250 [==============================] - 0s 872us/step - loss: 0.3279 - accuracy: 0.8652\n",
            "Epoch 130/500\n",
            "250/250 [==============================] - 0s 897us/step - loss: 0.3279 - accuracy: 0.8661\n",
            "Epoch 131/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3280 - accuracy: 0.8639\n",
            "Epoch 132/500\n",
            "250/250 [==============================] - 0s 876us/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 133/500\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3279 - accuracy: 0.8656\n",
            "Epoch 134/500\n",
            "250/250 [==============================] - 0s 882us/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 135/500\n",
            "250/250 [==============================] - 0s 928us/step - loss: 0.3281 - accuracy: 0.8650\n",
            "Epoch 136/500\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.3282 - accuracy: 0.8641\n",
            "Epoch 137/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 138/500\n",
            "250/250 [==============================] - 0s 849us/step - loss: 0.3279 - accuracy: 0.8643\n",
            "Epoch 139/500\n",
            "250/250 [==============================] - 0s 846us/step - loss: 0.3280 - accuracy: 0.8651\n",
            "Epoch 140/500\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.3277 - accuracy: 0.8664\n",
            "Epoch 141/500\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3284 - accuracy: 0.8639\n",
            "Epoch 142/500\n",
            "250/250 [==============================] - 0s 888us/step - loss: 0.3278 - accuracy: 0.8646\n",
            "Epoch 143/500\n",
            "250/250 [==============================] - 0s 820us/step - loss: 0.3278 - accuracy: 0.8645\n",
            "Epoch 144/500\n",
            "250/250 [==============================] - 0s 914us/step - loss: 0.3278 - accuracy: 0.8654\n",
            "Epoch 145/500\n",
            "250/250 [==============================] - 0s 910us/step - loss: 0.3270 - accuracy: 0.8658\n",
            "Epoch 146/500\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3283 - accuracy: 0.8645\n",
            "Epoch 147/500\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3279 - accuracy: 0.8656\n",
            "Epoch 148/500\n",
            "250/250 [==============================] - 0s 865us/step - loss: 0.3279 - accuracy: 0.8664\n",
            "Epoch 149/500\n",
            "250/250 [==============================] - 0s 928us/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 150/500\n",
            "250/250 [==============================] - 0s 863us/step - loss: 0.3281 - accuracy: 0.8658\n",
            "Epoch 151/500\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3280 - accuracy: 0.8658\n",
            "Epoch 152/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3280 - accuracy: 0.8634\n",
            "Epoch 153/500\n",
            "250/250 [==============================] - 0s 928us/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 154/500\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3277 - accuracy: 0.8656\n",
            "Epoch 155/500\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3283 - accuracy: 0.8652\n",
            "Epoch 156/500\n",
            "250/250 [==============================] - 0s 883us/step - loss: 0.3278 - accuracy: 0.8654\n",
            "Epoch 157/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3280 - accuracy: 0.8656\n",
            "Epoch 158/500\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3280 - accuracy: 0.8631\n",
            "Epoch 159/500\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3282 - accuracy: 0.8661\n",
            "Epoch 160/500\n",
            "250/250 [==============================] - 0s 884us/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 161/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8655\n",
            "Epoch 162/500\n",
            "250/250 [==============================] - 0s 901us/step - loss: 0.3279 - accuracy: 0.8646\n",
            "Epoch 163/500\n",
            "250/250 [==============================] - 0s 976us/step - loss: 0.3279 - accuracy: 0.8635\n",
            "Epoch 164/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3281 - accuracy: 0.8650\n",
            "Epoch 165/500\n",
            "250/250 [==============================] - 0s 910us/step - loss: 0.3281 - accuracy: 0.8652\n",
            "Epoch 166/500\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3278 - accuracy: 0.8655\n",
            "Epoch 167/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8650\n",
            "Epoch 168/500\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3280 - accuracy: 0.8645\n",
            "Epoch 169/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3279 - accuracy: 0.8645\n",
            "Epoch 170/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8652\n",
            "Epoch 171/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3277 - accuracy: 0.8652\n",
            "Epoch 172/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3278 - accuracy: 0.8643\n",
            "Epoch 173/500\n",
            "250/250 [==============================] - 0s 915us/step - loss: 0.3280 - accuracy: 0.8631\n",
            "Epoch 174/500\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3279 - accuracy: 0.8649\n",
            "Epoch 175/500\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3277 - accuracy: 0.8654\n",
            "Epoch 176/500\n",
            "250/250 [==============================] - 0s 891us/step - loss: 0.3278 - accuracy: 0.8639\n",
            "Epoch 177/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3280 - accuracy: 0.8655\n",
            "Epoch 178/500\n",
            "250/250 [==============================] - 0s 981us/step - loss: 0.3274 - accuracy: 0.8648\n",
            "Epoch 179/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8631\n",
            "Epoch 180/500\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 181/500\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3280 - accuracy: 0.8637\n",
            "Epoch 182/500\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3278 - accuracy: 0.8656\n",
            "Epoch 183/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3276 - accuracy: 0.8655\n",
            "Epoch 184/500\n",
            "250/250 [==============================] - 0s 892us/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 185/500\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3278 - accuracy: 0.8655\n",
            "Epoch 186/500\n",
            "250/250 [==============================] - 0s 953us/step - loss: 0.3279 - accuracy: 0.8648\n",
            "Epoch 187/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3281 - accuracy: 0.8659\n",
            "Epoch 188/500\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3281 - accuracy: 0.8643\n",
            "Epoch 189/500\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.3278 - accuracy: 0.8661\n",
            "Epoch 190/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8635\n",
            "Epoch 191/500\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3280 - accuracy: 0.8650\n",
            "Epoch 192/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 193/500\n",
            "250/250 [==============================] - 0s 883us/step - loss: 0.3274 - accuracy: 0.8658\n",
            "Epoch 194/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3279 - accuracy: 0.8629\n",
            "Epoch 195/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3280 - accuracy: 0.8650\n",
            "Epoch 196/500\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 197/500\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 198/500\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3283 - accuracy: 0.8650\n",
            "Epoch 199/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3281 - accuracy: 0.8640\n",
            "Epoch 200/500\n",
            "250/250 [==============================] - 0s 867us/step - loss: 0.3277 - accuracy: 0.8661\n",
            "Epoch 201/500\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3279 - accuracy: 0.8669\n",
            "Epoch 202/500\n",
            "250/250 [==============================] - 0s 851us/step - loss: 0.3276 - accuracy: 0.8652\n",
            "Epoch 203/500\n",
            "250/250 [==============================] - 0s 988us/step - loss: 0.3280 - accuracy: 0.8633\n",
            "Epoch 204/500\n",
            "250/250 [==============================] - 0s 942us/step - loss: 0.3279 - accuracy: 0.8648\n",
            "Epoch 205/500\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3276 - accuracy: 0.8650\n",
            "Epoch 206/500\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3279 - accuracy: 0.8643\n",
            "Epoch 207/500\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3275 - accuracy: 0.8629\n",
            "Epoch 208/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8648\n",
            "Epoch 209/500\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3279 - accuracy: 0.8645\n",
            "Epoch 210/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3277 - accuracy: 0.8648\n",
            "Epoch 211/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3274 - accuracy: 0.8636\n",
            "Epoch 212/500\n",
            "250/250 [==============================] - 0s 893us/step - loss: 0.3281 - accuracy: 0.8661\n",
            "Epoch 213/500\n",
            "250/250 [==============================] - 0s 883us/step - loss: 0.3278 - accuracy: 0.8655\n",
            "Epoch 214/500\n",
            "250/250 [==============================] - 0s 838us/step - loss: 0.3278 - accuracy: 0.8645\n",
            "Epoch 215/500\n",
            "250/250 [==============================] - 0s 903us/step - loss: 0.3278 - accuracy: 0.8646\n",
            "Epoch 216/500\n",
            "250/250 [==============================] - 0s 899us/step - loss: 0.3279 - accuracy: 0.8641\n",
            "Epoch 217/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8652\n",
            "Epoch 218/500\n",
            "250/250 [==============================] - 0s 888us/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 219/500\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3278 - accuracy: 0.8630\n",
            "Epoch 220/500\n",
            "250/250 [==============================] - 0s 915us/step - loss: 0.3276 - accuracy: 0.8639\n",
            "Epoch 221/500\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3277 - accuracy: 0.8659\n",
            "Epoch 222/500\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3278 - accuracy: 0.8636\n",
            "Epoch 223/500\n",
            "250/250 [==============================] - 0s 890us/step - loss: 0.3278 - accuracy: 0.8636\n",
            "Epoch 224/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8652\n",
            "Epoch 225/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3278 - accuracy: 0.8666\n",
            "Epoch 226/500\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3280 - accuracy: 0.8651\n",
            "Epoch 227/500\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3279 - accuracy: 0.8639\n",
            "Epoch 228/500\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3279 - accuracy: 0.8655\n",
            "Epoch 229/500\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3282 - accuracy: 0.8646\n",
            "Epoch 230/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3276 - accuracy: 0.8633\n",
            "Epoch 231/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3278 - accuracy: 0.8634\n",
            "Epoch 232/500\n",
            "250/250 [==============================] - 0s 883us/step - loss: 0.3279 - accuracy: 0.8646\n",
            "Epoch 233/500\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3282 - accuracy: 0.8643\n",
            "Epoch 234/500\n",
            "250/250 [==============================] - 0s 975us/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 235/500\n",
            "250/250 [==============================] - 0s 910us/step - loss: 0.3277 - accuracy: 0.8637\n",
            "Epoch 236/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3281 - accuracy: 0.8644\n",
            "Epoch 237/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3280 - accuracy: 0.8665\n",
            "Epoch 238/500\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.3279 - accuracy: 0.8650\n",
            "Epoch 239/500\n",
            "250/250 [==============================] - 0s 872us/step - loss: 0.3281 - accuracy: 0.8644\n",
            "Epoch 240/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3281 - accuracy: 0.8656\n",
            "Epoch 241/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8668\n",
            "Epoch 242/500\n",
            "250/250 [==============================] - 0s 967us/step - loss: 0.3277 - accuracy: 0.8648\n",
            "Epoch 243/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3280 - accuracy: 0.8650\n",
            "Epoch 244/500\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3278 - accuracy: 0.8648\n",
            "Epoch 245/500\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3275 - accuracy: 0.8644\n",
            "Epoch 246/500\n",
            "250/250 [==============================] - 0s 869us/step - loss: 0.3280 - accuracy: 0.8636\n",
            "Epoch 247/500\n",
            "250/250 [==============================] - 0s 898us/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 248/500\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3279 - accuracy: 0.8640\n",
            "Epoch 249/500\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3271 - accuracy: 0.8648\n",
            "Epoch 250/500\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 251/500\n",
            "250/250 [==============================] - 0s 942us/step - loss: 0.3279 - accuracy: 0.8641\n",
            "Epoch 252/500\n",
            "250/250 [==============================] - 0s 912us/step - loss: 0.3275 - accuracy: 0.8648\n",
            "Epoch 253/500\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3276 - accuracy: 0.8656\n",
            "Epoch 254/500\n",
            "250/250 [==============================] - 0s 942us/step - loss: 0.3278 - accuracy: 0.8652\n",
            "Epoch 255/500\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3279 - accuracy: 0.8660\n",
            "Epoch 256/500\n",
            "250/250 [==============================] - 0s 870us/step - loss: 0.3277 - accuracy: 0.8658\n",
            "Epoch 257/500\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3276 - accuracy: 0.8650\n",
            "Epoch 258/500\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.3276 - accuracy: 0.8654\n",
            "Epoch 259/500\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3276 - accuracy: 0.8651\n",
            "Epoch 260/500\n",
            "250/250 [==============================] - 0s 889us/step - loss: 0.3278 - accuracy: 0.8650\n",
            "Epoch 261/500\n",
            "250/250 [==============================] - 0s 896us/step - loss: 0.3279 - accuracy: 0.8641\n",
            "Epoch 262/500\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3278 - accuracy: 0.8664\n",
            "Epoch 263/500\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3278 - accuracy: 0.8636\n",
            "Epoch 264/500\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3276 - accuracy: 0.8650\n",
            "Epoch 265/500\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3280 - accuracy: 0.8650\n",
            "Epoch 266/500\n",
            "250/250 [==============================] - 0s 988us/step - loss: 0.3279 - accuracy: 0.8646\n",
            "Epoch 267/500\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3278 - accuracy: 0.8655\n",
            "Epoch 268/500\n",
            "250/250 [==============================] - 0s 1000us/step - loss: 0.3275 - accuracy: 0.8658\n",
            "Epoch 269/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8650\n",
            "Epoch 270/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3282 - accuracy: 0.8646\n",
            "Epoch 271/500\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3279 - accuracy: 0.8649\n",
            "Epoch 272/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3279 - accuracy: 0.8661\n",
            "Epoch 273/500\n",
            "250/250 [==============================] - 0s 984us/step - loss: 0.3278 - accuracy: 0.8644\n",
            "Epoch 274/500\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3276 - accuracy: 0.8655\n",
            "Epoch 275/500\n",
            "250/250 [==============================] - 0s 921us/step - loss: 0.3281 - accuracy: 0.8649\n",
            "Epoch 276/500\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3276 - accuracy: 0.8649\n",
            "Epoch 277/500\n",
            "250/250 [==============================] - 0s 858us/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 278/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3277 - accuracy: 0.8656\n",
            "Epoch 279/500\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3280 - accuracy: 0.8643\n",
            "Epoch 280/500\n",
            "250/250 [==============================] - 0s 902us/step - loss: 0.3282 - accuracy: 0.8646\n",
            "Epoch 281/500\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3273 - accuracy: 0.8668\n",
            "Epoch 282/500\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.3278 - accuracy: 0.8648\n",
            "Epoch 283/500\n",
            "250/250 [==============================] - 0s 991us/step - loss: 0.3280 - accuracy: 0.8646\n",
            "Epoch 284/500\n",
            "250/250 [==============================] - 0s 938us/step - loss: 0.3277 - accuracy: 0.8668\n",
            "Epoch 285/500\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3280 - accuracy: 0.8643\n",
            "Epoch 286/500\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3280 - accuracy: 0.8648\n",
            "Epoch 287/500\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3276 - accuracy: 0.8645\n",
            "Epoch 288/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3277 - accuracy: 0.8651\n",
            "Epoch 289/500\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3280 - accuracy: 0.8654\n",
            "Epoch 290/500\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.3276 - accuracy: 0.8652\n",
            "Epoch 291/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8645\n",
            "Epoch 292/500\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3276 - accuracy: 0.8649\n",
            "Epoch 293/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3279 - accuracy: 0.8648\n",
            "Epoch 294/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3280 - accuracy: 0.8631\n",
            "Epoch 295/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8652\n",
            "Epoch 296/500\n",
            "250/250 [==============================] - 0s 860us/step - loss: 0.3281 - accuracy: 0.8650\n",
            "Epoch 297/500\n",
            "250/250 [==============================] - 0s 890us/step - loss: 0.3279 - accuracy: 0.8656\n",
            "Epoch 298/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8655\n",
            "Epoch 299/500\n",
            "250/250 [==============================] - 0s 985us/step - loss: 0.3281 - accuracy: 0.8649\n",
            "Epoch 300/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3276 - accuracy: 0.8654\n",
            "Epoch 301/500\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.3278 - accuracy: 0.8662\n",
            "Epoch 302/500\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3276 - accuracy: 0.8650\n",
            "Epoch 303/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8645\n",
            "Epoch 304/500\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.3277 - accuracy: 0.8650\n",
            "Epoch 305/500\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3281 - accuracy: 0.8660\n",
            "Epoch 306/500\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3279 - accuracy: 0.8645\n",
            "Epoch 307/500\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 308/500\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3279 - accuracy: 0.8640\n",
            "Epoch 309/500\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.3279 - accuracy: 0.8630\n",
            "Epoch 310/500\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3279 - accuracy: 0.8646\n",
            "Epoch 311/500\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.3281 - accuracy: 0.8646\n",
            "Epoch 312/500\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 313/500\n",
            "250/250 [==============================] - 0s 994us/step - loss: 0.3279 - accuracy: 0.8646\n",
            "Epoch 314/500\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3281 - accuracy: 0.8640\n",
            "Epoch 315/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8654\n",
            "Epoch 316/500\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3278 - accuracy: 0.8661\n",
            "Epoch 317/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 318/500\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3277 - accuracy: 0.8659\n",
            "Epoch 319/500\n",
            "250/250 [==============================] - 0s 992us/step - loss: 0.3279 - accuracy: 0.8656\n",
            "Epoch 320/500\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3278 - accuracy: 0.8649\n",
            "Epoch 321/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3277 - accuracy: 0.8649\n",
            "Epoch 322/500\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3282 - accuracy: 0.8643\n",
            "Epoch 323/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8648\n",
            "Epoch 324/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8655\n",
            "Epoch 325/500\n",
            "250/250 [==============================] - 0s 901us/step - loss: 0.3278 - accuracy: 0.8660\n",
            "Epoch 326/500\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3276 - accuracy: 0.8654\n",
            "Epoch 327/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8651\n",
            "Epoch 328/500\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3278 - accuracy: 0.8656\n",
            "Epoch 329/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3280 - accuracy: 0.8658\n",
            "Epoch 330/500\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3280 - accuracy: 0.8646\n",
            "Epoch 331/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8630\n",
            "Epoch 332/500\n",
            "250/250 [==============================] - 0s 894us/step - loss: 0.3276 - accuracy: 0.8659\n",
            "Epoch 333/500\n",
            "250/250 [==============================] - 0s 859us/step - loss: 0.3275 - accuracy: 0.8648\n",
            "Epoch 334/500\n",
            "250/250 [==============================] - 0s 976us/step - loss: 0.3278 - accuracy: 0.8641\n",
            "Epoch 335/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3277 - accuracy: 0.8645\n",
            "Epoch 336/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8649\n",
            "Epoch 337/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3277 - accuracy: 0.8659\n",
            "Epoch 338/500\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3277 - accuracy: 0.8641\n",
            "Epoch 339/500\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3279 - accuracy: 0.8636\n",
            "Epoch 340/500\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3278 - accuracy: 0.8652\n",
            "Epoch 341/500\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3277 - accuracy: 0.8659\n",
            "Epoch 342/500\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 343/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3280 - accuracy: 0.8643\n",
            "Epoch 344/500\n",
            "250/250 [==============================] - 0s 974us/step - loss: 0.3275 - accuracy: 0.8659\n",
            "Epoch 345/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8643\n",
            "Epoch 346/500\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3279 - accuracy: 0.8660\n",
            "Epoch 347/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8646\n",
            "Epoch 348/500\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3276 - accuracy: 0.8662\n",
            "Epoch 349/500\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3279 - accuracy: 0.8639\n",
            "Epoch 350/500\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3276 - accuracy: 0.8641\n",
            "Epoch 351/500\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3280 - accuracy: 0.8652\n",
            "Epoch 352/500\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3280 - accuracy: 0.8668\n",
            "Epoch 353/500\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3275 - accuracy: 0.8651\n",
            "Epoch 354/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8658\n",
            "Epoch 355/500\n",
            "250/250 [==============================] - 0s 974us/step - loss: 0.3276 - accuracy: 0.8651\n",
            "Epoch 356/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3281 - accuracy: 0.8637\n",
            "Epoch 357/500\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3274 - accuracy: 0.8660\n",
            "Epoch 358/500\n",
            "250/250 [==============================] - 0s 890us/step - loss: 0.3275 - accuracy: 0.8665\n",
            "Epoch 359/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3276 - accuracy: 0.8656\n",
            "Epoch 360/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8648\n",
            "Epoch 361/500\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3279 - accuracy: 0.8645\n",
            "Epoch 362/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8655\n",
            "Epoch 363/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8649\n",
            "Epoch 364/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8658\n",
            "Epoch 365/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8649\n",
            "Epoch 366/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8660\n",
            "Epoch 367/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8662\n",
            "Epoch 368/500\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3275 - accuracy: 0.8652\n",
            "Epoch 369/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 370/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8651\n",
            "Epoch 371/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8636\n",
            "Epoch 372/500\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3279 - accuracy: 0.8655\n",
            "Epoch 373/500\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3280 - accuracy: 0.8658\n",
            "Epoch 374/500\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3281 - accuracy: 0.8655\n",
            "Epoch 375/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8650\n",
            "Epoch 376/500\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.3277 - accuracy: 0.8662\n",
            "Epoch 377/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8646\n",
            "Epoch 378/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3280 - accuracy: 0.8641\n",
            "Epoch 379/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8644\n",
            "Epoch 380/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8649\n",
            "Epoch 381/500\n",
            "250/250 [==============================] - 0s 994us/step - loss: 0.3278 - accuracy: 0.8646\n",
            "Epoch 382/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8644\n",
            "Epoch 383/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8654\n",
            "Epoch 384/500\n",
            "250/250 [==============================] - 0s 992us/step - loss: 0.3280 - accuracy: 0.8635\n",
            "Epoch 385/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8649\n",
            "Epoch 386/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8656\n",
            "Epoch 387/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8644\n",
            "Epoch 388/500\n",
            "250/250 [==============================] - 0s 997us/step - loss: 0.3279 - accuracy: 0.8639\n",
            "Epoch 389/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8662\n",
            "Epoch 390/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8656\n",
            "Epoch 391/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3280 - accuracy: 0.8648\n",
            "Epoch 392/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8654\n",
            "Epoch 393/500\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3279 - accuracy: 0.8650\n",
            "Epoch 394/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8645\n",
            "Epoch 395/500\n",
            "250/250 [==============================] - 0s 999us/step - loss: 0.3277 - accuracy: 0.8652\n",
            "Epoch 396/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8649\n",
            "Epoch 397/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 398/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8643\n",
            "Epoch 399/500\n",
            "250/250 [==============================] - 0s 981us/step - loss: 0.3279 - accuracy: 0.8645\n",
            "Epoch 400/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8641\n",
            "Epoch 401/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8637\n",
            "Epoch 402/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8649\n",
            "Epoch 403/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8648\n",
            "Epoch 404/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8660\n",
            "Epoch 405/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8646\n",
            "Epoch 406/500\n",
            "250/250 [==============================] - 0s 979us/step - loss: 0.3278 - accuracy: 0.8650\n",
            "Epoch 407/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8669\n",
            "Epoch 408/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8651\n",
            "Epoch 409/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8651\n",
            "Epoch 410/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8648\n",
            "Epoch 411/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 412/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8656\n",
            "Epoch 413/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 414/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8643\n",
            "Epoch 415/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 416/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 417/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3279 - accuracy: 0.8640\n",
            "Epoch 418/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8652\n",
            "Epoch 419/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8659\n",
            "Epoch 420/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8655\n",
            "Epoch 421/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8649\n",
            "Epoch 422/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 423/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8639\n",
            "Epoch 424/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8643\n",
            "Epoch 425/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3274 - accuracy: 0.8656\n",
            "Epoch 426/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8654\n",
            "Epoch 427/500\n",
            "250/250 [==============================] - 0s 921us/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 428/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8658\n",
            "Epoch 429/500\n",
            "250/250 [==============================] - 0s 982us/step - loss: 0.3278 - accuracy: 0.8645\n",
            "Epoch 430/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8648\n",
            "Epoch 431/500\n",
            "250/250 [==============================] - 0s 970us/step - loss: 0.3275 - accuracy: 0.8660\n",
            "Epoch 432/500\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.3279 - accuracy: 0.8634\n",
            "Epoch 433/500\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3276 - accuracy: 0.8635\n",
            "Epoch 434/500\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.3276 - accuracy: 0.8635\n",
            "Epoch 435/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8655\n",
            "Epoch 436/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8660\n",
            "Epoch 437/500\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.3281 - accuracy: 0.8662\n",
            "Epoch 438/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8637\n",
            "Epoch 439/500\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3278 - accuracy: 0.8649\n",
            "Epoch 440/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8651\n",
            "Epoch 441/500\n",
            "250/250 [==============================] - 0s 975us/step - loss: 0.3276 - accuracy: 0.8644\n",
            "Epoch 442/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8654\n",
            "Epoch 443/500\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3272 - accuracy: 0.8654\n",
            "Epoch 444/500\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3279 - accuracy: 0.8643\n",
            "Epoch 445/500\n",
            "250/250 [==============================] - 0s 994us/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 446/500\n",
            "250/250 [==============================] - 0s 984us/step - loss: 0.3276 - accuracy: 0.8649\n",
            "Epoch 447/500\n",
            "250/250 [==============================] - 0s 976us/step - loss: 0.3282 - accuracy: 0.8651\n",
            "Epoch 448/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8658\n",
            "Epoch 449/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8666\n",
            "Epoch 450/500\n",
            "250/250 [==============================] - 0s 975us/step - loss: 0.3275 - accuracy: 0.8664\n",
            "Epoch 451/500\n",
            "250/250 [==============================] - 0s 984us/step - loss: 0.3280 - accuracy: 0.8649\n",
            "Epoch 452/500\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3275 - accuracy: 0.8665\n",
            "Epoch 453/500\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3277 - accuracy: 0.8661\n",
            "Epoch 454/500\n",
            "250/250 [==============================] - 0s 987us/step - loss: 0.3277 - accuracy: 0.8637\n",
            "Epoch 455/500\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3278 - accuracy: 0.8662\n",
            "Epoch 456/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8659\n",
            "Epoch 457/500\n",
            "250/250 [==============================] - 0s 923us/step - loss: 0.3278 - accuracy: 0.8650\n",
            "Epoch 458/500\n",
            "250/250 [==============================] - 0s 1000us/step - loss: 0.3278 - accuracy: 0.8654\n",
            "Epoch 459/500\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3278 - accuracy: 0.8660\n",
            "Epoch 460/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 461/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8649\n",
            "Epoch 462/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8644\n",
            "Epoch 463/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8646\n",
            "Epoch 464/500\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3280 - accuracy: 0.8650\n",
            "Epoch 465/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8654\n",
            "Epoch 466/500\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3275 - accuracy: 0.8640\n",
            "Epoch 467/500\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3280 - accuracy: 0.8659\n",
            "Epoch 468/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8659\n",
            "Epoch 469/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8648\n",
            "Epoch 470/500\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3278 - accuracy: 0.8645\n",
            "Epoch 471/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8635\n",
            "Epoch 472/500\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3279 - accuracy: 0.8666\n",
            "Epoch 473/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8658\n",
            "Epoch 474/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8641\n",
            "Epoch 475/500\n",
            "250/250 [==============================] - 0s 999us/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 476/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8655\n",
            "Epoch 477/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8659\n",
            "Epoch 478/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8649\n",
            "Epoch 479/500\n",
            "250/250 [==============================] - 0s 990us/step - loss: 0.3272 - accuracy: 0.8655\n",
            "Epoch 480/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8650\n",
            "Epoch 481/500\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.3277 - accuracy: 0.8656\n",
            "Epoch 482/500\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3275 - accuracy: 0.8649\n",
            "Epoch 483/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8648\n",
            "Epoch 484/500\n",
            "250/250 [==============================] - 0s 984us/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 485/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8650\n",
            "Epoch 486/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8658\n",
            "Epoch 487/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8646\n",
            "Epoch 488/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8661\n",
            "Epoch 489/500\n",
            "250/250 [==============================] - 0s 978us/step - loss: 0.3281 - accuracy: 0.8643\n",
            "Epoch 490/500\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3278 - accuracy: 0.8640\n",
            "Epoch 491/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8650\n",
            "Epoch 492/500\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3278 - accuracy: 0.8648\n",
            "Epoch 493/500\n",
            "250/250 [==============================] - 0s 978us/step - loss: 0.3282 - accuracy: 0.8649\n",
            "Epoch 494/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8652\n",
            "Epoch 495/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8650\n",
            "Epoch 496/500\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.3273 - accuracy: 0.8671\n",
            "Epoch 497/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8651\n",
            "Epoch 498/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8665\n",
            "Epoch 499/500\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3279 - accuracy: 0.8646\n",
            "Epoch 500/500\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f70307b2e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lDeVkCEzpog"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlKQRydHwe9f"
      },
      "source": [
        "**Part 4 - Making the predictions and evaluating the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46SkdmkDwjHf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP_m5ErIwkB2"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "Important note 1: Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "Important note 2: Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns.For Male you should encode as '1' and for Female '0'\n",
        "\n",
        "Assignment\n",
        "\n",
        "Use our ANN model to predict if the customers with the following informations will leave the bank:\n",
        "\n",
        "Geography: France,Germany,Spain\n",
        "\n",
        "Credit Score: 600,800,700\n",
        "\n",
        "Gender: Male,Female,Male\n",
        "\n",
        "Age: 40,50,35,years old\n",
        "\n",
        "Tenure: 3,5,4 years\n",
        "\n",
        "Balance: $ 60000,70000,0\n",
        "\n",
        "Number of Products: 2,1,0\n",
        "\n",
        "Does this customer have a credit card ? Yes,No,No\n",
        "\n",
        "Is this customer an Active Member: Yes,No,No\n",
        "\n",
        "Estimated Salary: $ 50000,10000,0\n",
        "\n",
        "So, should we say goodbye to that customer ?\n",
        "\n",
        "Sample If value is greater than 0.5 - True\n",
        "Else -False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uST8BsW5wpJm",
        "outputId": "927fa6a9-a161-4444-ebb4-a264e522d8ad"
      },
      "source": [
        "print(ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]]))>  0.5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf4GzUEcwZcI",
        "outputId": "399dde63-6912-4d81-d31f-ec9da7387dc8"
      },
      "source": [
        "print(ann.predict(sc.transform([[0,1,0,800,0,50,5,70000,1,0,0,10000]]))>  0.5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV_GV2RrwwG5",
        "outputId": "3b48f78b-e47b-4808-8495-385c108cf6cf"
      },
      "source": [
        "print(ann.predict(sc.transform([[0,0,1,700,0,35,4,0,0,0,0,0]]))>0.5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiqryBE2xgwO"
      },
      "source": [
        "**Predicting the Test set results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB7RxLtYxoML",
        "outputId": "09dc06e8-667c-42a2-c8fa-fd50dc563df9"
      },
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1qY19RbxtBu",
        "outputId": "fb583c1e-fe4f-4b28-9f22-a9ac32092562"
      },
      "source": [
        "y_pred[0:10]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cfjAgQtxwI0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS9EbnHyxzj_",
        "outputId": "63214465-2864-447d-9293-15b79c048c8b"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5itPMRx1be"
      },
      "source": [
        "**Making the Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xon54uMNx6bW",
        "outputId": "413c3c1f-b9b2-4640-9794-1bb0a7daaaf3"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1507   88]\n",
            " [ 191  214]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YljpYrYcyHA7",
        "outputId": "3400bb47-397b-4896-c83b-ecf2bb5d22f7"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "Te41DrhjyKrl",
        "outputId": "823fbb40-8817-4770-b724-0b2558262025"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "LABELS = ['Not Left Bank', 'Left Bank'] \n",
        "plt.figure(figsize =(8, 8)) \n",
        "sns.heatmap(cm, xticklabels = LABELS,  \n",
        "            yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
        "plt.title(\"Confusion matrix\") \n",
        "plt.ylabel('True class') \n",
        "plt.xlabel('Predicted class') \n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn53Wl2ZzjaB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN4lA-MeucyQ"
      },
      "source": [
        ""
      ]
    }
  ]
}