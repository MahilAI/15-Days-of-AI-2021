{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnjanYajur/Mahil-AI/blob/master/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkJoQBkUIHC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaTwK7ojXr2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "599d1cff-b067-4755-9d83-add0c390b2c2"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUkhkMfU4wq"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYP9cQTWbzuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d62bd1-1cef-44c3-e4c1-9bbf55f6f14d"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38vKGE6Nb2RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f0b11f-8ff0-404f-b6d2-c2876aab3337"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "aLv7t1AhSSfh",
        "outputId": "e73f7491-00bd-4d92-d8c1-9626149d538e"
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>15574012</td>\n",
              "      <td>Chu</td>\n",
              "      <td>645</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>8</td>\n",
              "      <td>113755.78</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>149756.71</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>15592531</td>\n",
              "      <td>Bartlett</td>\n",
              "      <td>822</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>50</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10062.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>15656148</td>\n",
              "      <td>Obinna</td>\n",
              "      <td>376</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Female</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>115046.74</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>119346.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>15792365</td>\n",
              "      <td>He</td>\n",
              "      <td>501</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>142051.07</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74940.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>15592389</td>\n",
              "      <td>H?</td>\n",
              "      <td>684</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>134603.88</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>71725.73</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "5          6    15574012       Chu  ...               0       149756.71      1\n",
              "6          7    15592531  Bartlett  ...               1        10062.80      0\n",
              "7          8    15656148    Obinna  ...               0       119346.88      1\n",
              "8          9    15792365        He  ...               1        74940.50      0\n",
              "9         10    15592389        H?  ...               1        71725.73      0\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVKWXxLbczC"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M1KboxFb6OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a3e301-4837-4d67-8bdb-562f9ca31890"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1 ... 0 1 112542.58]\n",
            " [1.0 0.0 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMXC8-KMVirw"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcxwEon-b8nV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8aacc76-a856-4e6a-aca6-19e6a499a8de"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 1.0 ... 1 1 101348.88]\n",
            " [1.0 0.0 0.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 1.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 1.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 1.0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQMGcJEvTGkP",
        "outputId": "334b2757-18cf-4f22-db56-0a3387b9f8f9"
      },
      "source": [
        "print(X[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0 0.0 1.0 0 619 0 42 2 0.0 1 1 1 101348.88]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHQWWD89TGs7",
        "outputId": "79498309-c604-4da4-c9a2-63bf5721f49a"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-TDt0Y_XEfc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCrE00rV8Sk"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad7ZM3_jT3BU",
        "outputId": "cac7c26b-2275-4cb2-9695-fe8f634240d5"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.5698444  -0.5698444  -1.01460667  1.74309049  0.16958176 -1.09168714\n",
            " -0.46460796  0.00666099 -1.21571749  0.8095029   0.64259497 -1.03227043\n",
            "  1.10643166]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dtrScHxXQox"
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bppGycBXYCQr"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JneR0u0sYRTd"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3x41RBYfvY"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG3RrwDXZEaS"
      },
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHZ-LKv_ZRb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8802abaf-e0c6-4e02-ca62-215b0f994df8"
      },
      "source": [
        "#train on 100,500,1000 epochs\n",
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 1000)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8631\n",
            "Epoch 2/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8625\n",
            "Epoch 3/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8646\n",
            "Epoch 4/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8636\n",
            "Epoch 5/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8631\n",
            "Epoch 6/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8629\n",
            "Epoch 7/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8654\n",
            "Epoch 8/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8635\n",
            "Epoch 9/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8626\n",
            "Epoch 10/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8641\n",
            "Epoch 11/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8608\n",
            "Epoch 12/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8656\n",
            "Epoch 13/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8625\n",
            "Epoch 14/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8629\n",
            "Epoch 15/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8636\n",
            "Epoch 16/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8641\n",
            "Epoch 17/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8640\n",
            "Epoch 18/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8625\n",
            "Epoch 19/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8634\n",
            "Epoch 20/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8625\n",
            "Epoch 21/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8625\n",
            "Epoch 22/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8637\n",
            "Epoch 23/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8627\n",
            "Epoch 24/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8616\n",
            "Epoch 25/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8631\n",
            "Epoch 26/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8630\n",
            "Epoch 27/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8644\n",
            "Epoch 28/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8639\n",
            "Epoch 29/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8635\n",
            "Epoch 30/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8631\n",
            "Epoch 31/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8641\n",
            "Epoch 32/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8637\n",
            "Epoch 33/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8618\n",
            "Epoch 34/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8637\n",
            "Epoch 35/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8631\n",
            "Epoch 36/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8633\n",
            "Epoch 37/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8645\n",
            "Epoch 38/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8640\n",
            "Epoch 39/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8626\n",
            "Epoch 40/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8645\n",
            "Epoch 41/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8641\n",
            "Epoch 42/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8631\n",
            "Epoch 43/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8643\n",
            "Epoch 44/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8636\n",
            "Epoch 45/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8637\n",
            "Epoch 46/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8646\n",
            "Epoch 47/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8619\n",
            "Epoch 48/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8636\n",
            "Epoch 49/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8634\n",
            "Epoch 50/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8634\n",
            "Epoch 51/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8649\n",
            "Epoch 52/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8639\n",
            "Epoch 53/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8627\n",
            "Epoch 54/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8635\n",
            "Epoch 55/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8625\n",
            "Epoch 56/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8637\n",
            "Epoch 57/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8645\n",
            "Epoch 58/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8627\n",
            "Epoch 59/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8639\n",
            "Epoch 60/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8631\n",
            "Epoch 61/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8625\n",
            "Epoch 62/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8622\n",
            "Epoch 63/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8627\n",
            "Epoch 64/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8630\n",
            "Epoch 65/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8625\n",
            "Epoch 66/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8644\n",
            "Epoch 67/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8637\n",
            "Epoch 68/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8654\n",
            "Epoch 69/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8629\n",
            "Epoch 70/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8626\n",
            "Epoch 71/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8627\n",
            "Epoch 72/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8631\n",
            "Epoch 73/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8640\n",
            "Epoch 74/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8629\n",
            "Epoch 75/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8626\n",
            "Epoch 76/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8635\n",
            "Epoch 77/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8616\n",
            "Epoch 78/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8641\n",
            "Epoch 79/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8641\n",
            "Epoch 80/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8634\n",
            "Epoch 81/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8629\n",
            "Epoch 82/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8637\n",
            "Epoch 83/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8637\n",
            "Epoch 84/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8629\n",
            "Epoch 85/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8640\n",
            "Epoch 86/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8629\n",
            "Epoch 87/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8644\n",
            "Epoch 88/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8631\n",
            "Epoch 89/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8641\n",
            "Epoch 90/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8627\n",
            "Epoch 91/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8622\n",
            "Epoch 92/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8620\n",
            "Epoch 93/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8640\n",
            "Epoch 94/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8639\n",
            "Epoch 95/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8635\n",
            "Epoch 96/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8631\n",
            "Epoch 97/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8624\n",
            "Epoch 98/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8634\n",
            "Epoch 99/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8624\n",
            "Epoch 100/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8630\n",
            "Epoch 101/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8630\n",
            "Epoch 102/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8634\n",
            "Epoch 103/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8645\n",
            "Epoch 104/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8622\n",
            "Epoch 105/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8614\n",
            "Epoch 106/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8622\n",
            "Epoch 107/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8625\n",
            "Epoch 108/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8629\n",
            "Epoch 109/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8636\n",
            "Epoch 110/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8626\n",
            "Epoch 111/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8646\n",
            "Epoch 112/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8627\n",
            "Epoch 113/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8643\n",
            "Epoch 114/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8644\n",
            "Epoch 115/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8635\n",
            "Epoch 116/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8631\n",
            "Epoch 117/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8621\n",
            "Epoch 118/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8626\n",
            "Epoch 119/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8635\n",
            "Epoch 120/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8634\n",
            "Epoch 121/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8622\n",
            "Epoch 122/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8634\n",
            "Epoch 123/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8635\n",
            "Epoch 124/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8629\n",
            "Epoch 125/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8641\n",
            "Epoch 126/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8637\n",
            "Epoch 127/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8627\n",
            "Epoch 128/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8635\n",
            "Epoch 129/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8646\n",
            "Epoch 130/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8641\n",
            "Epoch 131/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8624\n",
            "Epoch 132/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8637\n",
            "Epoch 133/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8637\n",
            "Epoch 134/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8636\n",
            "Epoch 135/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8637\n",
            "Epoch 136/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8624\n",
            "Epoch 137/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8633\n",
            "Epoch 138/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8626\n",
            "Epoch 139/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8639\n",
            "Epoch 140/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8629\n",
            "Epoch 141/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8644\n",
            "Epoch 142/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8634\n",
            "Epoch 143/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8625\n",
            "Epoch 144/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8636\n",
            "Epoch 145/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8631\n",
            "Epoch 146/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8624\n",
            "Epoch 147/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8635\n",
            "Epoch 148/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8625\n",
            "Epoch 149/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8626\n",
            "Epoch 150/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8633\n",
            "Epoch 151/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8639\n",
            "Epoch 152/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8635\n",
            "Epoch 153/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8635\n",
            "Epoch 154/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8634\n",
            "Epoch 155/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8627\n",
            "Epoch 156/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8641\n",
            "Epoch 157/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8650\n",
            "Epoch 158/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8630\n",
            "Epoch 159/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8619\n",
            "Epoch 160/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8627\n",
            "Epoch 161/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8637\n",
            "Epoch 162/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8618\n",
            "Epoch 163/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8630\n",
            "Epoch 164/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8634\n",
            "Epoch 165/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8648\n",
            "Epoch 166/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8644\n",
            "Epoch 167/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8649\n",
            "Epoch 168/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8618\n",
            "Epoch 169/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8627\n",
            "Epoch 170/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8635\n",
            "Epoch 171/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8622\n",
            "Epoch 172/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8624\n",
            "Epoch 173/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8631\n",
            "Epoch 174/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8622\n",
            "Epoch 175/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8633\n",
            "Epoch 176/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8639\n",
            "Epoch 177/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8621\n",
            "Epoch 178/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8627\n",
            "Epoch 179/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8637\n",
            "Epoch 180/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8631\n",
            "Epoch 181/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8637\n",
            "Epoch 182/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8634\n",
            "Epoch 183/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8640\n",
            "Epoch 184/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8629\n",
            "Epoch 185/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8624\n",
            "Epoch 186/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8634\n",
            "Epoch 187/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8627\n",
            "Epoch 188/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8631\n",
            "Epoch 189/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8631\n",
            "Epoch 190/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8630\n",
            "Epoch 191/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8627\n",
            "Epoch 192/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8635\n",
            "Epoch 193/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8643\n",
            "Epoch 194/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8634\n",
            "Epoch 195/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8637\n",
            "Epoch 196/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8622\n",
            "Epoch 197/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8637\n",
            "Epoch 198/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8664\n",
            "Epoch 199/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8629\n",
            "Epoch 200/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8641\n",
            "Epoch 201/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8634\n",
            "Epoch 202/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8629\n",
            "Epoch 203/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8635\n",
            "Epoch 204/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8616\n",
            "Epoch 205/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8644\n",
            "Epoch 206/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8631\n",
            "Epoch 207/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8627\n",
            "Epoch 208/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8635\n",
            "Epoch 209/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8640\n",
            "Epoch 210/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8622\n",
            "Epoch 211/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8633\n",
            "Epoch 212/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8619\n",
            "Epoch 213/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8629\n",
            "Epoch 214/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8624\n",
            "Epoch 215/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8630\n",
            "Epoch 216/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8641\n",
            "Epoch 217/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8640\n",
            "Epoch 218/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8635\n",
            "Epoch 219/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8621\n",
            "Epoch 220/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8646\n",
            "Epoch 221/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8619\n",
            "Epoch 222/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8634\n",
            "Epoch 223/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8626\n",
            "Epoch 224/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8635\n",
            "Epoch 225/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8633\n",
            "Epoch 226/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8633\n",
            "Epoch 227/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8614\n",
            "Epoch 228/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8625\n",
            "Epoch 229/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8627\n",
            "Epoch 230/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8634\n",
            "Epoch 231/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8643\n",
            "Epoch 232/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8630\n",
            "Epoch 233/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8627\n",
            "Epoch 234/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8631\n",
            "Epoch 235/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8645\n",
            "Epoch 236/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8626\n",
            "Epoch 237/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8627\n",
            "Epoch 238/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8634\n",
            "Epoch 239/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8631\n",
            "Epoch 240/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8639\n",
            "Epoch 241/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8622\n",
            "Epoch 242/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8644\n",
            "Epoch 243/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8648\n",
            "Epoch 244/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8633\n",
            "Epoch 245/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8639\n",
            "Epoch 246/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8621\n",
            "Epoch 247/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8649\n",
            "Epoch 248/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8639\n",
            "Epoch 249/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8640\n",
            "Epoch 250/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8633\n",
            "Epoch 251/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8627\n",
            "Epoch 252/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8630\n",
            "Epoch 253/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8612\n",
            "Epoch 254/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8633\n",
            "Epoch 255/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8634\n",
            "Epoch 256/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8635\n",
            "Epoch 257/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8631\n",
            "Epoch 258/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8639\n",
            "Epoch 259/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8641\n",
            "Epoch 260/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8624\n",
            "Epoch 261/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8630\n",
            "Epoch 262/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8635\n",
            "Epoch 263/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8635\n",
            "Epoch 264/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8616\n",
            "Epoch 265/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8635\n",
            "Epoch 266/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8620\n",
            "Epoch 267/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8629\n",
            "Epoch 268/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8643\n",
            "Epoch 269/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8631\n",
            "Epoch 270/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8630\n",
            "Epoch 271/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8640\n",
            "Epoch 272/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8639\n",
            "Epoch 273/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8625\n",
            "Epoch 274/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8641\n",
            "Epoch 275/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8635\n",
            "Epoch 276/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8639\n",
            "Epoch 277/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8634\n",
            "Epoch 278/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8627\n",
            "Epoch 279/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8633\n",
            "Epoch 280/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8634\n",
            "Epoch 281/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8627\n",
            "Epoch 282/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8624\n",
            "Epoch 283/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8646\n",
            "Epoch 284/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8634\n",
            "Epoch 285/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8633\n",
            "Epoch 286/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8625\n",
            "Epoch 287/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8637\n",
            "Epoch 288/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8643\n",
            "Epoch 289/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8630\n",
            "Epoch 290/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8637\n",
            "Epoch 291/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8621\n",
            "Epoch 292/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8620\n",
            "Epoch 293/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8627\n",
            "Epoch 294/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8635\n",
            "Epoch 295/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8631\n",
            "Epoch 296/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8625\n",
            "Epoch 297/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8629\n",
            "Epoch 298/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8627\n",
            "Epoch 299/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8626\n",
            "Epoch 300/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8624\n",
            "Epoch 301/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8633\n",
            "Epoch 302/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8614\n",
            "Epoch 303/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8640\n",
            "Epoch 304/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8639\n",
            "Epoch 305/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8631\n",
            "Epoch 306/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8631\n",
            "Epoch 307/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8641\n",
            "Epoch 308/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8646\n",
            "Epoch 309/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8631\n",
            "Epoch 310/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8627\n",
            "Epoch 311/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8649\n",
            "Epoch 312/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8633\n",
            "Epoch 313/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8645\n",
            "Epoch 314/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8646\n",
            "Epoch 315/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8624\n",
            "Epoch 316/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8631\n",
            "Epoch 317/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8622\n",
            "Epoch 318/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8635\n",
            "Epoch 319/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8634\n",
            "Epoch 320/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8625\n",
            "Epoch 321/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8626\n",
            "Epoch 322/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8636\n",
            "Epoch 323/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8640\n",
            "Epoch 324/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8625\n",
            "Epoch 325/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8635\n",
            "Epoch 326/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8635\n",
            "Epoch 327/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8633\n",
            "Epoch 328/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8635\n",
            "Epoch 329/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8633\n",
            "Epoch 330/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8629\n",
            "Epoch 331/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8636\n",
            "Epoch 332/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8652\n",
            "Epoch 333/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8641\n",
            "Epoch 334/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8643\n",
            "Epoch 335/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8637\n",
            "Epoch 336/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8637\n",
            "Epoch 337/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8650\n",
            "Epoch 338/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8627\n",
            "Epoch 339/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8626\n",
            "Epoch 340/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8624\n",
            "Epoch 341/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8634\n",
            "Epoch 342/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8621\n",
            "Epoch 343/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8630\n",
            "Epoch 344/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8630\n",
            "Epoch 345/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8639\n",
            "Epoch 346/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8634\n",
            "Epoch 347/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8635\n",
            "Epoch 348/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8631\n",
            "Epoch 349/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8634\n",
            "Epoch 350/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8636\n",
            "Epoch 351/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8636\n",
            "Epoch 352/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8627\n",
            "Epoch 353/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8629\n",
            "Epoch 354/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8645\n",
            "Epoch 355/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8629\n",
            "Epoch 356/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8624\n",
            "Epoch 357/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8629\n",
            "Epoch 358/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8624\n",
            "Epoch 359/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8639\n",
            "Epoch 360/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8648\n",
            "Epoch 361/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8622\n",
            "Epoch 362/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8655\n",
            "Epoch 363/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8629\n",
            "Epoch 364/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8643\n",
            "Epoch 365/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8636\n",
            "Epoch 366/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8646\n",
            "Epoch 367/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8631\n",
            "Epoch 368/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8634\n",
            "Epoch 369/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8634\n",
            "Epoch 370/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8643\n",
            "Epoch 371/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8648\n",
            "Epoch 372/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8631\n",
            "Epoch 373/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8641\n",
            "Epoch 374/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8646\n",
            "Epoch 375/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8643\n",
            "Epoch 376/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8630\n",
            "Epoch 377/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8634\n",
            "Epoch 378/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8616\n",
            "Epoch 379/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8655\n",
            "Epoch 380/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8636\n",
            "Epoch 381/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8626\n",
            "Epoch 382/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8633\n",
            "Epoch 383/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8637\n",
            "Epoch 384/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8614\n",
            "Epoch 385/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8636\n",
            "Epoch 386/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8630\n",
            "Epoch 387/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8631\n",
            "Epoch 388/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8645\n",
            "Epoch 389/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8633\n",
            "Epoch 390/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8645\n",
            "Epoch 391/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8640\n",
            "Epoch 392/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8643\n",
            "Epoch 393/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8633\n",
            "Epoch 394/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8634\n",
            "Epoch 395/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8636\n",
            "Epoch 396/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8645\n",
            "Epoch 397/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8641\n",
            "Epoch 398/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8637\n",
            "Epoch 399/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8625\n",
            "Epoch 400/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8627\n",
            "Epoch 401/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8633\n",
            "Epoch 402/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8641\n",
            "Epoch 403/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8629\n",
            "Epoch 404/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8634\n",
            "Epoch 405/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8634\n",
            "Epoch 406/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8627\n",
            "Epoch 407/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8631\n",
            "Epoch 408/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8643\n",
            "Epoch 409/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8641\n",
            "Epoch 410/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8625\n",
            "Epoch 411/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8643\n",
            "Epoch 412/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8636\n",
            "Epoch 413/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8639\n",
            "Epoch 414/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8630\n",
            "Epoch 415/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8625\n",
            "Epoch 416/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8643\n",
            "Epoch 417/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8640\n",
            "Epoch 418/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8636\n",
            "Epoch 419/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8644\n",
            "Epoch 420/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8637\n",
            "Epoch 421/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8644\n",
            "Epoch 422/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8637\n",
            "Epoch 423/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8629\n",
            "Epoch 424/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8637\n",
            "Epoch 425/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8633\n",
            "Epoch 426/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8644\n",
            "Epoch 427/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8640\n",
            "Epoch 428/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8621\n",
            "Epoch 429/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8630\n",
            "Epoch 430/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8636\n",
            "Epoch 431/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8644\n",
            "Epoch 432/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8631\n",
            "Epoch 433/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8643\n",
            "Epoch 434/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8630\n",
            "Epoch 435/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8646\n",
            "Epoch 436/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8631\n",
            "Epoch 437/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8621\n",
            "Epoch 438/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8648\n",
            "Epoch 439/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8620\n",
            "Epoch 440/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8643\n",
            "Epoch 441/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8631\n",
            "Epoch 442/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8637\n",
            "Epoch 443/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8630\n",
            "Epoch 444/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8618\n",
            "Epoch 445/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8627\n",
            "Epoch 446/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8625\n",
            "Epoch 447/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8633\n",
            "Epoch 448/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8621\n",
            "Epoch 449/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8654\n",
            "Epoch 450/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8640\n",
            "Epoch 451/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8637\n",
            "Epoch 452/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8636\n",
            "Epoch 453/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8631\n",
            "Epoch 454/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8639\n",
            "Epoch 455/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8646\n",
            "Epoch 456/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8637\n",
            "Epoch 457/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8637\n",
            "Epoch 458/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8633\n",
            "Epoch 459/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8635\n",
            "Epoch 460/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8643\n",
            "Epoch 461/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8630\n",
            "Epoch 462/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8624\n",
            "Epoch 463/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8645\n",
            "Epoch 464/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8637\n",
            "Epoch 465/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8622\n",
            "Epoch 466/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8630\n",
            "Epoch 467/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8634\n",
            "Epoch 468/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8633\n",
            "Epoch 469/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8649\n",
            "Epoch 470/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8627\n",
            "Epoch 471/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8643\n",
            "Epoch 472/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8631\n",
            "Epoch 473/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8633\n",
            "Epoch 474/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8626\n",
            "Epoch 475/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8646\n",
            "Epoch 476/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8631\n",
            "Epoch 477/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8634\n",
            "Epoch 478/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8651\n",
            "Epoch 479/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8621\n",
            "Epoch 480/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8634\n",
            "Epoch 481/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8630\n",
            "Epoch 482/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8625\n",
            "Epoch 483/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8633\n",
            "Epoch 484/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8640\n",
            "Epoch 485/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8639\n",
            "Epoch 486/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8630\n",
            "Epoch 487/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8646\n",
            "Epoch 488/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8637\n",
            "Epoch 489/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8635\n",
            "Epoch 490/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8631\n",
            "Epoch 491/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8635\n",
            "Epoch 492/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8630\n",
            "Epoch 493/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8619\n",
            "Epoch 494/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8636\n",
            "Epoch 495/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8635\n",
            "Epoch 496/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8641\n",
            "Epoch 497/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8629\n",
            "Epoch 498/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8641\n",
            "Epoch 499/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8637\n",
            "Epoch 500/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8645\n",
            "Epoch 501/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8635\n",
            "Epoch 502/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8636\n",
            "Epoch 503/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8640\n",
            "Epoch 504/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8631\n",
            "Epoch 505/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8633\n",
            "Epoch 506/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8649\n",
            "Epoch 507/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8626\n",
            "Epoch 508/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8637\n",
            "Epoch 509/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8644\n",
            "Epoch 510/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8639\n",
            "Epoch 511/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8649\n",
            "Epoch 512/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8631\n",
            "Epoch 513/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8629\n",
            "Epoch 514/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8634\n",
            "Epoch 515/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8627\n",
            "Epoch 516/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8636\n",
            "Epoch 517/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8626\n",
            "Epoch 518/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8620\n",
            "Epoch 519/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8637\n",
            "Epoch 520/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8645\n",
            "Epoch 521/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8636\n",
            "Epoch 522/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8633\n",
            "Epoch 523/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8633\n",
            "Epoch 524/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8637\n",
            "Epoch 525/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8633\n",
            "Epoch 526/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8641\n",
            "Epoch 527/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8637\n",
            "Epoch 528/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8636\n",
            "Epoch 529/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8627\n",
            "Epoch 530/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8649\n",
            "Epoch 531/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8633\n",
            "Epoch 532/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8630\n",
            "Epoch 533/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8631\n",
            "Epoch 534/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8648\n",
            "Epoch 535/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8624\n",
            "Epoch 536/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8655\n",
            "Epoch 537/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8627\n",
            "Epoch 538/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8640\n",
            "Epoch 539/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8630\n",
            "Epoch 540/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8633\n",
            "Epoch 541/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8626\n",
            "Epoch 542/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8620\n",
            "Epoch 543/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8631\n",
            "Epoch 544/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8640\n",
            "Epoch 545/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8640\n",
            "Epoch 546/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8649\n",
            "Epoch 547/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8634\n",
            "Epoch 548/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8627\n",
            "Epoch 549/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8636\n",
            "Epoch 550/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8635\n",
            "Epoch 551/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8626\n",
            "Epoch 552/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8641\n",
            "Epoch 553/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8639\n",
            "Epoch 554/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8624\n",
            "Epoch 555/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8634\n",
            "Epoch 556/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8634\n",
            "Epoch 557/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8652\n",
            "Epoch 558/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8637\n",
            "Epoch 559/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8625\n",
            "Epoch 560/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8644\n",
            "Epoch 561/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8659\n",
            "Epoch 562/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8627\n",
            "Epoch 563/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8641\n",
            "Epoch 564/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8648\n",
            "Epoch 565/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8636\n",
            "Epoch 566/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8630\n",
            "Epoch 567/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8626\n",
            "Epoch 568/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8636\n",
            "Epoch 569/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8635\n",
            "Epoch 570/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8636\n",
            "Epoch 571/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8639\n",
            "Epoch 572/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8620\n",
            "Epoch 573/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8641\n",
            "Epoch 574/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8630\n",
            "Epoch 575/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8640\n",
            "Epoch 576/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8626\n",
            "Epoch 577/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8618\n",
            "Epoch 578/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8639\n",
            "Epoch 579/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8631\n",
            "Epoch 580/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8626\n",
            "Epoch 581/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8634\n",
            "Epoch 582/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8636\n",
            "Epoch 583/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8629\n",
            "Epoch 584/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8630\n",
            "Epoch 585/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8639\n",
            "Epoch 586/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8652\n",
            "Epoch 587/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8640\n",
            "Epoch 588/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8635\n",
            "Epoch 589/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8639\n",
            "Epoch 590/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8630\n",
            "Epoch 591/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8631\n",
            "Epoch 592/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8636\n",
            "Epoch 593/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8633\n",
            "Epoch 594/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8646\n",
            "Epoch 595/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8636\n",
            "Epoch 596/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8630\n",
            "Epoch 597/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8631\n",
            "Epoch 598/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8627\n",
            "Epoch 599/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8640\n",
            "Epoch 600/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8630\n",
            "Epoch 601/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8635\n",
            "Epoch 602/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8631\n",
            "Epoch 603/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8636\n",
            "Epoch 604/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8641\n",
            "Epoch 605/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8643\n",
            "Epoch 606/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8640\n",
            "Epoch 607/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8627\n",
            "Epoch 608/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8630\n",
            "Epoch 609/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8646\n",
            "Epoch 610/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8643\n",
            "Epoch 611/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8624\n",
            "Epoch 612/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8636\n",
            "Epoch 613/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8641\n",
            "Epoch 614/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8650\n",
            "Epoch 615/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8631\n",
            "Epoch 616/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8639\n",
            "Epoch 617/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8633\n",
            "Epoch 618/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8634\n",
            "Epoch 619/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8627\n",
            "Epoch 620/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8639\n",
            "Epoch 621/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8630\n",
            "Epoch 622/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8637\n",
            "Epoch 623/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8639\n",
            "Epoch 624/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8649\n",
            "Epoch 625/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8637\n",
            "Epoch 626/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8622\n",
            "Epoch 627/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8620\n",
            "Epoch 628/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8641\n",
            "Epoch 629/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8634\n",
            "Epoch 630/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8641\n",
            "Epoch 631/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8630\n",
            "Epoch 632/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8627\n",
            "Epoch 633/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8631\n",
            "Epoch 634/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8640\n",
            "Epoch 635/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8634\n",
            "Epoch 636/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8636\n",
            "Epoch 637/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8641\n",
            "Epoch 638/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8633\n",
            "Epoch 639/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8633\n",
            "Epoch 640/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8627\n",
            "Epoch 641/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8625\n",
            "Epoch 642/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8625\n",
            "Epoch 643/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8635\n",
            "Epoch 644/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8637\n",
            "Epoch 645/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8626\n",
            "Epoch 646/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8648\n",
            "Epoch 647/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8636\n",
            "Epoch 648/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8639\n",
            "Epoch 649/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8643\n",
            "Epoch 650/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8630\n",
            "Epoch 651/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8649\n",
            "Epoch 652/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8643\n",
            "Epoch 653/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8639\n",
            "Epoch 654/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8621\n",
            "Epoch 655/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8639\n",
            "Epoch 656/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8636\n",
            "Epoch 657/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8636\n",
            "Epoch 658/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8629\n",
            "Epoch 659/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8627\n",
            "Epoch 660/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8654\n",
            "Epoch 661/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8644\n",
            "Epoch 662/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8627\n",
            "Epoch 663/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8648\n",
            "Epoch 664/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8644\n",
            "Epoch 665/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8622\n",
            "Epoch 666/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8629\n",
            "Epoch 667/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8625\n",
            "Epoch 668/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8629\n",
            "Epoch 669/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8635\n",
            "Epoch 670/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8630\n",
            "Epoch 671/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8635\n",
            "Epoch 672/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8634\n",
            "Epoch 673/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8634\n",
            "Epoch 674/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8633\n",
            "Epoch 675/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8619\n",
            "Epoch 676/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8634\n",
            "Epoch 677/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8620\n",
            "Epoch 678/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8635\n",
            "Epoch 679/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8643\n",
            "Epoch 680/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8629\n",
            "Epoch 681/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8627\n",
            "Epoch 682/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8625\n",
            "Epoch 683/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8644\n",
            "Epoch 684/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8637\n",
            "Epoch 685/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8639\n",
            "Epoch 686/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8636\n",
            "Epoch 687/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8637\n",
            "Epoch 688/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8622\n",
            "Epoch 689/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8630\n",
            "Epoch 690/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8631\n",
            "Epoch 691/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8621\n",
            "Epoch 692/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8650\n",
            "Epoch 693/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8634\n",
            "Epoch 694/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8641\n",
            "Epoch 695/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8636\n",
            "Epoch 696/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8636\n",
            "Epoch 697/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8621\n",
            "Epoch 698/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8629\n",
            "Epoch 699/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8636\n",
            "Epoch 700/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8624\n",
            "Epoch 701/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8644\n",
            "Epoch 702/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8624\n",
            "Epoch 703/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8639\n",
            "Epoch 704/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8629\n",
            "Epoch 705/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8639\n",
            "Epoch 706/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8637\n",
            "Epoch 707/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8641\n",
            "Epoch 708/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8626\n",
            "Epoch 709/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8636\n",
            "Epoch 710/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8648\n",
            "Epoch 711/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8637\n",
            "Epoch 712/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8626\n",
            "Epoch 713/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8636\n",
            "Epoch 714/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8631\n",
            "Epoch 715/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8636\n",
            "Epoch 716/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8634\n",
            "Epoch 717/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8634\n",
            "Epoch 718/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8633\n",
            "Epoch 719/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8629\n",
            "Epoch 720/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8620\n",
            "Epoch 721/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8627\n",
            "Epoch 722/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8635\n",
            "Epoch 723/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8639\n",
            "Epoch 724/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8636\n",
            "Epoch 725/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8626\n",
            "Epoch 726/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8646\n",
            "Epoch 727/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8644\n",
            "Epoch 728/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8634\n",
            "Epoch 729/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8626\n",
            "Epoch 730/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8626\n",
            "Epoch 731/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8640\n",
            "Epoch 732/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8627\n",
            "Epoch 733/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8622\n",
            "Epoch 734/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8636\n",
            "Epoch 735/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8635\n",
            "Epoch 736/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8641\n",
            "Epoch 737/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8633\n",
            "Epoch 738/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8620\n",
            "Epoch 739/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8639\n",
            "Epoch 740/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8637\n",
            "Epoch 741/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8629\n",
            "Epoch 742/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8634\n",
            "Epoch 743/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8640\n",
            "Epoch 744/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8636\n",
            "Epoch 745/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8630\n",
            "Epoch 746/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8643\n",
            "Epoch 747/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8640\n",
            "Epoch 748/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8630\n",
            "Epoch 749/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8635\n",
            "Epoch 750/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8630\n",
            "Epoch 751/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8631\n",
            "Epoch 752/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8634\n",
            "Epoch 753/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8627\n",
            "Epoch 754/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8633\n",
            "Epoch 755/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8630\n",
            "Epoch 756/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8636\n",
            "Epoch 757/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8634\n",
            "Epoch 758/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8633\n",
            "Epoch 759/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8629\n",
            "Epoch 760/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8635\n",
            "Epoch 761/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8643\n",
            "Epoch 762/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8635\n",
            "Epoch 763/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8633\n",
            "Epoch 764/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8633\n",
            "Epoch 765/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8645\n",
            "Epoch 766/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8625\n",
            "Epoch 767/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8648\n",
            "Epoch 768/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8641\n",
            "Epoch 769/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8639\n",
            "Epoch 770/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8649\n",
            "Epoch 771/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8635\n",
            "Epoch 772/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8636\n",
            "Epoch 773/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8640\n",
            "Epoch 774/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8627\n",
            "Epoch 775/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8636\n",
            "Epoch 776/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8631\n",
            "Epoch 777/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8622\n",
            "Epoch 778/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8627\n",
            "Epoch 779/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8644\n",
            "Epoch 780/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8627\n",
            "Epoch 781/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8635\n",
            "Epoch 782/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8629\n",
            "Epoch 783/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8640\n",
            "Epoch 784/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8646\n",
            "Epoch 785/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8645\n",
            "Epoch 786/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8624\n",
            "Epoch 787/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8637\n",
            "Epoch 788/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8637\n",
            "Epoch 789/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8626\n",
            "Epoch 790/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8629\n",
            "Epoch 791/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8634\n",
            "Epoch 792/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8648\n",
            "Epoch 793/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8644\n",
            "Epoch 794/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8631\n",
            "Epoch 795/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8639\n",
            "Epoch 796/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8630\n",
            "Epoch 797/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8633\n",
            "Epoch 798/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8627\n",
            "Epoch 799/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8620\n",
            "Epoch 800/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8630\n",
            "Epoch 801/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8626\n",
            "Epoch 802/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8634\n",
            "Epoch 803/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8625\n",
            "Epoch 804/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8641\n",
            "Epoch 805/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8627\n",
            "Epoch 806/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8650\n",
            "Epoch 807/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8639\n",
            "Epoch 808/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8639\n",
            "Epoch 809/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8618\n",
            "Epoch 810/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8636\n",
            "Epoch 811/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8636\n",
            "Epoch 812/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8631\n",
            "Epoch 813/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8650\n",
            "Epoch 814/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8640\n",
            "Epoch 815/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8631\n",
            "Epoch 816/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8636\n",
            "Epoch 817/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8661\n",
            "Epoch 818/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8648\n",
            "Epoch 819/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8641\n",
            "Epoch 820/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8631\n",
            "Epoch 821/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8636\n",
            "Epoch 822/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8639\n",
            "Epoch 823/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8634\n",
            "Epoch 824/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8640\n",
            "Epoch 825/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8635\n",
            "Epoch 826/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8627\n",
            "Epoch 827/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8634\n",
            "Epoch 828/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8645\n",
            "Epoch 829/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8622\n",
            "Epoch 830/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8631\n",
            "Epoch 831/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8641\n",
            "Epoch 832/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8633\n",
            "Epoch 833/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8631\n",
            "Epoch 834/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8631\n",
            "Epoch 835/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8652\n",
            "Epoch 836/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8622\n",
            "Epoch 837/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8627\n",
            "Epoch 838/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8629\n",
            "Epoch 839/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8640\n",
            "Epoch 840/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8637\n",
            "Epoch 841/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8648\n",
            "Epoch 842/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8625\n",
            "Epoch 843/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8649\n",
            "Epoch 844/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8639\n",
            "Epoch 845/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8645\n",
            "Epoch 846/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8641\n",
            "Epoch 847/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8627\n",
            "Epoch 848/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8648\n",
            "Epoch 849/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8620\n",
            "Epoch 850/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8636\n",
            "Epoch 851/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8633\n",
            "Epoch 852/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8650\n",
            "Epoch 853/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8645\n",
            "Epoch 854/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8627\n",
            "Epoch 855/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8639\n",
            "Epoch 856/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8631\n",
            "Epoch 857/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8644\n",
            "Epoch 858/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8648\n",
            "Epoch 859/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8644\n",
            "Epoch 860/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8631\n",
            "Epoch 861/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8635\n",
            "Epoch 862/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8634\n",
            "Epoch 863/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8625\n",
            "Epoch 864/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8645\n",
            "Epoch 865/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8634\n",
            "Epoch 866/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8640\n",
            "Epoch 867/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8635\n",
            "Epoch 868/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8641\n",
            "Epoch 869/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8637\n",
            "Epoch 870/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8639\n",
            "Epoch 871/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8640\n",
            "Epoch 872/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8646\n",
            "Epoch 873/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8639\n",
            "Epoch 874/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8634\n",
            "Epoch 875/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8637\n",
            "Epoch 876/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8644\n",
            "Epoch 877/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8630\n",
            "Epoch 878/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8644\n",
            "Epoch 879/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8630\n",
            "Epoch 880/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8639\n",
            "Epoch 881/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8640\n",
            "Epoch 882/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8631\n",
            "Epoch 883/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8641\n",
            "Epoch 884/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8634\n",
            "Epoch 885/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8629\n",
            "Epoch 886/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8637\n",
            "Epoch 887/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8637\n",
            "Epoch 888/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8637\n",
            "Epoch 889/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8633\n",
            "Epoch 890/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8650\n",
            "Epoch 891/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8650\n",
            "Epoch 892/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8634\n",
            "Epoch 893/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8646\n",
            "Epoch 894/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8634\n",
            "Epoch 895/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8627\n",
            "Epoch 896/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8639\n",
            "Epoch 897/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8633\n",
            "Epoch 898/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8641\n",
            "Epoch 899/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8637\n",
            "Epoch 900/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8629\n",
            "Epoch 901/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8649\n",
            "Epoch 902/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8635\n",
            "Epoch 903/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8649\n",
            "Epoch 904/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8645\n",
            "Epoch 905/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8645\n",
            "Epoch 906/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8636\n",
            "Epoch 907/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8631\n",
            "Epoch 908/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8648\n",
            "Epoch 909/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8619\n",
            "Epoch 910/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8648\n",
            "Epoch 911/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8629\n",
            "Epoch 912/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8639\n",
            "Epoch 913/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8634\n",
            "Epoch 914/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8648\n",
            "Epoch 915/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8631\n",
            "Epoch 916/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8648\n",
            "Epoch 917/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8643\n",
            "Epoch 918/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8635\n",
            "Epoch 919/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8645\n",
            "Epoch 920/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8639\n",
            "Epoch 921/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8635\n",
            "Epoch 922/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8648\n",
            "Epoch 923/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8634\n",
            "Epoch 924/1000\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8624\n",
            "Epoch 925/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8636\n",
            "Epoch 926/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8645\n",
            "Epoch 927/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8636\n",
            "Epoch 928/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8643\n",
            "Epoch 929/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8641\n",
            "Epoch 930/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8637\n",
            "Epoch 931/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8645\n",
            "Epoch 932/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8634\n",
            "Epoch 933/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8636\n",
            "Epoch 934/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8636\n",
            "Epoch 935/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8627\n",
            "Epoch 936/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8637\n",
            "Epoch 937/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8636\n",
            "Epoch 938/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8626\n",
            "Epoch 939/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8644\n",
            "Epoch 940/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8636\n",
            "Epoch 941/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8631\n",
            "Epoch 942/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8631\n",
            "Epoch 943/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8621\n",
            "Epoch 944/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8645\n",
            "Epoch 945/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8637\n",
            "Epoch 946/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8639\n",
            "Epoch 947/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8649\n",
            "Epoch 948/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8621\n",
            "Epoch 949/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8634\n",
            "Epoch 950/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8640\n",
            "Epoch 951/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8639\n",
            "Epoch 952/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8643\n",
            "Epoch 953/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8635\n",
            "Epoch 954/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8665\n",
            "Epoch 955/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8641\n",
            "Epoch 956/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8636\n",
            "Epoch 957/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8635\n",
            "Epoch 958/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8626\n",
            "Epoch 959/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8645\n",
            "Epoch 960/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8630\n",
            "Epoch 961/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8629\n",
            "Epoch 962/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8640\n",
            "Epoch 963/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8630\n",
            "Epoch 964/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8629\n",
            "Epoch 965/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8645\n",
            "Epoch 966/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8637\n",
            "Epoch 967/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8645\n",
            "Epoch 968/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8624\n",
            "Epoch 969/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8645\n",
            "Epoch 970/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8639\n",
            "Epoch 971/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8640\n",
            "Epoch 972/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8639\n",
            "Epoch 973/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8635\n",
            "Epoch 974/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8650\n",
            "Epoch 975/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8633\n",
            "Epoch 976/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8636\n",
            "Epoch 977/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8639\n",
            "Epoch 978/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8635\n",
            "Epoch 979/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8631\n",
            "Epoch 980/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8636\n",
            "Epoch 981/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8635\n",
            "Epoch 982/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8639\n",
            "Epoch 983/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8630\n",
            "Epoch 984/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8640\n",
            "Epoch 985/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8648\n",
            "Epoch 986/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8636\n",
            "Epoch 987/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8636\n",
            "Epoch 988/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8654\n",
            "Epoch 989/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8633\n",
            "Epoch 990/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8640\n",
            "Epoch 991/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8633\n",
            "Epoch 992/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8636\n",
            "Epoch 993/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8650\n",
            "Epoch 994/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8641\n",
            "Epoch 995/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8634\n",
            "Epoch 996/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8646\n",
            "Epoch 997/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8635\n",
            "Epoch 998/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8637\n",
            "Epoch 999/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8626\n",
            "Epoch 1000/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa231116e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of 3 observation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns.For Male you should encode as '1' and for Female '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "**Assignment**\n",
        "\n",
        "Use our ANN model to predict if the customers with the following informations will leave the bank: \n",
        "\n",
        "Geography: France,Germany,Spain\n",
        "\n",
        "Credit Score: 600,800,700\n",
        "\n",
        "Gender: Male,Female,Male\n",
        "\n",
        "Age: 40,50,35,years old\n",
        "\n",
        "Tenure: 3,5,4 years\n",
        "\n",
        "Balance: \\$ 60000,70000,0\n",
        "\n",
        "Number of Products: 2,1,0\n",
        "\n",
        "Does this customer have a credit card ? Yes,No,No\n",
        "\n",
        "Is this customer an Active Member: Yes,No,No\n",
        "\n",
        "Estimated Salary: \\$ 50000,10000,0\n",
        "\n",
        "So, should we say goodbye to that customer ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "Sample \n",
        "If value is greater than 0.5 - True  \n",
        "Else -False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-15JL842dxWo"
      },
      "source": [
        "#print(ann.predict(sc.transform([[input your values here]])) is greater than  0.5)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opk6uV7JjjW7",
        "outputId": "a0fd80f8-fe1d-45e1-8732-dbe39b1c7ff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]])) > 0.5)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGAYIx4Zjjgh"
      },
      "source": [
        "print(ann.predict(sc.transform([[0,1,0,800,0,50,5,70000,1,0,0,10000]])) > 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCw4m5bCjkKt"
      },
      "source": [
        "print(ann.predict(sc.transform([[0,0,1,700,1,35,4,0,0,0,0,0]])) > 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyEeQdRZwgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4949c0f2-c28a-425a-a004-d5fa9e07295b"
      },
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjvfa5SBe-eP",
        "outputId": "015a358b-22c3-4027-f38e-380557993834"
      },
      "source": [
        "y_pred[0:10]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KcgCBWbX89C",
        "outputId": "ccf4ce4e-1a83-46f3-ad9b-de69bc985e5d"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6K_r6LaF6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28bad70e-33fb-47cb-e50d-9a3193f1898a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1511   84]\n",
            " [ 196  209]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ut3uyxlOqs",
        "outputId": "b836365b-f4cf-468d-9e34-aefb14f36a98"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "qSRSEMXDjmI2",
        "outputId": "2087968f-2b4a-4b73-a9cd-56382830f82b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "LABELS = ['Not Left Bank', 'Left Bank'] \n",
        "plt.figure(figsize =(8, 8)) \n",
        "sns.heatmap(cm, xticklabels = LABELS,  \n",
        "            yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
        "plt.title(\"Confusion matrix\") \n",
        "plt.ylabel('True class') \n",
        "plt.xlabel('Predicted class') \n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ijy_fUxk-Ga"
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    }
  ]
}
