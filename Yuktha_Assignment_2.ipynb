{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soAOnU7Kv03L"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkJoQBkUIHC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaTwK7ojXr2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49983575-b9c0-4f2b-b1af-65b05c2e90e5"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUkhkMfU4wq"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYP9cQTWbzuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17fd9fd-e7f7-43db-8d6c-734b5bc37590"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38vKGE6Nb2RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc1cb8e-3195-476c-b63c-a912d85f46f2"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLv7t1AhSSfh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "d52d6a99-fd9f-47ec-aed3-7e8f428d4fd0"
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>15574012</td>\n",
              "      <td>Chu</td>\n",
              "      <td>645</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>8</td>\n",
              "      <td>113755.78</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>149756.71</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>15592531</td>\n",
              "      <td>Bartlett</td>\n",
              "      <td>822</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>50</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10062.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>15656148</td>\n",
              "      <td>Obinna</td>\n",
              "      <td>376</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Female</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>115046.74</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>119346.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>15792365</td>\n",
              "      <td>He</td>\n",
              "      <td>501</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>142051.07</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74940.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>15592389</td>\n",
              "      <td>H?</td>\n",
              "      <td>684</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>134603.88</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>71725.73</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "5          6    15574012       Chu  ...               0       149756.71      1\n",
              "6          7    15592531  Bartlett  ...               1        10062.80      0\n",
              "7          8    15656148    Obinna  ...               0       119346.88      1\n",
              "8          9    15792365        He  ...               1        74940.50      0\n",
              "9         10    15592389        H?  ...               1        71725.73      0\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVKWXxLbczC"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M1KboxFb6OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98befc40-ead7-486d-b30a-c4a29dbd4f91"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMXC8-KMVirw"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcxwEon-b8nV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1683a8-2b12-4c23-960c-f4243aab87d6"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQMGcJEvTGkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab075d0-6efa-4b34-b7d8-e44daeeecd00"
      },
      "source": [
        "print(X[0])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0 0.0 0.0 619 0 42 2 0.0 1 1 1 101348.88]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHQWWD89TGs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e396db-49e1-4a10-aa3c-5c72262bdfb9"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-TDt0Y_XEfc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCrE00rV8Sk"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad7ZM3_jT3BU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b30877-f476-454e-fd10-43f78e829507"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.01460667 -0.5698444   1.74309049  0.16958176 -1.09168714 -0.46460796\n",
            "  0.00666099 -1.21571749  0.8095029   0.64259497 -1.03227043  1.10643166]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dtrScHxXQox"
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bppGycBXYCQr"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JneR0u0sYRTd"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3x41RBYfvY"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG3RrwDXZEaS"
      },
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHZ-LKv_ZRb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b0a619b-5bc7-4d47-c418-33c1e1ee560d"
      },
      "source": [
        "#train on 100,500,1000 epochs\n",
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 1000)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8643\n",
            "Epoch 496/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8652\n",
            "Epoch 497/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8646\n",
            "Epoch 498/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8656\n",
            "Epoch 499/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8648\n",
            "Epoch 500/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8655\n",
            "Epoch 501/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8651\n",
            "Epoch 502/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8654\n",
            "Epoch 503/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8654\n",
            "Epoch 504/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8673\n",
            "Epoch 505/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8646\n",
            "Epoch 506/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8656\n",
            "Epoch 507/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8648\n",
            "Epoch 508/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8659\n",
            "Epoch 509/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8646\n",
            "Epoch 510/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8674\n",
            "Epoch 511/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8656\n",
            "Epoch 512/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8666\n",
            "Epoch 513/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8649\n",
            "Epoch 514/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8660\n",
            "Epoch 515/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8664\n",
            "Epoch 516/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8675\n",
            "Epoch 517/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8660\n",
            "Epoch 518/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8661\n",
            "Epoch 519/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8661\n",
            "Epoch 520/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8669\n",
            "Epoch 521/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8659\n",
            "Epoch 522/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8661\n",
            "Epoch 523/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8652\n",
            "Epoch 524/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8649\n",
            "Epoch 525/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8641\n",
            "Epoch 526/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8646\n",
            "Epoch 527/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8637\n",
            "Epoch 528/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8668\n",
            "Epoch 529/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8670\n",
            "Epoch 530/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8659\n",
            "Epoch 531/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8656\n",
            "Epoch 532/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8651\n",
            "Epoch 533/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8651\n",
            "Epoch 534/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8643\n",
            "Epoch 535/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8652\n",
            "Epoch 536/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8656\n",
            "Epoch 537/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8660\n",
            "Epoch 538/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8660\n",
            "Epoch 539/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8668\n",
            "Epoch 540/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8668\n",
            "Epoch 541/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8659\n",
            "Epoch 542/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8645\n",
            "Epoch 543/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8665\n",
            "Epoch 544/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8658\n",
            "Epoch 545/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8658\n",
            "Epoch 546/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8665\n",
            "Epoch 547/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8666\n",
            "Epoch 548/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8659\n",
            "Epoch 549/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8645\n",
            "Epoch 550/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8660\n",
            "Epoch 551/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8661\n",
            "Epoch 552/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8658\n",
            "Epoch 553/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8650\n",
            "Epoch 554/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8646\n",
            "Epoch 555/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8661\n",
            "Epoch 556/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8651\n",
            "Epoch 557/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8674\n",
            "Epoch 558/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8664\n",
            "Epoch 559/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8652\n",
            "Epoch 560/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8646\n",
            "Epoch 561/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8654\n",
            "Epoch 562/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8652\n",
            "Epoch 563/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8668\n",
            "Epoch 564/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8644\n",
            "Epoch 565/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8640\n",
            "Epoch 566/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8654\n",
            "Epoch 567/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8665\n",
            "Epoch 568/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8646\n",
            "Epoch 569/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8654\n",
            "Epoch 570/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8659\n",
            "Epoch 571/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8637\n",
            "Epoch 572/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8636\n",
            "Epoch 573/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8654\n",
            "Epoch 574/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8665\n",
            "Epoch 575/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8641\n",
            "Epoch 576/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8641\n",
            "Epoch 577/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8660\n",
            "Epoch 578/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8658\n",
            "Epoch 579/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8652\n",
            "Epoch 580/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8652\n",
            "Epoch 581/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8649\n",
            "Epoch 582/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8649\n",
            "Epoch 583/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8661\n",
            "Epoch 584/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8661\n",
            "Epoch 585/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8658\n",
            "Epoch 586/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8659\n",
            "Epoch 587/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8662\n",
            "Epoch 588/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8649\n",
            "Epoch 589/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8659\n",
            "Epoch 590/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8665\n",
            "Epoch 591/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8650\n",
            "Epoch 592/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8664\n",
            "Epoch 593/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8641\n",
            "Epoch 594/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8659\n",
            "Epoch 595/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8666\n",
            "Epoch 596/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8654\n",
            "Epoch 597/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8662\n",
            "Epoch 598/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8648\n",
            "Epoch 599/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8656\n",
            "Epoch 600/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8644\n",
            "Epoch 601/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8662\n",
            "Epoch 602/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8658\n",
            "Epoch 603/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8649\n",
            "Epoch 604/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8655\n",
            "Epoch 605/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8656\n",
            "Epoch 606/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8648\n",
            "Epoch 607/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8656\n",
            "Epoch 608/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8666\n",
            "Epoch 609/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8662\n",
            "Epoch 610/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8643\n",
            "Epoch 611/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8660\n",
            "Epoch 612/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8662\n",
            "Epoch 613/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8659\n",
            "Epoch 614/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8655\n",
            "Epoch 615/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8659\n",
            "Epoch 616/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8635\n",
            "Epoch 617/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8660\n",
            "Epoch 618/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8649\n",
            "Epoch 619/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8660\n",
            "Epoch 620/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8671\n",
            "Epoch 621/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8649\n",
            "Epoch 622/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8650\n",
            "Epoch 623/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8659\n",
            "Epoch 624/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8652\n",
            "Epoch 625/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8650\n",
            "Epoch 626/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8671\n",
            "Epoch 627/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8658\n",
            "Epoch 628/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8654\n",
            "Epoch 629/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8654\n",
            "Epoch 630/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8656\n",
            "Epoch 631/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8655\n",
            "Epoch 632/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8652\n",
            "Epoch 633/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8658\n",
            "Epoch 634/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8671\n",
            "Epoch 635/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8674\n",
            "Epoch 636/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8675\n",
            "Epoch 637/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8650\n",
            "Epoch 638/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8666\n",
            "Epoch 639/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8668\n",
            "Epoch 640/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8650\n",
            "Epoch 641/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8658\n",
            "Epoch 642/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8637\n",
            "Epoch 643/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8664\n",
            "Epoch 644/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8666\n",
            "Epoch 645/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8645\n",
            "Epoch 646/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8665\n",
            "Epoch 647/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8658\n",
            "Epoch 648/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8661\n",
            "Epoch 649/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8648\n",
            "Epoch 650/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8671\n",
            "Epoch 651/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8666\n",
            "Epoch 652/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8643\n",
            "Epoch 653/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8652\n",
            "Epoch 654/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8650\n",
            "Epoch 655/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8670\n",
            "Epoch 656/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8661\n",
            "Epoch 657/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8659\n",
            "Epoch 658/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8655\n",
            "Epoch 659/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8654\n",
            "Epoch 660/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8651\n",
            "Epoch 661/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8655\n",
            "Epoch 662/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8650\n",
            "Epoch 663/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8651\n",
            "Epoch 664/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8646\n",
            "Epoch 665/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8649\n",
            "Epoch 666/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8654\n",
            "Epoch 667/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8651\n",
            "Epoch 668/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8637\n",
            "Epoch 669/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8646\n",
            "Epoch 670/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8666\n",
            "Epoch 671/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8654\n",
            "Epoch 672/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8655\n",
            "Epoch 673/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8654\n",
            "Epoch 674/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8643\n",
            "Epoch 675/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8656\n",
            "Epoch 676/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8649\n",
            "Epoch 677/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8660\n",
            "Epoch 678/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8655\n",
            "Epoch 679/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8660\n",
            "Epoch 680/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8660\n",
            "Epoch 681/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8659\n",
            "Epoch 682/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8645\n",
            "Epoch 683/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8641\n",
            "Epoch 684/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8659\n",
            "Epoch 685/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8662\n",
            "Epoch 686/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8662\n",
            "Epoch 687/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8664\n",
            "Epoch 688/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8665\n",
            "Epoch 689/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8671\n",
            "Epoch 690/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8650\n",
            "Epoch 691/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8662\n",
            "Epoch 692/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8664\n",
            "Epoch 693/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8662\n",
            "Epoch 694/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8671\n",
            "Epoch 695/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8661\n",
            "Epoch 696/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8656\n",
            "Epoch 697/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8654\n",
            "Epoch 698/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8637\n",
            "Epoch 699/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8644\n",
            "Epoch 700/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8645\n",
            "Epoch 701/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8640\n",
            "Epoch 702/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8649\n",
            "Epoch 703/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8664\n",
            "Epoch 704/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8648\n",
            "Epoch 705/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8649\n",
            "Epoch 706/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8664\n",
            "Epoch 707/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8662\n",
            "Epoch 708/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8651\n",
            "Epoch 709/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8674\n",
            "Epoch 710/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8659\n",
            "Epoch 711/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8635\n",
            "Epoch 712/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8648\n",
            "Epoch 713/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8658\n",
            "Epoch 714/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8681\n",
            "Epoch 715/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8662\n",
            "Epoch 716/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8660\n",
            "Epoch 717/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8665\n",
            "Epoch 718/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8655\n",
            "Epoch 719/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8661\n",
            "Epoch 720/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8661\n",
            "Epoch 721/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8646\n",
            "Epoch 722/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8658\n",
            "Epoch 723/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8668\n",
            "Epoch 724/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8658\n",
            "Epoch 725/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8646\n",
            "Epoch 726/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8639\n",
            "Epoch 727/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8669\n",
            "Epoch 728/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8640\n",
            "Epoch 729/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8665\n",
            "Epoch 730/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8662\n",
            "Epoch 731/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8659\n",
            "Epoch 732/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8645\n",
            "Epoch 733/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8659\n",
            "Epoch 734/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8655\n",
            "Epoch 735/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8658\n",
            "Epoch 736/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8658\n",
            "Epoch 737/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8671\n",
            "Epoch 738/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8645\n",
            "Epoch 739/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8665\n",
            "Epoch 740/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8644\n",
            "Epoch 741/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8649\n",
            "Epoch 742/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8654\n",
            "Epoch 743/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8664\n",
            "Epoch 744/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8645\n",
            "Epoch 745/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8666\n",
            "Epoch 746/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8654\n",
            "Epoch 747/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8676\n",
            "Epoch 748/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8658\n",
            "Epoch 749/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8664\n",
            "Epoch 750/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8641\n",
            "Epoch 751/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8648\n",
            "Epoch 752/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8649\n",
            "Epoch 753/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8656\n",
            "Epoch 754/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8671\n",
            "Epoch 755/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8664\n",
            "Epoch 756/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8641\n",
            "Epoch 757/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8652\n",
            "Epoch 758/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8646\n",
            "Epoch 759/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8644\n",
            "Epoch 760/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8651\n",
            "Epoch 761/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8650\n",
            "Epoch 762/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8651\n",
            "Epoch 763/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8652\n",
            "Epoch 764/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8654\n",
            "Epoch 765/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8658\n",
            "Epoch 766/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8643\n",
            "Epoch 767/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8662\n",
            "Epoch 768/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8650\n",
            "Epoch 769/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8668\n",
            "Epoch 770/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8661\n",
            "Epoch 771/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8661\n",
            "Epoch 772/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8655\n",
            "Epoch 773/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8645\n",
            "Epoch 774/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8650\n",
            "Epoch 775/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8664\n",
            "Epoch 776/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 777/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8665\n",
            "Epoch 778/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8649\n",
            "Epoch 779/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8650\n",
            "Epoch 780/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8656\n",
            "Epoch 781/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8641\n",
            "Epoch 782/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8654\n",
            "Epoch 783/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8670\n",
            "Epoch 784/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8651\n",
            "Epoch 785/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8660\n",
            "Epoch 786/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8662\n",
            "Epoch 787/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8645\n",
            "Epoch 788/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8661\n",
            "Epoch 789/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8662\n",
            "Epoch 790/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8660\n",
            "Epoch 791/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8659\n",
            "Epoch 792/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8643\n",
            "Epoch 793/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8648\n",
            "Epoch 794/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8661\n",
            "Epoch 795/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8658\n",
            "Epoch 796/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8652\n",
            "Epoch 797/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8677\n",
            "Epoch 798/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8636\n",
            "Epoch 799/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8660\n",
            "Epoch 800/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8655\n",
            "Epoch 801/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8664\n",
            "Epoch 802/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8652\n",
            "Epoch 803/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8655\n",
            "Epoch 804/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 805/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8668\n",
            "Epoch 806/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8649\n",
            "Epoch 807/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8646\n",
            "Epoch 808/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8665\n",
            "Epoch 809/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8633\n",
            "Epoch 810/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8662\n",
            "Epoch 811/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8648\n",
            "Epoch 812/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8648\n",
            "Epoch 813/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8661\n",
            "Epoch 814/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8658\n",
            "Epoch 815/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8679\n",
            "Epoch 816/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8658\n",
            "Epoch 817/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8648\n",
            "Epoch 818/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8648\n",
            "Epoch 819/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8655\n",
            "Epoch 820/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8661\n",
            "Epoch 821/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8658\n",
            "Epoch 822/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8673\n",
            "Epoch 823/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8646\n",
            "Epoch 824/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8655\n",
            "Epoch 825/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8654\n",
            "Epoch 826/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8654\n",
            "Epoch 827/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8659\n",
            "Epoch 828/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8636\n",
            "Epoch 829/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8651\n",
            "Epoch 830/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8662\n",
            "Epoch 831/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8662\n",
            "Epoch 832/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8669\n",
            "Epoch 833/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8658\n",
            "Epoch 834/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8645\n",
            "Epoch 835/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8659\n",
            "Epoch 836/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8660\n",
            "Epoch 837/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8664\n",
            "Epoch 838/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8652\n",
            "Epoch 839/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8660\n",
            "Epoch 840/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8652\n",
            "Epoch 841/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 842/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8650\n",
            "Epoch 843/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8641\n",
            "Epoch 844/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8652\n",
            "Epoch 845/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8645\n",
            "Epoch 846/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8676\n",
            "Epoch 847/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8659\n",
            "Epoch 848/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8660\n",
            "Epoch 849/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8649\n",
            "Epoch 850/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8664\n",
            "Epoch 851/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8656\n",
            "Epoch 852/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8655\n",
            "Epoch 853/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8656\n",
            "Epoch 854/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8648\n",
            "Epoch 855/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8668\n",
            "Epoch 856/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8650\n",
            "Epoch 857/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8644\n",
            "Epoch 858/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8666\n",
            "Epoch 859/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8648\n",
            "Epoch 860/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8644\n",
            "Epoch 861/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8662\n",
            "Epoch 862/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8659\n",
            "Epoch 863/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8656\n",
            "Epoch 864/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8661\n",
            "Epoch 865/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8629\n",
            "Epoch 866/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8662\n",
            "Epoch 867/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8649\n",
            "Epoch 868/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8651\n",
            "Epoch 869/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8669\n",
            "Epoch 870/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8650\n",
            "Epoch 871/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8645\n",
            "Epoch 872/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8646\n",
            "Epoch 873/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8656\n",
            "Epoch 874/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8645\n",
            "Epoch 875/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8680\n",
            "Epoch 876/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8637\n",
            "Epoch 877/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8656\n",
            "Epoch 878/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8651\n",
            "Epoch 879/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8665\n",
            "Epoch 880/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8643\n",
            "Epoch 881/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8660\n",
            "Epoch 882/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8666\n",
            "Epoch 883/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8637\n",
            "Epoch 884/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8654\n",
            "Epoch 885/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8646\n",
            "Epoch 886/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8666\n",
            "Epoch 887/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8659\n",
            "Epoch 888/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8654\n",
            "Epoch 889/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8648\n",
            "Epoch 890/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8662\n",
            "Epoch 891/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8644\n",
            "Epoch 892/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8656\n",
            "Epoch 893/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8654\n",
            "Epoch 894/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8630\n",
            "Epoch 895/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8651\n",
            "Epoch 896/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8648\n",
            "Epoch 897/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8652\n",
            "Epoch 898/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8664\n",
            "Epoch 899/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8650\n",
            "Epoch 900/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8659\n",
            "Epoch 901/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8658\n",
            "Epoch 902/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8674\n",
            "Epoch 903/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8654\n",
            "Epoch 904/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8662\n",
            "Epoch 905/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8652\n",
            "Epoch 906/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8641\n",
            "Epoch 907/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8661\n",
            "Epoch 908/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8649\n",
            "Epoch 909/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8648\n",
            "Epoch 910/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8649\n",
            "Epoch 911/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8664\n",
            "Epoch 912/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8660\n",
            "Epoch 913/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8659\n",
            "Epoch 914/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8658\n",
            "Epoch 915/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8659\n",
            "Epoch 916/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8651\n",
            "Epoch 917/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8654\n",
            "Epoch 918/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8656\n",
            "Epoch 919/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8651\n",
            "Epoch 920/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8649\n",
            "Epoch 921/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8644\n",
            "Epoch 922/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8658\n",
            "Epoch 923/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8654\n",
            "Epoch 924/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8659\n",
            "Epoch 925/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8645\n",
            "Epoch 926/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8649\n",
            "Epoch 927/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8661\n",
            "Epoch 928/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8658\n",
            "Epoch 929/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8644\n",
            "Epoch 930/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8658\n",
            "Epoch 931/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8655\n",
            "Epoch 932/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8639\n",
            "Epoch 933/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8656\n",
            "Epoch 934/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8660\n",
            "Epoch 935/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8659\n",
            "Epoch 936/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8651\n",
            "Epoch 937/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8639\n",
            "Epoch 938/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8660\n",
            "Epoch 939/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 940/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8661\n",
            "Epoch 941/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8644\n",
            "Epoch 942/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8669\n",
            "Epoch 943/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8669\n",
            "Epoch 944/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8661\n",
            "Epoch 945/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8668\n",
            "Epoch 946/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8668\n",
            "Epoch 947/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8659\n",
            "Epoch 948/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8637\n",
            "Epoch 949/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8669\n",
            "Epoch 950/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8644\n",
            "Epoch 951/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8645\n",
            "Epoch 952/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8662\n",
            "Epoch 953/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8656\n",
            "Epoch 954/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8645\n",
            "Epoch 955/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8658\n",
            "Epoch 956/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8645\n",
            "Epoch 957/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8631\n",
            "Epoch 958/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8670\n",
            "Epoch 959/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8670\n",
            "Epoch 960/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8664\n",
            "Epoch 961/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8673\n",
            "Epoch 962/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8655\n",
            "Epoch 963/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8645\n",
            "Epoch 964/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8666\n",
            "Epoch 965/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8656\n",
            "Epoch 966/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8661\n",
            "Epoch 967/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8658\n",
            "Epoch 968/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8648\n",
            "Epoch 969/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8650\n",
            "Epoch 970/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8669\n",
            "Epoch 971/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8626\n",
            "Epoch 972/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8664\n",
            "Epoch 973/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8662\n",
            "Epoch 974/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8648\n",
            "Epoch 975/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8644\n",
            "Epoch 976/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8645\n",
            "Epoch 977/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8640\n",
            "Epoch 978/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8652\n",
            "Epoch 979/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8641\n",
            "Epoch 980/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8655\n",
            "Epoch 981/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8650\n",
            "Epoch 982/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8659\n",
            "Epoch 983/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8669\n",
            "Epoch 984/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8659\n",
            "Epoch 985/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8659\n",
            "Epoch 986/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8665\n",
            "Epoch 987/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8634\n",
            "Epoch 988/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8659\n",
            "Epoch 989/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8650\n",
            "Epoch 990/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8641\n",
            "Epoch 991/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8659\n",
            "Epoch 992/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8658\n",
            "Epoch 993/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8646\n",
            "Epoch 994/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8665\n",
            "Epoch 995/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8648\n",
            "Epoch 996/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8661\n",
            "Epoch 997/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8644\n",
            "Epoch 998/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8666\n",
            "Epoch 999/1000\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8644\n",
            "Epoch 1000/1000\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fedbf760c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of 3 observation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns.For Male you should encode as '1' and for Female '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "**Assignment**\n",
        "\n",
        "Use our ANN model to predict if the customers with the following informations will leave the bank: \n",
        "\n",
        "Geography: France,Germany,Spain\n",
        "\n",
        "Credit Score: 600,800,700\n",
        "\n",
        "Gender: Male,Female,Male\n",
        "\n",
        "Age: 40,50,35,years old\n",
        "\n",
        "Tenure: 3,5,4 years\n",
        "\n",
        "Balance: \\$ 60000,70000,0\n",
        "\n",
        "Number of Products: 2,1,0\n",
        "\n",
        "Does this customer have a credit card ? Yes,No,No\n",
        "\n",
        "Is this customer an Active Member: Yes,No,No\n",
        "\n",
        "Estimated Salary: \\$ 50000,10000,0\n",
        "\n",
        "So, should we say goodbye to that customer ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "Sample \n",
        "If value is greater than 0.5 - True  \n",
        "Else -False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-15JL842dxWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56485aa8-f8da-41a7-89cc-3ee5a45d9d46"
      },
      "source": [
        "print(ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]])) > 0.5)\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opk6uV7JjjW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f290c0-13f9-4535-b89d-61f26e06af09"
      },
      "source": [
        "ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]]))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.06935316]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGAYIx4Zjjgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e1da28-f28f-4937-9ab2-b0c8cb74c610"
      },
      "source": [
        "print(ann.predict(sc.transform([[0,1,0,800,0,50,5,70000,1,0,0,10000]])) > 0.5)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCw4m5bCjkKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def08f93-135d-46a9-a8c5-7d73f6c617a4"
      },
      "source": [
        "print(ann.predict(sc.transform([[0,0,1,700,1,35,4,0,0,0,0,0]])) > 0.5)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyEeQdRZwgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20d6e1d-ae49-40da-ac4b-cda544f37c14"
      },
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjvfa5SBe-eP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6993581f-b966-4dd6-d009-680ea433a655"
      },
      "source": [
        "y_pred[0:10]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KcgCBWbX89C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960650f4-220b-4ed9-b172-014cb048562d"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6K_r6LaF6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccde8ef2-e2e2-4b5d-c493-236aad99139f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1499   96]\n",
            " [ 183  222]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ut3uyxlOqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1453474f-92d3-4b58-b04d-c1c50f583722"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSRSEMXDjmI2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "3178cfe4-3be8-41f4-b50c-c810300f0283"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "LABELS = ['Not Left Bank', 'Left Bank'] \n",
        "plt.figure(figsize =(8, 8)) \n",
        "sns.heatmap(cm, xticklabels = LABELS,  \n",
        "            yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
        "plt.title(\"Confusion matrix\") \n",
        "plt.ylabel('True class') \n",
        "plt.xlabel('Predicted class') \n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ijy_fUxk-Ga"
      },
      "source": [
        ""
      ],
      "execution_count": 73,
      "outputs": []
    }
  ]
}